"""
Nombre del m√≥dulo: S90_PUBLICAR_OC_PRECARGA.py

Descripci√≥n:
Migraci√≥n optimizada de datos de √≥rdenes de compra precargadas desde PostgreSQL (Open_Diarco_Data)
a SQL Server de Test (Open_Diarco_Test), con log de auditor√≠a y soporte para inserciones masivas.
Migraci√≥n optimizada de datos desde PostgreSQL (Open_Diarco_Data)
a SQL Server de test (Open_Diarco_Test), con log y marca de publicaci√≥n.

Autor: EWE - Zeetrex
Fecha: 2025-04-25
"""

import pandas as pd
import traceback
from sqlalchemy import create_engine, text
from sqlalchemy.dialects.postgresql import insert
from dotenv import dotenv_values
import pyodbc
import logging
import os

# Cargar configuraci√≥n
secrets = dotenv_values(".env")
folder_logs = secrets["FOLDER_DATOS"]
os.makedirs(folder_logs, exist_ok=True)
log_file = os.path.join(folder_logs, "publicacion_oc_precarga.log")


# Configurar logging
logging.basicConfig(
    filename=log_file,
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)

def Open_Diarco_Data():
    try:
        conn_str = f"postgresql+psycopg2://{secrets['USUARIO3']}:{secrets['CONTRASENA3']}@{secrets['SERVIDOR3']}:{secrets['PUERTO3']}/{secrets['BASE3']}"
        return create_engine(conn_str)
    except Exception as e:
        print(f'Error en la conexi√≥n: {e}')
        return None

def Open_Diarco_Test():
    conn_str = (
        f"DRIVER={{ODBC Driver 17 for SQL Server}};"
        f"SERVER={secrets['TEST_SERVER']};"
        f"DATABASE={secrets['TEST_BASE']};"
        f"UID={secrets['TEST_USER']};"
        f"PWD={secrets['TEST_PASS']};"
        f"TrustServerCertificate=yes;"
    )
    conn = pyodbc.connect(conn_str, autocommit=False)
    return conn

# Funci√≥n para limpiar y normalizar los campos
def limpiar_campos_oc(df):
    # Normalizar textos respetando la longitud m√°xima del destino
    df["c_usuario_genero_oc"]   = df["c_usuario_genero_oc"].fillna("").astype(str).str[:10]
    df["c_terminal_genero_oc"]  = df["c_terminal_genero_oc"].fillna("").astype(str).str[:15]
    df["c_usuario_bloqueo"]     = df["c_usuario_bloqueo"].fillna("").astype(str).str[:10]
    df["m_procesado"]           = df["m_procesado"].fillna("N").astype(str).str[:1]
    df["c_compra_kikker"]       = df["c_compra_kikker"].fillna("").astype(str).str[:20]
    df["c_usuario_modif"]       = df["c_usuario_modif"].fillna("").astype(str).str[:20]

    # N√∫meros exactos
    df["u_prefijo_oc"] = pd.to_numeric(df["u_prefijo_oc"], errors="coerce").fillna(0).astype(int)
    df["u_sufijo_oc"]  = pd.to_numeric(df["u_sufijo_oc"], errors="coerce").fillna(0).astype(int)

    # Timestamps (permitimos NaT)
    df["f_genero_oc"] = df["f_genero_oc"].fillna(pd.Timestamp('1900-01-01 00:00:00.000'))
    df["f_procesado"] = df["f_procesado"].fillna(pd.Timestamp('1900-01-01 00:00:00.000'))
    #df["f_genero_oc"] = pd.to_datetime(df["f_genero_oc"], errors='coerce')
    #df["f_procesado"] = pd.to_datetime(df["f_procesado"], errors='coerce')

    return df

def validar_longitudes(df):
    campos_texto = [
        "c_usuario_genero_oc", "c_terminal_genero_oc", "c_usuario_bloqueo",
        "m_procesado", "c_compra_kikker", "c_usuario_modif"
    ]
    print("\nüß™ Validando longitudes m√°ximas por columna de texto:")
    for col in campos_texto:
        max_len = df[col].astype(str).map(len).max()
        print(f"{col}: longitud m√°xima = {max_len}")


# Funci√≥n principal de publicaci√≥n
def publicar_oc_precarga():
    logging.info("üîÑ Iniciando publicaci√≥n de OC Precarga")

    try:
        # Conexi√≥n PostgreSQL
        engine_pg = Open_Diarco_Data()
        with engine_pg.begin() as conn_pg:
            query = """
            SELECT *
            FROM public.t080_oc_precarga_kikker
            WHERE m_publicado = false
            """
            df_oc = pd.read_sql(query, conn_pg)

            if df_oc.empty:
                logging.warning("‚ö†Ô∏è No hay registros pendientes de publicaci√≥n")
                return

            total_rows = len(df_oc)
            logging.info(f"‚úÖ Registros a publicar: {total_rows}")

            # Limpiar los campos antes de insertar
            df_oc = limpiar_campos_oc(df_oc)
            validar_longitudes(df_oc)
            
            print(df_oc.head(5))  # Mostrar las primeras filas del DataFrame

            # Conexi√≥n a SQL Server
            conn_sql = Open_Diarco_Test()
            cursor = conn_sql.cursor()
            cursor.fast_executemany = True

            insert_stmt = """
            INSERT INTO [dbo].[T080_OC_PRECARGA_KIKKER] (
                [C_PROVEEDOR], [C_ARTICULO], [C_SUCU_EMPR], [Q_BULTOS_KILOS_DIARCO],
                [F_ALTA_SIST], [C_USUARIO_GENERO_OC], [C_TERMINAL_GENERO_OC], [F_GENERO_OC],
                [C_USUARIO_BLOQUEO], [M_PROCESADO], [F_PROCESADO], [U_PREFIJO_OC],
                [U_SUFIJO_OC], [C_COMPRA_KIKKER], [C_USUARIO_MODIF], [C_COMPRADOR]
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """

            data_tuples = df_oc[[
                'c_proveedor', 'c_articulo', 'c_sucu_empr', 'q_bultos_kilos_diarco',
                'f_alta_sist', 'c_usuario_genero_oc', 'c_terminal_genero_oc', 'f_genero_oc',
                'c_usuario_bloqueo', 'm_procesado', 'f_procesado', 'u_prefijo_oc',
                'u_sufijo_oc', 'c_compra_kikker', 'c_usuario_modif', 'c_comprador'
            ]].itertuples(index=False, name=None)

            cursor.executemany(insert_stmt, list(data_tuples))
            conn_sql.commit()
            logging.info("üü¢ Inserci√≥n completada en SQL Server")
            print(f"‚úî Se insertaron {total_rows} registros en SQL Server.")

            # Actualizaci√≥n en PostgreSQL: marcar como publicado
            update_stmt = text("""
                UPDATE public.t080_oc_precarga_kikker
                SET m_publicado = true
                WHERE m_publicado = false
            """)
            result = conn_pg.execute(update_stmt)
            logging.info(f"üîÅ {result.rowcount} registros marcados como publicados")
            print(f"‚úî {result.rowcount} registros actualizados con m_publicado = true")

    except Exception as e:
        logging.error("‚ùå Error durante la publicaci√≥n de OC Precarga")
        logging.error(traceback.format_exc())
        print("‚ùå Error durante la ejecuci√≥n:", e)

    finally:
        try:
            cursor.close()
            conn_sql.close()
            logging.info("üîí Conexiones cerradas correctamente")
        except Exception as e:
            logging.warning("‚ö†Ô∏è Error al cerrar conexiones")
            logging.warning(str(e))

if __name__ == "__main__":
    publicar_oc_precarga()
    print(f"üìù Proceso finalizado. Ver log en: {log_file}")