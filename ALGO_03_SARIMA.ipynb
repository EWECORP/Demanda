{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALGORITMOS BASADOS EN SERIES TEMPORALES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Modelos ARIMA con Componentes Estacionales (SARIMA)\n",
    "El modelo SARIMA (Seasonal Autoregressive Integrated Moving Average) es una extensiÃ³n del modelo ARIMA que incorpora patrones estacionales y se basa en valores anteriores de la serie temporal.\n",
    "\n",
    "### Estructura del modelo SARIMA(p, d, q)(P, D, Q, s):\n",
    "* (p, d, q) â†’ Componentes autoregresivos, diferenciales y de media mÃ³vil.\n",
    "* (P, D, Q, s) â†’ Componentes estacionales con periodicidad ð‘  (en este caso, s=12 meses).\n",
    "\n",
    "Este modelo aprende la relaciÃ³n entre:\n",
    "* Ventas recientes (p).\n",
    "* Tendencias de largo plazo (d).\n",
    "* Variaciones estacionales mensuales (P, D, Q, s).\n",
    "\n",
    "### ðŸ“Œ SARIMA es adecuado cuando la demanda tiene estacionalidad anual y fluctuaciones a corto plazo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#from pmdarima.arima import auto_arima\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpmdarima\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auto_arima\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, mean_squared_error\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyodbc\u001b[39;00m\n",
      "File \u001b[1;32mc:\\PY\\.venv\\Lib\\site-packages\\pmdarima\\__init__.py:52\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __check_build\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Stuff we want at top-level\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auto_arima, ARIMA, AutoARIMA, StepwiseContext, decompose\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m acf, autocorr_plot, c, pacf, plot_acf, plot_pacf, \\\n\u001b[0;32m     54\u001b[0m     tsdisplay\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n",
      "File \u001b[1;32mc:\\PY\\.venv\\Lib\\site-packages\\pmdarima\\arima\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Author: Taylor Smith <taylor.smith@alkaline-ml.com>\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapprox\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\PY\\.venv\\Lib\\site-packages\\pmdarima\\arima\\approx.py:9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Author: Taylor Smith <taylor.smith@alkaline-ml.com>\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# R approx function\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m c, check_endog\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_callable\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DTYPE\n",
      "File \u001b[1;32mc:\\PY\\.venv\\Lib\\site-packages\\pmdarima\\utils\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Author: Taylor Smith <taylor.smith@alkaline-ml.com>\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetaestimators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\PY\\.venv\\Lib\\site-packages\\pmdarima\\utils\\array.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DTYPE\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m C_intgrt_vec\n\u001b[0;32m     15\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mas_series\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_iterable\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     23\u001b[0m ]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_series\u001b[39m(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "File \u001b[1;32mc:\\PY\\.venv\\Lib\\site-packages\\pmdarima\\utils\\_array.pyx:1\u001b[0m, in \u001b[0;36minit pmdarima.utils._array\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "#from pmdarima.arima import auto_arima\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import pyodbc\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 2.2.3\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pmdarima' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpmdarima version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mpmdarima\u001b[49m\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pmdarima' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"pmdarima version:\", pmdarima.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELEGIR el PROVEEDOR\n",
    "\n",
    "proveedor = 327\n",
    "label = '327-Paladini'\n",
    "\n",
    "# Cargar Datos\n",
    "data = pd.read_csv(f'data/{label}.csv')\n",
    "data.head()\n",
    "\n",
    "# Adecuar Tipos de Datos\n",
    "data['Sucursal']= data['Sucursal'].astype(int)\n",
    "data['Familia']= data['Familia'].astype(int)\n",
    "data['Rubro']= data['Rubro'].astype(int)\n",
    "data['SubRubro']= data['SubRubro'].astype(int)\n",
    "data['Clasificacion']= data['Clasificacion'].astype(int)\n",
    "data['Codigo_Articulo']= data['Codigo_Articulo'].astype(int)\n",
    "data['Fecha'] = pd.to_datetime(data['Fecha'])  # Convertir a formato datetime si aÃºn no lo estÃ¡\n",
    "data.sort_values(by='Fecha', ascending=True)  # Ordenar por fecha de menor a mayor\n",
    "\n",
    "# Crear una nueva columna con el mes y el aÃ±o para anÃ¡lisis temporal\n",
    "data['AÃ±o-Mes'] = data['Fecha'].dt.to_period('M')\n",
    "\n",
    "# Crear una nueva columna con el formato AÃ±o-Semana (AAAA-WW) a partir de la columna Fecha\n",
    "data['AÃ±o-Semana'] = data['Fecha'].dt.strftime('%Y-%W')\n",
    "\n",
    "# Confirmar que la columna sigue siendo un campo datetime\n",
    "#print(data.dtypes)\n",
    "\n",
    "#data = data.sort_values(by='Fecha', ascending=True)  # Ordenar en orden ascendente (del mÃ¡s antiguo al mÃ¡s reciente)\n",
    "#data = data.reset_index()\n",
    "\n",
    "# Recortar Cantidad de Datos ULTIMO AÃ‘O COMPLETO\n",
    "df = data[data['Fecha']>='2021-01-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”¹ ExplicaciÃ³n del CÃ³digo\n",
    "#### ðŸ“Š Preprocesamiento de datos\n",
    "* Se agruparon las ventas mensuales por artÃ­culo y sucursal.\n",
    "* Se seleccionÃ³ un producto y sucursal especÃ­ficos para entrenar el modelo.\n",
    "* Se convirtiÃ³ el DataFrame en una serie temporal con frecuencia mensual (asfreq('M')).\n",
    "\n",
    "#### ðŸ”Ž SelecciÃ³n de ParÃ¡metros AutomÃ¡ticos con auto_arima\n",
    "* auto_arima(train, seasonal=True, m=12, trace=True) encuentra automÃ¡ticamente los mejores parÃ¡metros (p, d, q) y (P, D, Q, s) considerando estacionalidad mensual (m=12).\n",
    "#### ðŸ“ˆ Entrenamiento del Modelo SARIMA\n",
    "* Se usa SARIMAX de statsmodels con los parÃ¡metros encontrados.\n",
    "* Se entrena el modelo en los datos histÃ³ricos de ventas.\n",
    "#### ðŸ“Š PredicciÃ³n y EvaluaciÃ³n\n",
    "* Se generan predicciones para el conjunto de prueba.\n",
    "* Se calculan mÃ©tricas de error:\n",
    "* MAE (Error Absoluto Medio)\n",
    "* RMSE (RaÃ­z del Error CuadrÃ¡tico Medio)\n",
    "#### ðŸ“‰ VisualizaciÃ³n\n",
    "Se grafica la serie original junto con las predicciones para ver la precisiÃ³n del modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisar:\n",
    "* âœ… SARIMA es ideal cuando hay patrones estacionales fuertes en la demanda.\n",
    "* âœ… Este modelo mejora la precisiÃ³n al incorporar informaciÃ³n del aÃ±o pasado y la tendencia de corto plazo.\n",
    "* âœ… Se puede entrenar un SARIMA diferente para cada producto y sucursal, o usar tÃ©cnicas mÃ¡s avanzadas como modelos de series temporales mÃºltiples (VAR, Prophet, LSTM) si tienes muchos productos.\n",
    "\n",
    "Â¡Puedes probarlo en tus datos y ver quÃ© tan bien predice la demanda en cada tienda ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que 'AÃ±o-Mes' estÃ¡ en formato datetime\n",
    "df['AÃ±o-Mes'] = pd.to_datetime(df['AÃ±o-Mes'].astype(str))\n",
    "\n",
    "# Agrupar las ventas mensuales por artÃ­culo y sucursal\n",
    "df_ventas_mensuales = df.groupby(['AÃ±o-Mes', 'Codigo_Articulo', 'Sucursal'])['Unidades'].sum().reset_index()\n",
    "\n",
    "# Seleccionar un producto y una sucursal para el anÃ¡lisis SARIMA\n",
    "codigo_articulo = df_ventas_mensuales['Codigo_Articulo'].unique()[0]  # Primer artÃ­culo\n",
    "sucursal = df_ventas_mensuales['Sucursal'].unique()[0]  # Primera sucursal\n",
    "\n",
    "df_filtrado = df_ventas_mensuales[(df_ventas_mensuales['Codigo_Articulo'] == codigo_articulo) &\n",
    "                                  (df_ventas_mensuales['Sucursal'] == sucursal)]\n",
    "\n",
    "# Convertir en serie temporal con 'AÃ±o-Mes' como Ã­ndice\n",
    "df_filtrado.set_index('AÃ±o-Mes', inplace=True)\n",
    "df_filtrado = df_filtrado.asfreq('M')  # Asegurar frecuencia mensual\n",
    "\n",
    "# Dividir en datos de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "train_size = int(len(df_filtrado) * 0.8)\n",
    "train, test = df_filtrado.iloc[:train_size], df_filtrado.iloc[train_size:]\n",
    "\n",
    "# Identificar automÃ¡ticamente los mejores parÃ¡metros SARIMA (p, d, q) y (P, D, Q, s)\n",
    "auto_model = auto_arima(train, seasonal=True, m=12, trace=True, stepwise=True, suppress_warnings=True)\n",
    "\n",
    "# Entrenar el modelo SARIMA con los parÃ¡metros encontrados\n",
    "order = auto_model.order\n",
    "seasonal_order = auto_model.seasonal_order\n",
    "sarima_model = sm.tsa.SARIMAX(train, order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n",
    "sarima_fit = sarima_model.fit()\n",
    "\n",
    "# Generar predicciones en el conjunto de prueba\n",
    "pred_start = test.index[0]\n",
    "pred_end = test.index[-1]\n",
    "predictions = sarima_fit.predict(start=pred_start, end=pred_end)\n",
    "\n",
    "# Evaluar el modelo\n",
    "mae = mean_absolute_error(test, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(test, predictions))\n",
    "\n",
    "print(f\"Error Absoluto Medio (MAE): {mae:.2f}\")\n",
    "print(f\"RaÃ­z del Error CuadrÃ¡tico Medio (RMSE): {rmse:.2f}\")\n",
    "\n",
    "# Graficar resultados\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train.index, train['Unidades'], label=\"Entrenamiento\", color='blue')\n",
    "plt.plot(test.index, test['Unidades'], label=\"Prueba\", color='green')\n",
    "plt.plot(test.index, predictions, label=\"PredicciÃ³n SARIMA\", color='red', linestyle='dashed')\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Unidades Vendidas\")\n",
    "plt.legend()\n",
    "plt.title(f\"Forecast SARIMA para CÃ³digo_Articulo {codigo_articulo} en Sucursal {sucursal}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ver Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Asegurar que la columna 'AÃ±o-Mes' estÃ¡ en formato datetime\n",
    "df['AÃ±o-Mes'] = pd.to_datetime(df['AÃ±o-Mes'].astype(str))\n",
    "\n",
    "# Agrupar las ventas mensuales por artÃ­culo y sucursal\n",
    "df_ventas_mensuales = df.groupby(['AÃ±o-Mes', 'Codigo_Articulo', 'Sucursal'])['Unidades'].sum().reset_index()\n",
    "\n",
    "# Crear variables de lag (ventas del mes anterior y mismo mes del aÃ±o anterior)\n",
    "df_ventas_mensuales['lag_1'] = df_ventas_mensuales.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'].shift(1)\n",
    "df_ventas_mensuales['lag_12'] = df_ventas_mensuales.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'].shift(12)\n",
    "\n",
    "# Eliminar filas con valores nulos generados por los lags\n",
    "df_ventas_mensuales.dropna(inplace=True)\n",
    "\n",
    "# Definir variables predictoras (X) y variable objetivo (y)\n",
    "X = df_ventas_mensuales[['lag_1', 'lag_12']]\n",
    "y = df_ventas_mensuales['Unidades']\n",
    "\n",
    "# Dividir en conjunto de entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo de regresiÃ³n lineal\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Error Absoluto Medio (MAE): {mae:.2f}\")\n",
    "print(f\"RaÃ­z del Error CuadrÃ¡tico Medio (RMSE): {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con las predicciones\n",
    "df_forecast = df_ventas_mensuales[['AÃ±o-Mes', 'Codigo_Articulo', 'Sucursal']].copy()\n",
    "df_forecast['Forecast_Unidades'] = modelo.predict(X)  # PredicciÃ³n con el modelo\n",
    "\n",
    "# Merge con el DataFrame original de ventas mensuales\n",
    "df_resultado = df_ventas_mensuales.merge(df_forecast, on=['AÃ±o-Mes', 'Codigo_Articulo', 'Sucursal'], how='left')\n",
    "\n",
    "# Ordenar por fecha y mostrar las primeras filas\n",
    "df_resultado = df_resultado.sort_values(by=['Codigo_Articulo', 'Sucursal', 'AÃ±o-Mes'])\n",
    "\n",
    "# Mostrar resultado\n",
    "import ace_tools_open  as tools\n",
    "tools.display_dataframe_to_user(name=\"Forecast de Ventas\", dataframe=df_resultado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) MEJORAS\n",
    "\n",
    "### âœ… Agregar mÃ¡s variables:\n",
    "\n",
    "* **Precio del producto:** Puede afectar la demanda.\n",
    "* **Promociones/descuentos:** Puede influir en las ventas.\n",
    "* **Tendencias globales:** Se puede agregar una tendencia para mejorar la predicciÃ³n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Asegurar que 'AÃ±o-Mes' estÃ¡ en formato datetime\n",
    "df['AÃ±o-Mes'] = pd.to_datetime(df['AÃ±o-Mes'].astype(str))\n",
    "\n",
    "# Agrupar las ventas mensuales por artÃ­culo y sucursal, sumando unidades vendidas y promediando el precio\n",
    "df_ventas_mensuales = df.groupby(['AÃ±o-Mes', 'Codigo_Articulo', 'Sucursal']).agg(\n",
    "    Unidades=('Unidades', 'sum'),\n",
    "    Precio=('Precio', 'mean')  # Precio promedio del mes\n",
    ").reset_index()\n",
    "\n",
    "# Crear variables de lag (ventas del mes anterior y del mismo mes del aÃ±o anterior)\n",
    "df_ventas_mensuales['lag_1'] = df_ventas_mensuales.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'].shift(1)\n",
    "df_ventas_mensuales['lag_12'] = df_ventas_mensuales.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'].shift(12)\n",
    "\n",
    "# Crear variable de lag del precio del mes anterior\n",
    "df_ventas_mensuales['lag_1_precio'] = df_ventas_mensuales.groupby(['Codigo_Articulo', 'Sucursal'])['Precio'].shift(1)\n",
    "\n",
    "# Crear variable de descuento: Si el precio bajÃ³ mÃ¡s de un 5% respecto al mes anterior\n",
    "df_ventas_mensuales['Descuento'] = (df_ventas_mensuales['lag_1_precio'] > df_ventas_mensuales['Precio'] * 1.05).astype(int)\n",
    "\n",
    "# Agregar una tendencia global (nÃºmero de mes desde el inicio de la serie)\n",
    "df_ventas_mensuales['Tendencia'] = (df_ventas_mensuales['AÃ±o-Mes'] - df_ventas_mensuales['AÃ±o-Mes'].min()).dt.days // 30\n",
    "\n",
    "# Eliminar filas con valores nulos generados por los lags\n",
    "df_ventas_mensuales.dropna(inplace=True)\n",
    "\n",
    "# Definir variables predictoras (X) y variable objetivo (y)\n",
    "X = df_ventas_mensuales[['lag_1', 'lag_12', 'lag_1_precio', 'Descuento', 'Tendencia']]\n",
    "y = df_ventas_mensuales['Unidades']\n",
    "\n",
    "# Dividir en conjunto de entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo de regresiÃ³n lineal\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Error Absoluto Medio (MAE): {mae:.2f}\")\n",
    "print(f\"RaÃ­z del Error CuadrÃ¡tico Medio (RMSE): {rmse:.2f}\")\n",
    "\n",
    "# Mostrar los coeficientes del modelo\n",
    "coeficientes = pd.DataFrame(modelo.coef_, X.columns, columns=['Coeficiente'])\n",
    "print(coeficientes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con las predicciones\n",
    "df_forecast = df_ventas_mensuales[['AÃ±o-Mes', 'Codigo_Articulo', 'Sucursal']].copy()\n",
    "df_forecast['Forecast_Unidades'] = modelo.predict(X)  # PredicciÃ³n con el modelo\n",
    "\n",
    "# Merge con el DataFrame original de ventas mensuales\n",
    "df_resultado = df_ventas_mensuales.merge(df_forecast, on=['AÃ±o-Mes', 'Codigo_Articulo', 'Sucursal'], how='left')\n",
    "\n",
    "# Ordenar por fecha y mostrar las primeras filas\n",
    "df_resultado = df_resultado.sort_values(by=['Codigo_Articulo', 'Sucursal', 'AÃ±o-Mes'])\n",
    "\n",
    "# Mostrar resultado\n",
    "import ace_tools_open  as tools\n",
    "tools.display_dataframe_to_user(name=\"Forecast de Ventas\", dataframe=df_resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Otra Prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) MODELO ML REGRESION LINEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "def create_training_data(df, period_length=30, min_date=None, max_date=None):\n",
    "    \"\"\"\n",
    "    Genera un conjunto de entrenamiento mediante ventanas mÃ³viles.\n",
    "    \n",
    "    Para cada combinaciÃ³n de 'Codigo_Articulo' y 'Sucursal', se calculan:\n",
    "      - 'ventas_last': Ventas acumuladas en los Ãºltimos 'period_length' dÃ­as (ventana actual).\n",
    "      - 'ventas_previous': Ventas acumuladas en el perÃ­odo anterior inmediato (previo a la ventana actual).\n",
    "      - 'ventas_same_year': Ventas acumuladas en el mismo perÃ­odo del aÃ±o anterior.\n",
    "      - 'target': Ventas acumuladas en el perÃ­odo inmediatamente posterior a la ventana actual.\n",
    "    \n",
    "    Se requiere que existan datos suficientes para cubrir cada uno de los perÃ­odos.\n",
    "    \n",
    "    ParÃ¡metros:\n",
    "      - df: DataFrame con los datos histÃ³ricos.\n",
    "      - period_length: NÃºmero de dÃ­as que conforman cada ventana (por defecto 30).\n",
    "      - min_date: Fecha mÃ­nima para considerar la fecha de corte (forecast_date) en el entrenamiento.\n",
    "      - max_date: Fecha mÃ¡xima para la fecha de corte; se recomienda que sea menor o igual a (Fecha mÃ¡xima del df - period_length).\n",
    "    \n",
    "    Retorna:\n",
    "      - training_df: DataFrame con las features y el target para cada ejemplo de entrenamiento.\n",
    "    \"\"\"\n",
    "    # Asegurarse de que la columna 'Fecha' sea de tipo datetime\n",
    "    df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "    \n",
    "    # Definir un rango viable para la fecha de corte (forecast_date)\n",
    "    overall_min_date = df['Fecha'].min() + pd.Timedelta(days=2*period_length) + pd.DateOffset(years=1)\n",
    "    overall_max_date = df['Fecha'].max() - pd.Timedelta(days=period_length)\n",
    "    \n",
    "    if min_date is None:\n",
    "        min_date = overall_min_date\n",
    "    if max_date is None:\n",
    "        max_date = overall_max_date\n",
    "    \n",
    "    training_rows = []\n",
    "    \n",
    "    # Se agrupa la informaciÃ³n por artÃ­culo y sucursal\n",
    "    groups = df.groupby(['Codigo_Articulo', 'Sucursal'])\n",
    "    \n",
    "    for (codigo, sucursal), group in groups:\n",
    "        group = group.sort_values('Fecha')\n",
    "        # Se obtienen las fechas Ãºnicas disponibles en el grupo\n",
    "        fechas_unicas = group['Fecha'].unique()\n",
    "        # Se filtran las fechas que se encuentran en el rango viable para forecast_date\n",
    "        viable_dates = [d for d in fechas_unicas if (d >= min_date) and (d <= max_date)]\n",
    "        \n",
    "        for forecast_date in viable_dates:\n",
    "            # Definir ventanas:\n",
    "            # Ventana actual (Ãºltimos period_length dÃ­as hasta forecast_date)\n",
    "            last_start = forecast_date - pd.Timedelta(days=period_length - 1)\n",
    "            last_end = forecast_date\n",
    "            # Ventana anterior inmediata\n",
    "            previous_start = forecast_date - pd.Timedelta(days=2*period_length)\n",
    "            previous_end = forecast_date - pd.Timedelta(days=period_length)\n",
    "            # Mismo perÃ­odo del aÃ±o anterior\n",
    "            same_year_start = forecast_date - pd.DateOffset(years=1) - pd.Timedelta(days=period_length - 1)\n",
    "            same_year_end = forecast_date - pd.DateOffset(years=1)\n",
    "            # PerÃ­odo objetivo (target) a pronosticar: los period_length dÃ­as siguientes a forecast_date\n",
    "            target_start = forecast_date + pd.Timedelta(days=1)\n",
    "            target_end = forecast_date + pd.Timedelta(days=period_length)\n",
    "            \n",
    "            # Filtrar el grupo segÃºn cada ventana\n",
    "            mask_last = (group['Fecha'] >= last_start) & (group['Fecha'] <= last_end)\n",
    "            mask_previous = (group['Fecha'] >= previous_start) & (group['Fecha'] <= previous_end)\n",
    "            mask_same_year = (group['Fecha'] >= same_year_start) & (group['Fecha'] <= same_year_end)\n",
    "            mask_target = (group['Fecha'] >= target_start) & (group['Fecha'] <= target_end)\n",
    "            \n",
    "            ventas_last = group.loc[mask_last, 'Unidades'].sum()\n",
    "            ventas_previous = group.loc[mask_previous, 'Unidades'].sum()\n",
    "            ventas_same_year = group.loc[mask_same_year, 'Unidades'].sum()\n",
    "            target_sales = group.loc[mask_target, 'Unidades'].sum()\n",
    "            \n",
    "            # Se pueden agregar condiciones para omitir ejemplos sin informaciÃ³n (por ejemplo, si target es nulo)\n",
    "            # En este ejemplo se incluyen todos los casos, asumiendo que ventas nulas representan 0.\n",
    "            training_rows.append({\n",
    "                'Codigo_Articulo': codigo,\n",
    "                'Sucursal': sucursal,\n",
    "                'forecast_date': forecast_date,\n",
    "                'ventas_last': ventas_last,\n",
    "                'ventas_previous': ventas_previous,\n",
    "                'ventas_same_year': ventas_same_year,\n",
    "                'target': target_sales\n",
    "            })\n",
    "    \n",
    "    training_df = pd.DataFrame(training_rows)\n",
    "    return training_df\n",
    "\n",
    "def forecast_linear_regression(df, forecast_date=None, period_length=30, training_min_date=None, training_max_date=None):\n",
    "    \"\"\"\n",
    "    Realiza la predicciÃ³n de la demanda utilizando un modelo de regresiÃ³n lineal.\n",
    "    \n",
    "    Procedimiento:\n",
    "      1. Se crea un conjunto de entrenamiento a partir de los datos histÃ³ricos mediante la funciÃ³n 'create_training_data'.\n",
    "      2. Se entrena un modelo global de regresiÃ³n lineal utilizando como variables independientes:\n",
    "           - ventas_last, ventas_previous, ventas_same_year\n",
    "         y como variable dependiente el target (ventas acumuladas en el perÃ­odo posterior).\n",
    "      3. Para cada combinaciÃ³n de 'Codigo_Articulo' y 'Sucursal', se calculan las features correspondientes al perÃ­odo\n",
    "         de pronÃ³stico definido por 'forecast_date' y se predice la demanda.\n",
    "    \n",
    "    ParÃ¡metros:\n",
    "      - df: DataFrame con la informaciÃ³n histÃ³rica.\n",
    "      - forecast_date: Fecha para la cual se desea pronosticar la demanda. Si no se indica, se toma (Fecha mÃ¡xima - period_length).\n",
    "      - period_length: NÃºmero de dÃ­as que definen cada ventana (por defecto 30).\n",
    "      - training_min_date: Fecha mÃ­nima para incluir ejemplos en el entrenamiento.\n",
    "      - training_max_date: Fecha mÃ¡xima para incluir ejemplos en el entrenamiento.\n",
    "    \n",
    "    Retorna:\n",
    "      - forecast_df: DataFrame con la predicciÃ³n para cada artÃ­culo y sucursal.\n",
    "      - model: Modelo de regresiÃ³n lineal entrenado.\n",
    "      - training_df: Conjunto de entrenamiento utilizado.\n",
    "    \"\"\"\n",
    "    # Asegurarse de que la columna 'Fecha' sea de tipo datetime\n",
    "    df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "    \n",
    "    # Definir la fecha de pronÃ³stico si no se especifica\n",
    "    if forecast_date is None:\n",
    "        forecast_date = df['Fecha'].max() - pd.Timedelta(days=period_length)\n",
    "    else:\n",
    "        forecast_date = pd.to_datetime(forecast_date)\n",
    "    \n",
    "    # Crear el conjunto de entrenamiento\n",
    "    training_df = create_training_data(df, period_length=period_length, min_date=training_min_date, max_date=training_max_date)\n",
    "    \n",
    "    if training_df.empty:\n",
    "        raise ValueError(\"No se pudo generar el conjunto de entrenamiento. Verifique el rango de fechas y la informaciÃ³n disponible.\")\n",
    "    \n",
    "    # Definir las variables independientes (features) y la variable dependiente (target)\n",
    "    features = ['ventas_last', 'ventas_previous', 'ventas_same_year']\n",
    "    X_train = training_df[features]\n",
    "    y_train = training_df['target']\n",
    "    \n",
    "    # Entrenar el modelo de regresiÃ³n lineal\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Para la fecha de pronÃ³stico, se calculan las features para cada combinaciÃ³n de artÃ­culo y sucursal\n",
    "    forecast_rows = []\n",
    "    groups = df.groupby(['Codigo_Articulo', 'Sucursal'])\n",
    "    \n",
    "    for (codigo, sucursal), group in groups:\n",
    "        group = group.sort_values('Fecha')\n",
    "        # Definir las ventanas para la fecha de pronÃ³stico\n",
    "        last_start = forecast_date - pd.Timedelta(days=period_length - 1)\n",
    "        last_end = forecast_date\n",
    "        previous_start = forecast_date - pd.Timedelta(days=2*period_length)\n",
    "        previous_end = forecast_date - pd.Timedelta(days=period_length)\n",
    "        same_year_start = forecast_date - pd.DateOffset(years=1) - pd.Timedelta(days=period_length - 1)\n",
    "        same_year_end = forecast_date - pd.DateOffset(years=1)\n",
    "        \n",
    "        mask_last = (group['Fecha'] >= last_start) & (group['Fecha'] <= last_end)\n",
    "        mask_previous = (group['Fecha'] >= previous_start) & (group['Fecha'] <= previous_end)\n",
    "        mask_same_year = (group['Fecha'] >= same_year_start) & (group['Fecha'] <= same_year_end)\n",
    "        \n",
    "        ventas_last = group.loc[mask_last, 'Unidades'].sum()\n",
    "        ventas_previous = group.loc[mask_previous, 'Unidades'].sum()\n",
    "        ventas_same_year = group.loc[mask_same_year, 'Unidades'].sum()\n",
    "        \n",
    "        # Vector de features para la predicciÃ³n\n",
    "        X_pred = np.array([[ventas_last, ventas_previous, ventas_same_year]])\n",
    "        pred = model.predict(X_pred)[0]\n",
    "        \n",
    "        forecast_rows.append({\n",
    "            'Codigo_Articulo': codigo,\n",
    "            'Sucursal': sucursal,\n",
    "            'forecast': int(round(pred)),\n",
    "            'ventas_last': ventas_last,\n",
    "            'ventas_previous': ventas_previous,\n",
    "            'ventas_same_year': ventas_same_year\n",
    "        })\n",
    "    \n",
    "    forecast_df = pd.DataFrame(forecast_rows)\n",
    "    return forecast_df, model, training_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fechas = pd.date_range(start='2023-01-01', end='2025-02-10', freq='D')\n",
    "np.random.seed(42)\n",
    "\n",
    "#df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define la fecha de pronÃ³stico: por ejemplo, la Ãºltima fecha disponible menos period_length\n",
    "forecast_date = df['Fecha'].max() - pd.Timedelta(days=30)\n",
    "\n",
    "# Se ejecuta el algoritmo de regresiÃ³n lineal para obtener la predicciÃ³n\n",
    "forecast_lr, model, training_data = forecast_linear_regression(\n",
    "    df, \n",
    "    forecast_date=forecast_date, \n",
    "    period_length=30\n",
    "    # Se pueden especificar training_min_date y training_max_date si se desea limitar el conjunto de entrenamiento\n",
    ")\n",
    "\n",
    "print(\"Demanda estimada utilizando el algoritmo de regresiÃ³n lineal:\")\n",
    "print(forecast_lr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EvaluaciÃ³n del modelo en el conjunto de entrenamiento\n",
    "X_train = training_data[['ventas_last', 'ventas_previous', 'ventas_same_year']]\n",
    "y_train = training_data['target']\n",
    "y_pred_train = model.predict(X_train)\n",
    "mae = mean_absolute_error(y_train, y_pred_train)\n",
    "mse = mean_squared_error(y_train, y_pred_train)\n",
    "print(f\"MAE en entrenamiento: {mae:.2f}\")\n",
    "print(f\"MSE en entrenamiento: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  mean_absolute_percentage_error\n",
    "mape = mean_absolute_percentage_error(y_train, y_pred_train)\n",
    "print(f\"MAPE en entrenamiento: {mape:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
