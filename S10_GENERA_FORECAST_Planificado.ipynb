{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S10 - RUTINA INICIAL - Genera FORECAST a partir de estado 10 - PLANIFICADO\n",
    "\n",
    "De acuerdo a los parámetros especificados, recorre los que tengan estado 10 para proceder a realizar el FORECAST.\n",
    "\n",
    "Luego Acutaliza a estado 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUTINA INICIAL - FORECAST\n",
    "\n",
    "1) Leer archivo Solicitudes_Compra\n",
    "2) Leer datos adicionales y id relacionados\n",
    "3) Leer datos adicionales de la T710_Estadis_Reposición\n",
    "4) Generar GRAFICOS\n",
    "5) Actulizar Estado en connexa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Recopilación de Funciones\n",
    "\n",
    "Se compilan los Algoritmos Probados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRERIAS NECESARIAS \n",
    "import base64\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# LIBRERIAS NECESARIAS \n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from dotenv import dotenv_values\n",
    "import psycopg2 as pg2    # Conectores para Postgres\n",
    "import pyodbc  # Conector para SQL Server\n",
    "import time  # Para medir el tiempo de ejecución\n",
    "import getpass  # Para obtener el usuario del sistema operativo\n",
    "import uuid  # Importar la librería uuid\n",
    "# Mostrar el DataFrame resultante\n",
    "import ace_tools_open as tools\n",
    "\n",
    "# Evitar Mensajes Molestos\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category= FutureWarning)\n",
    "\n",
    "secrets = dotenv_values(\".env\")   # Connection String from .env\n",
    "folder = secrets[\"FOLDER_DATOS\"]\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Liberias para Algoritmos\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.holtwinters import Holt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIONES OPTIMIZADA PARA EL PRONOSTICO DE DEMANDA\n",
    "# Trataremos de Estandarizar las salidas y optimizar el proceso\n",
    "# Generaremos datos para regenerar graficos simples al vuelo y grabaremos un gráfico ya precalculado\n",
    "# En esta primera etapa en un blob64, luego en un servidor de archivos con un link.\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "#     DATOS\n",
    "###----------------------------------------------------------------\n",
    "def Open_Connection():\n",
    "    secrets = dotenv_values(\".env\")   # Connection String from .env\n",
    "    conn_str = f'DRIVER={secrets[\"DRIVER2\"]};SERVER={secrets[\"SERVIDOR2\"]};PORT={secrets[\"PUERTO2\"]};DATABASE={secrets[\"BASE2\"]};UID={secrets[\"USUARIO2\"]};PWD={secrets[\"CONTRASENA2\"]}'\n",
    "    # print (conn_str) \n",
    "    try:    \n",
    "        conn = pyodbc.connect(conn_str)\n",
    "        return conn\n",
    "    except:\n",
    "        print('Error en la Conexión')\n",
    "        return None\n",
    "\n",
    "def Open_Diarco_Data():\n",
    "    secrets = dotenv_values(\".env\")   # Cargar credenciales desde .env    \n",
    "    conn_str = f\"dbname={secrets['BASE3']} user={secrets['USUARIO3']} password={secrets['CONTRASENA3']} host={secrets['SERVIDOR3']} port={secrets['PUERTO3']}\"\n",
    "    #print (conn_str)\n",
    "    try:    \n",
    "        conn = pg2.connect(conn_str)\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f'Error en la conexión: {e}')\n",
    "        return None\n",
    "\n",
    "def Open_Conn_Postgres():\n",
    "    secrets = dotenv_values(\".env\")   # Cargar credenciales desde .env    \n",
    "    conn_str = f\"dbname={secrets['BASE4']} user={secrets['USUARIO4']} password={secrets['CONTRASENA4']} host={secrets['SERVIDOR4']} port={secrets['PUERTO4']}\"\n",
    "    try:    \n",
    "        conn = pg2.connect(conn_str)\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f'Error en la conexión: {e}')\n",
    "        return None\n",
    "\n",
    "def Open_Postgres_retry(max_retries=5, wait_seconds=10):\n",
    "    secrets = dotenv_values(\".env\")   # Cargar credenciales desde .env    \n",
    "    conn_str = f\"dbname={secrets['BASE4']} user={secrets['USUARIO4']} password={secrets['CONTRASENA4']} host={secrets['SERVIDOR4']} port={secrets['PUERTO4']}\"\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            conn = pg2.connect(conn_str)\n",
    "            return conn \n",
    "        except Exception as e:\n",
    "            print(f\"Error en la conexión, intento {i+1}/{max_retries}: {e}\")\n",
    "            time.sleep(wait_seconds)\n",
    "    return None  # Retorna None si todos los intentos fallan\n",
    "    \n",
    "def Close_Connection(conn): \n",
    "    conn.close()\n",
    "    return True\n",
    "\n",
    "def generar_datos(id_proveedor, etiqueta, ventana):\n",
    "    secrets = dotenv_values(\".env\")   # Connection String from .env\n",
    "    folder = secrets[\"FOLDER_DATOS\"]\n",
    "    \n",
    "    #  Intento recuperar datos cacheados\n",
    "    try:\n",
    "        data = pd.read_csv(f'{folder}/{etiqueta}.csv')\n",
    "        data['Codigo_Articulo']= data['Codigo_Articulo'].astype(int)\n",
    "        data['Sucursal']= data['Sucursal'].astype(int)\n",
    "        data['Fecha']= pd.to_datetime(data['Fecha'])\n",
    "\n",
    "        articulos = pd.read_csv(f'{folder}/{etiqueta}_articulos.csv')\n",
    "        #articulos.head()\n",
    "        print(f\"-> Datos Recuperados del CACHE: {id_proveedor}, Label: {etiqueta}\")\n",
    "        return data, articulos\n",
    "    except:     \n",
    "        print(f\"-> Generando datos para ID: {id_proveedor}, Label: {etiqueta}\")\n",
    "        # Configuración de conexión\n",
    "        conn = Open_Connection()\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # FILTRA solo PRODUCTOS HABILITADOS y Traer datos de STOCK y PENDIENTES desde PRODUCCIÓN\n",
    "        # ----------------------------------------------------------------\n",
    "        query = f\"\"\"\n",
    "            SELECT A.[C_PROVEEDOR_PRIMARIO]\n",
    "            ,S.[C_ARTICULO]\n",
    "            ,S.[C_SUCU_EMPR]\n",
    "\t\t\t--,R.[C_SUCU_EMPR]\n",
    "\t\t\t--,R.[C_ARTICULO]\n",
    "            ,S.[I_PRECIO_VTA]\n",
    "            ,S.[I_COSTO_ESTADISTICO]\n",
    "            ,S.[Q_FACTOR_VENTA_ESP]\n",
    "            ,S.[Q_FACTOR_VTA_SUCU]\n",
    "            ,S.[M_OFERTA_SUCU]\n",
    "            ,S.[M_HABILITADO_SUCU]\n",
    "            ,A.M_BAJA\n",
    "            --,S.[Q_VTA_DIA_ANT]\n",
    "            --,S.[Q_VTA_ACUM]\n",
    "            --,S.[Q_ULT_ING_STOCK]\n",
    "            --,S.[Q_STOCK_A_ULT_ING]\n",
    "            --,S.[Q_15DIASVTA_A_ULT_ING_STOCK]\n",
    "            --,S.[Q_30DIASVTA_A_ULT_ING_STOCK]\n",
    "            --,S.[Q_BULTOS_PENDIENTE_OC]\n",
    "            --,S.[Q_PESO_PENDIENTE_OC]\n",
    "            --,S.[Q_UNID_PESO_PEND_RECEP_TRANSF]\n",
    "            --,S.[Q_UNID_PESO_VTA_MES_ACTUAL]\n",
    "            ,S.[F_ULTIMA_VTA]\n",
    "            ,S.[Q_VTA_ULTIMOS_15DIAS]\n",
    "            ,S.[Q_VTA_ULTIMOS_30DIAS]\n",
    "            ,S.[Q_TRANSF_PEND]\n",
    "            ,S.[Q_TRANSF_EN_PREP]\n",
    "            --,S.[M_FOLDER]\n",
    "            --,S.[M_ALTA_RENTABILIDAD]\n",
    "            --,S.[Lugar_Abastecimiento]\n",
    "            --,S.[M_COSTO_LOGISTICO]\n",
    "            --,A.[N_ARTICULO]\n",
    "            ,A.[C_FAMILIA]\n",
    "            ,A.[C_RUBRO]\n",
    "\n",
    "            ,R.[Q_VENTA_30_DIAS]\n",
    "            ,R.[Q_VENTA_15_DIAS]\n",
    "            ,R.[Q_VENTA_DOMINGO]\n",
    "            ,R.[Q_VENTA_ESPECIAL_30_DIAS]\n",
    "            ,R.[Q_VENTA_ESPECIAL_15_DIAS]\n",
    "            ,R.[Q_DIAS_CON_STOCK]\n",
    "            ,R.[Q_REPONER]\n",
    "            ,R.[Q_REPONER_INCLUIDO_SOBRE_STOCK]\n",
    "\n",
    "            ,R.[Q_VENTA_DIARIA_NORMAL]\n",
    "            ,R.[Q_DIAS_STOCK]\n",
    "            ,R.[Q_DIAS_SOBRE_STOCK]\n",
    "            ,R.[Q_DIAS_ENTREGA_PROVEEDOR]\n",
    "        \n",
    "        FROM [DIARCOP001].[DiarcoP].[dbo].[T051_ARTICULOS_SUCURSAL] S\n",
    "        LEFT JOIN [DIARCOP001].[DiarcoP].[dbo].[T050_ARTICULOS] A\n",
    "            ON A.[C_ARTICULO] = S.[C_ARTICULO]\n",
    "        LEFT JOIN [DIARCOP001].[DiarcoP].[dbo].[T055_ARTICULOS_PARAM_STOCK] P\n",
    "            ON P.[C_SUCU_EMPR] = S.[C_SUCU_EMPR]\n",
    "            AND P.[C_FAMILIA] =A.[C_FAMILIA]\n",
    "\t\tLEFT JOIN [DIARCOP001].[DiarcoP].[dbo].[T710_ESTADIS_REPOSICION] R\n",
    "\t\t\tON R.[C_ARTICULO] = S.[C_ARTICULO]\n",
    "\t\t\tAND R.[C_SUCU_EMPR] = S.[C_SUCU_EMPR]\n",
    "\n",
    "        WHERE S.[M_HABILITADO_SUCU] = 'S' -- Permitido Reponer\n",
    "            AND A.M_BAJA = 'N'  -- Activo en Maestro Artículos\n",
    "            AND A.[C_PROVEEDOR_PRIMARIO] = {id_proveedor} -- Solo del Proveedor\n",
    "        \n",
    "        ORDER BY S.[C_ARTICULO],S.[C_SUCU_EMPR];\n",
    "        \"\"\"\n",
    "        # Ejecutar la consulta SQL\n",
    "        articulos = pd.read_sql(query, conn)\n",
    "        file_path = f'{folder}/{etiqueta}_Articulos.csv'\n",
    "        articulos['C_PROVEEDOR_PRIMARIO']= articulos['C_PROVEEDOR_PRIMARIO'].astype(int)\n",
    "        articulos['C_ARTICULO']= articulos['C_ARTICULO'].astype(int)\n",
    "        articulos['C_FAMILIA']= articulos['C_FAMILIA'].astype(int)\n",
    "        articulos['C_RUBRO']= articulos['C_RUBRO'].astype(int)\n",
    "            # Convertir a enteros y reemplazar valores nulos por el valor de ventana\n",
    "        articulos['Q_DIAS_STOCK'] = articulos['Q_DIAS_STOCK'].fillna(ventana).astype(int)\n",
    "        articulos['Q_DIAS_SOBRE_STOCK'] = articulos['Q_DIAS_SOBRE_STOCK'].fillna(0).astype(int)\n",
    "        articulos.to_csv(file_path, index=False, encoding='utf-8')        \n",
    "        print(f\"---> Datos de Artículos guardados: {file_path}\")\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # Consulta SQL para obtener las VENTAS de un proveedor específico   \n",
    "        # Reemplazar {proveedor} en la consulta con el ID de la tienda actual\n",
    "        # ----------------------------------------------------------------\n",
    "        query = f\"\"\"\n",
    "        SELECT V.[F_VENTA] as Fecha\n",
    "            ,V.[C_ARTICULO] as Codigo_Articulo\n",
    "            ,V.[C_SUCU_EMPR] as Sucursal\n",
    "            ,V.[I_PRECIO_VENTA] as Precio\n",
    "            ,V.[I_PRECIO_COSTO] as Costo\n",
    "            ,V.[Q_UNIDADES_VENDIDAS] as Unidades\n",
    "            ,V.[C_FAMILIA] as Familia\n",
    "            ,A.[C_RUBRO] as Rubro\n",
    "            ,A.[C_SUBRUBRO_1] as SubRubro\n",
    "            ,LTRIM(RTRIM(REPLACE(REPLACE(REPLACE(A.N_ARTICULO, CHAR(9), ''), CHAR(13), ''), CHAR(10), ''))) as Nombre_Articulo\n",
    "            ,A.[C_CLASIFICACION_COMPRA] as Clasificacion\n",
    "        FROM [DCO-DBCORE-P02].[DiarcoEst].[dbo].[T702_EST_VTAS_POR_ARTICULO] V\n",
    "        LEFT JOIN [DCO-DBCORE-P02].[DiarcoEst].[dbo].[T050_ARTICULOS] A \n",
    "            ON V.C_ARTICULO = A.C_ARTICULO\n",
    "        WHERE A.[C_PROVEEDOR_PRIMARIO] = {id_proveedor} AND V.F_VENTA >= '20210101' AND A.M_BAJA ='N'\n",
    "        ORDER BY V.F_VENTA ;\n",
    "        \"\"\"\n",
    "\n",
    "        # Ejecutar la consulta SQL\n",
    "        demanda = pd.read_sql(query, conn)\n",
    "        \n",
    "        # UNIR Y FILTRAR solo la demanda de los Hartículos VALIDOS.\n",
    "        # Realizar la unión (merge) de los DataFrames por las claves especificadas\n",
    "        data = pd.merge(\n",
    "            articulos,  # DataFrame de artículos\n",
    "            demanda,    # DataFrame de demanda\n",
    "            left_on=['C_ARTICULO', 'C_SUCU_EMPR'],  # Claves en 'articulos'\n",
    "            right_on=['Codigo_Articulo', 'Sucursal'],  # Claves en 'demanda'\n",
    "            how='inner'  # Solo traer los productos que están en 'articulos'\n",
    "        )\n",
    "            \n",
    "        # Guardar los resultados en un archivo CSV con el nombre del Proveedor\n",
    "        # en el  mismo formato que hubiera generado el Query.\n",
    "        # Esto se utilizaría como cache de datos.\n",
    "\n",
    "        file_path = f'{folder}/{etiqueta}.csv'\n",
    "        data['C_ARTICULO']= data['C_ARTICULO'].astype(int)\n",
    "        data['C_SUCU_EMPR']= data['C_SUCU_EMPR'].astype(int)\n",
    "        data['C_FAMILIA']= articulos['C_FAMILIA'].astype(int)\n",
    "        data['C_RUBRO']= articulos['C_RUBRO'].astype(int)\n",
    "        data['Codigo_Articulo']= data['Codigo_Articulo'].astype(int)\n",
    "        data['Sucursal']= data['Sucursal'].astype(int)\n",
    "        data.to_csv(file_path, index=False, encoding='utf-8')\n",
    "        print(f\"---> Datos de Ventas guardados: {file_path}\")  \n",
    "\n",
    "        # Eliminar Columnas Innecesarias\n",
    "        data = data[['Fecha', 'Codigo_Articulo', 'Sucursal', 'Unidades']]\n",
    "        \n",
    "        # Guardar los datos Compactos de VENTAS en un archivo CSV con el nombre del Proveedor y sufijo _Ventas\n",
    "        file_path = f'{folder}/{etiqueta}_Ventas.csv'\n",
    "        data.to_csv(file_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        # Cerrar la conexión después de la iteración\n",
    "        Close_Connection(conn)\n",
    "        return data, articulos\n",
    "\n",
    "def Exportar_Pronostico(df_forecast, proveedor, etiqueta, algoritmo):\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    \n",
    "    # tools.display_dataframe_to_user(name=\"SET de Datos del Proveedor\", dataframe=df_forecast)\n",
    "    # df_forecast.info()\n",
    "    #print(f'-> ** Pronostico Guardado en: {folder}/{etiqueta}_{algoritmo}_Pronostico.csv **')\n",
    "    #df_forecast.to_csv(f'{folder}/{etiqueta}_{algoritmo}_Pronostico.csv', index=False)\n",
    "    \n",
    "    ## GUARDAR TABLA EN POSTGRES\n",
    "    usuario = getpass.getuser()  # Obtiene el usuario del sistema operativo\n",
    "    fecha_actual = datetime.today().strftime('%Y-%m-%d')  # Obtiene la fecha de hoy en formato 'YYYY-MM-DD'\n",
    "    conn = Open_Diarco_Data()\n",
    "    \n",
    "    # Query de inserción\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO public.f_oc_precarga_connexa (\n",
    "        c_proveedor, c_articulo, c_sucu_empr, q_forecast_unidades, f_alta_forecast, c_usuario_forecast, create_date\n",
    "    ) VALUES (%s, %s, %s, %s, %s, %s, %s);\n",
    "    \"\"\"\n",
    "\n",
    "    # Convertir el DataFrame a una lista de tuplas para la inserción en bloque\n",
    "    data_to_insert = [\n",
    "        (proveedor, row['Codigo_Articulo'], row['Sucursal'], row['Forecast'], fecha_actual, usuario, fecha_actual)\n",
    "        for _, row in df_forecast.iterrows()\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.executemany(insert_query, data_to_insert)\n",
    "        conn.commit()\n",
    "        print(f\"✅ Inserción completada: {len(data_to_insert)} registros insertados.\")\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"❌ Error en la inserción: {e}\")\n",
    "    finally:\n",
    "        Close_Connection(conn)\n",
    "        print(\"✅ Conexión cerrada.\")\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "#     ALGORITMOS\n",
    "###----------------------------------------------------------------\n",
    "# ALGO_01 Promedio de Ventas Ponderado \n",
    "###---------------------------------------------------------------- \n",
    "def Calcular_Demanda_ALGO_01(df, id_proveedor, etiqueta, period_length, current_date, factor_last, factor_previous, factor_year):\n",
    "    print('Dentro del Calcular_Demanda_ALGO_01')\n",
    "    print(f'FORECAST control: {id_proveedor} - {etiqueta} - ventana: {period_length} - factores: {factor_last} - {factor_previous} - {factor_year}')\n",
    "    # Definir rangos de fechas para cada período\n",
    "    last_period_start = current_date - pd.Timedelta(days=period_length - 1)\n",
    "    last_period_end = current_date\n",
    "\n",
    "    previous_period_start = current_date - pd.Timedelta(days=2 * period_length - 1)\n",
    "    previous_period_end = current_date - pd.Timedelta(days=period_length)\n",
    "\n",
    "    same_period_last_year_start = current_date - pd.DateOffset(years=1) - pd.Timedelta(days=period_length - 1)\n",
    "    same_period_last_year_end = current_date - pd.DateOffset(years=1)\n",
    "\n",
    "    # Filtrar los datos para cada uno de los períodos\n",
    "    df_last = df[(df['Fecha'] >= last_period_start) & (df['Fecha'] <= last_period_end)]\n",
    "    df_previous = df[(df['Fecha'] >= previous_period_start) & (df['Fecha'] <= previous_period_end)]\n",
    "    df_same_year = df[(df['Fecha'] >= same_period_last_year_start) & (df['Fecha'] <= same_period_last_year_end)]\n",
    "\n",
    "    # Agregar las ventas (unidades) por artículo y sucursal para cada período\n",
    "    sales_last = df_last.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                        .sum().reset_index().rename(columns={'Unidades': 'ventas_last'})\n",
    "    sales_previous = df_previous.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_previous'})\n",
    "    sales_same_year = df_same_year.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_same_year'})\n",
    "\n",
    "    # Unir la información de los tres períodos\n",
    "    df_forecast = pd.merge(sales_last, sales_previous, on=['Codigo_Articulo', 'Sucursal'], how='outer')\n",
    "    df_forecast = pd.merge(df_forecast, sales_same_year, on=['Codigo_Articulo', 'Sucursal'], how='outer')\n",
    "    df_forecast.fillna(0, inplace=True)\n",
    "\n",
    "    # Calcular la demanda estimada como el promedio de las ventas de los tres períodos\n",
    "    df_forecast['Forecast'] = (df_forecast['ventas_last'] * factor_last +\n",
    "                               df_forecast['ventas_previous'] * factor_previous +\n",
    "                               df_forecast['ventas_same_year'] * factor_year) / (factor_year + factor_last + factor_previous)\n",
    "\n",
    "    # Redondear la predicción al entero más cercano  y eliminar los Negativos\n",
    "    df_forecast['Forecast'] = np.ceil(df_forecast['Forecast']).clip(lower=0)\n",
    "    df_forecast['Average'] = round(df_forecast['Forecast'] /period_length ,3)\n",
    "    # Agregar las columnas id_proveedor y ventana\n",
    "    df_forecast['id_proveedor'] = id_proveedor\n",
    "    df_forecast['ventana'] = period_length\n",
    "    df_forecast['algoritmo'] = 'ALGO_01'\n",
    "\n",
    "    # Reordenar las columnas según la especificación\n",
    "    df_forecast = df_forecast[['id_proveedor', 'Codigo_Articulo', 'Sucursal',  'algoritmo', 'ventana', 'Forecast', \n",
    "                            'Average','ventas_last', 'ventas_previous', 'ventas_same_year']]\n",
    "    return df_forecast\n",
    "\n",
    "\n",
    "    # Borrar Columnas Innecesarias\n",
    "    # forecast_df.drop(columns=['ventas_last', 'ventas_previous', 'ventas_same_year'], inplace=True)\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "# ALGO_02 Doble Exponencial -  Modelo Holt (TENDENCIA)\n",
    "###----------------------------------------------------------------\n",
    "def Calcular_Demanda_ALGO_02(df, id_proveedor, etiqueta, ventana, current_date):\n",
    "    print('Dentro del Calcular_Demanda_ALGO_02')\n",
    "    print(f'FORECAST Holt control: {id_proveedor} - {etiqueta} - ventana: {ventana} ')\n",
    "\n",
    "        # Ajustar el modelo Holt-Winters: \n",
    "        # - trend: 'add' para tendencia aditiva\n",
    "        # - seasonal: 'add' para estacionalidad aditiva\n",
    "        # - seasonal_periods: 7 (para estacionalidad semanal)\n",
    "    # Configurar la ventana de pronóstico (por ejemplo, 30 días o 45 días)\n",
    "    #forecast_window = 30  # Cambia a 45 si es necesario\n",
    "    # Lista para almacenar los resultados del forecast\n",
    "    resultados = []\n",
    "    \n",
    "    # Definir rangos de fechas para cada período\n",
    "    last_period_start = current_date - pd.Timedelta(days=ventana - 1)\n",
    "    last_period_end = current_date\n",
    "\n",
    "    previous_period_start = current_date - pd.Timedelta(days=2 * ventana - 1)\n",
    "    previous_period_end = current_date - pd.Timedelta(days=ventana)\n",
    "\n",
    "    same_period_last_year_start = current_date - pd.DateOffset(years=1) - pd.Timedelta(days=ventana - 1)\n",
    "    same_period_last_year_end = current_date - pd.DateOffset(years=1)\n",
    "\n",
    "    # Filtrar los datos para cada uno de los períodos\n",
    "    df_last = df[(df['Fecha'] >= last_period_start) & (df['Fecha'] <= last_period_end)]\n",
    "    df_previous = df[(df['Fecha'] >= previous_period_start) & (df['Fecha'] <= previous_period_end)]\n",
    "    df_same_year = df[(df['Fecha'] >= same_period_last_year_start) & (df['Fecha'] <= same_period_last_year_end)]\n",
    "\n",
    "    # Agregar las ventas (unidades) por artículo y sucursal para cada período\n",
    "    sales_last = df_last.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                        .sum().reset_index().rename(columns={'Unidades': 'ventas_last'})\n",
    "    sales_previous = df_previous.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_previous'})\n",
    "    sales_same_year = df_same_year.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_same_year'})\n",
    "\n",
    "    # Agrupar los datos por 'Codigo_Articulo' y 'Sucursal'\n",
    "    for (codigo, sucursal), grupo in df.groupby(['Codigo_Articulo', 'Sucursal']):\n",
    "        # Ordenar cronológicamente y fijar 'Fecha' como índice\n",
    "        grupo = grupo.set_index('Fecha').sort_index()\n",
    "        \n",
    "        # Resamplear a frecuencia diaria sumando las ventas y rellenando días sin datos\n",
    "        ventas_diarias = grupo['Unidades'].resample('D').sum().fillna(0)\n",
    "        \n",
    "        # Verificar que la serie tenga suficientes datos para ajustar el modelo\n",
    "        if len(ventas_diarias) < 2 * 7:  # por ejemplo, al menos dos ciclos de la estacionalidad semanal\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Ajustar el modelo Holt\n",
    "            # - trend: 'add' para tendencia aditiva\n",
    "            # - seasonal: 'add' para estacionalidad aditiva\n",
    "            # - seasonal_periods: 7 (para estacionalidad semanal)\n",
    "            modelo = Holt(ventas_diarias)\n",
    "            modelo_ajustado = modelo.fit(optimized=True)\n",
    "            \n",
    "            # Realizar el forecast para la ventana definida\n",
    "            pronostico = modelo_ajustado.forecast(ventana)\n",
    "            \n",
    "            # La demanda esperada es la suma de las predicciones diarias en el periodo\n",
    "            forecast_total = pronostico.sum()\n",
    "        except Exception as e:\n",
    "            # Si ocurre algún error en el ajuste, puedes asignar un valor nulo o manejarlo de otra forma\n",
    "            forecast_total = None\n",
    "        \n",
    "        resultados.append({\n",
    "            'Codigo_Articulo': codigo,\n",
    "            'Sucursal': sucursal,\n",
    "            'Forecast': round(forecast_total, 2) if forecast_total is not None else None\n",
    "        })\n",
    "\n",
    "    # Crear el DataFrame final con los resultados del forecast\n",
    "    df_forecast = pd.DataFrame(resultados)\n",
    "    # Redondear la predicción al entero más cercano\n",
    "    df_forecast['Forecast'] = np.ceil(df_forecast['Forecast']).clip(lower=0)\n",
    "    df_forecast['Average'] = round(df_forecast['Forecast'] /ventana ,3)\n",
    "    \n",
    "        # Agregar las columnas id_proveedor y ventana\n",
    "    df_forecast['id_proveedor'] = id_proveedor\n",
    "    df_forecast['ventana'] = ventana\n",
    "    df_forecast['algoritmo'] = 'ALGO_02'\n",
    "    \n",
    "        # Unir las ventas de los períodos con el forecast\n",
    "    df_forecast = pd.merge(df_forecast, sales_last, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_previous, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_same_year, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast.fillna(0, inplace=True)\n",
    "\n",
    "    # Reordenar las columnas según la especificación\n",
    "    df_forecast = df_forecast[['id_proveedor', 'Codigo_Articulo', 'Sucursal', 'algoritmo', 'ventana', 'Forecast', \n",
    "                            'Average', 'ventas_last', 'ventas_previous', 'ventas_same_year']]\n",
    "    \n",
    "    return df_forecast\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "# ALGO_03 Suavizado Exponencial -  Modelo Holt-Winters (TENDENCIA + ESTACIONALIDAD)\n",
    "###----------------------------------------------------------------\n",
    "def Calcular_Demanda_ALGO_03(df, id_proveedor, etiqueta, ventana, current_date, periodos, f2, f3):\n",
    "    print('Dentro del Calcular_Demanda_ALGO_03')\n",
    "    print(f'FORECAST control: {id_proveedor} - {etiqueta} - ventana: {ventana} - factores: Períodos Estacionalidad  {periodos} - Tendencia: {f2} - Estacionalidad: {f3}')\n",
    "\n",
    "        # Ajustar el modelo Holt-Winters: \n",
    "        # - trend: 'add' para tendencia aditiva\n",
    "        # - seasonal: 'add' para estacionalidad aditiva\n",
    "        # - seasonal_periods: 7 (para estacionalidad semanal)\n",
    "    # Configurar la ventana de pronóstico (por ejemplo, 30 días o 45 días)\n",
    "    #forecast_window = 30  # Cambia a 45 si es necesario\n",
    "    # Lista para almacenar los resultados del forecast\n",
    "    resultados = []\n",
    "    \n",
    "    # Definir rangos de fechas para cada período\n",
    "    last_period_start = current_date - pd.Timedelta(days=ventana - 1)\n",
    "    last_period_end = current_date\n",
    "\n",
    "    previous_period_start = current_date - pd.Timedelta(days=2 * ventana - 1)\n",
    "    previous_period_end = current_date - pd.Timedelta(days=ventana)\n",
    "\n",
    "    same_period_last_year_start = current_date - pd.DateOffset(years=1) - pd.Timedelta(days=ventana - 1)\n",
    "    same_period_last_year_end = current_date - pd.DateOffset(years=1)\n",
    "\n",
    "    # Filtrar los datos para cada uno de los períodos\n",
    "    df_last = df[(df['Fecha'] >= last_period_start) & (df['Fecha'] <= last_period_end)]\n",
    "    df_previous = df[(df['Fecha'] >= previous_period_start) & (df['Fecha'] <= previous_period_end)]\n",
    "    df_same_year = df[(df['Fecha'] >= same_period_last_year_start) & (df['Fecha'] <= same_period_last_year_end)]\n",
    "\n",
    "    # Agregar las ventas (unidades) por artículo y sucursal para cada período\n",
    "    sales_last = df_last.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                        .sum().reset_index().rename(columns={'Unidades': 'ventas_last'})\n",
    "    sales_previous = df_previous.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_previous'})\n",
    "    sales_same_year = df_same_year.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_same_year'})\n",
    "    \n",
    "    # Agrupar los datos por 'Codigo_Articulo' y 'Sucursal'\n",
    "    for (codigo, sucursal), grupo in df.groupby(['Codigo_Articulo', 'Sucursal']):\n",
    "        # Ordenar cronológicamente y fijar 'Fecha' como índice\n",
    "        grupo = grupo.set_index('Fecha').sort_index()\n",
    "        \n",
    "        # Resamplear a frecuencia diaria sumando las ventas y rellenando días sin datos\n",
    "        ventas_diarias = grupo['Unidades'].resample('D').sum().fillna(0)\n",
    "        \n",
    "        # Verificar que la serie tenga suficientes datos para ajustar el modelo\n",
    "        if len(ventas_diarias) < 2 * 7:  # por ejemplo, al menos dos ciclos de la estacionalidad semanal\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Ajustar el modelo Holt-Winters: \n",
    "            # - trend: 'add' para tendencia aditiva\n",
    "            # - seasonal: 'add' para estacionalidad aditiva\n",
    "            # - seasonal_periods: 7 (para estacionalidad semanal)\n",
    "            modelo = ExponentialSmoothing(ventas_diarias, trend=f2, seasonal=f3, seasonal_periods=periodos)\n",
    "            modelo_ajustado = modelo.fit(optimized=True)\n",
    "            \n",
    "            # Realizar el forecast para la ventana definida\n",
    "            pronostico = modelo_ajustado.forecast(ventana)\n",
    "            \n",
    "            # La demanda esperada es la suma de las predicciones diarias en el periodo\n",
    "            forecast_total = pronostico.sum()\n",
    "        except Exception as e:\n",
    "            # Si ocurre algún error en el ajuste, puedes asignar un valor nulo o manejarlo de otra forma\n",
    "            forecast_total = None\n",
    "        \n",
    "        resultados.append({\n",
    "            'Codigo_Articulo': codigo,\n",
    "            'Sucursal': sucursal,\n",
    "            'Forecast': round(forecast_total, 2) if forecast_total is not None else None\n",
    "        })\n",
    "\n",
    "    # Crear el DataFrame final con los resultados del forecast\n",
    "    df_forecast = pd.DataFrame(resultados)\n",
    "    # Redondear la predicción al entero más cercano\n",
    "    df_forecast['Forecast'] = np.ceil(df_forecast['Forecast']).clip(lower=0)\n",
    "    df_forecast['Average'] = round(df_forecast['Forecast'] /ventana ,3)\n",
    "    \n",
    "        # Agregar las columnas id_proveedor y ventana\n",
    "    df_forecast['id_proveedor'] = id_proveedor\n",
    "    df_forecast['ventana'] = ventana\n",
    "    df_forecast['algoritmo'] = 'ALGO_03'\n",
    "    \n",
    "        # Unir las ventas de los períodos con el forecast\n",
    "    df_forecast = pd.merge(df_forecast, sales_last, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_previous, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_same_year, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast.fillna(0, inplace=True)\n",
    "\n",
    "    # Reordenar las columnas según la especificación\n",
    "    df_forecast = df_forecast[['id_proveedor', 'Codigo_Articulo', 'Sucursal', 'algoritmo', 'ventana', 'Forecast', \n",
    "                            'Average', 'ventas_last', 'ventas_previous', 'ventas_same_year']]\n",
    "    return df_forecast\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "# ALGO_04 Suavizado Exponencial Simple -  Modelo de Media Movil Exponencial Ponderada (EWMA) x Factor alpha\n",
    "###----------------------------------------------------------------\n",
    "def Calcular_Demanda_ALGO_04(df, id_proveedor, etiqueta, ventana, current_date, alpha):\n",
    "    print('Dentro del Calcular_Demanda_ALGO_04')\n",
    "    print(f'FORECAST control: {id_proveedor} - {etiqueta} - ventana: {ventana} - Fator Alpha: {alpha} ')\n",
    "\n",
    "    # Configurar la ventana de pronóstico (por ejemplo, 30 o 45 días)\n",
    "    #forecast_window = 45  # Puedes cambiarlo a 45 según tus necesidades\n",
    "    # Parámetro de suavizado (alpha); valores cercanos a 1 dan más peso a los datos recientes\n",
    "    #alpha = 0.3\n",
    "\n",
    "    # Lista para almacenar los resultados del forecast\n",
    "    resultados = []\n",
    "    \n",
    "    # Definir rangos de fechas para cada período\n",
    "    last_period_start = current_date - pd.Timedelta(days=ventana - 1)\n",
    "    last_period_end = current_date\n",
    "\n",
    "    previous_period_start = current_date - pd.Timedelta(days=2 * ventana - 1)\n",
    "    previous_period_end = current_date - pd.Timedelta(days=ventana)\n",
    "\n",
    "    same_period_last_year_start = current_date - pd.DateOffset(years=1) - pd.Timedelta(days=ventana - 1)\n",
    "    same_period_last_year_end = current_date - pd.DateOffset(years=1)\n",
    "\n",
    "    # Filtrar los datos para cada uno de los períodos\n",
    "    df_last = df[(df['Fecha'] >= last_period_start) & (df['Fecha'] <= last_period_end)]\n",
    "    df_previous = df[(df['Fecha'] >= previous_period_start) & (df['Fecha'] <= previous_period_end)]\n",
    "    df_same_year = df[(df['Fecha'] >= same_period_last_year_start) & (df['Fecha'] <= same_period_last_year_end)]\n",
    "\n",
    "    # Agregar las ventas (unidades) por artículo y sucursal para cada período\n",
    "    sales_last = df_last.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                        .sum().reset_index().rename(columns={'Unidades': 'ventas_last'})\n",
    "    sales_previous = df_previous.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_previous'})\n",
    "    sales_same_year = df_same_year.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_same_year'})\n",
    "    \n",
    "    # Agrupar los datos por 'Codigo_Articulo' y 'Sucursal'\n",
    "    for (codigo, sucursal), grupo in df.groupby(['Codigo_Articulo', 'Sucursal']):\n",
    "        # Ordenar cronológicamente y fijar 'Fecha' como índice\n",
    "        grupo = grupo.set_index('Fecha').sort_index()\n",
    "        \n",
    "        # Resamplear a frecuencia diaria sumando las ventas y rellenando días sin datos\n",
    "        ventas_diarias = grupo['Unidades'].resample('D').sum().fillna(0)\n",
    "        \n",
    "        # Calcular el suavizado exponencial (EWMA) sobre la serie de ventas diarias\n",
    "        ewma_series = ventas_diarias.ewm(alpha=alpha, adjust=False).mean()\n",
    "        \n",
    "        # Tomamos el último valor suavizado como forecast diario\n",
    "        ultimo_ewma = ewma_series.iloc[-1]\n",
    "        \n",
    "        # El pronóstico total para la ventana definida es el pronóstico diario multiplicado por la cantidad de días\n",
    "        forecast_total = ultimo_ewma * ventana\n",
    "        \n",
    "        resultados.append({\n",
    "            'Codigo_Articulo': codigo,\n",
    "            'Sucursal': sucursal,\n",
    "            'Forecast': round(forecast_total, 2),\n",
    "            'Average': round(ultimo_ewma, 3)\n",
    "        })\n",
    "\n",
    "    # Crear el DataFrame final con los resultados\n",
    "    df_forecast = pd.DataFrame(resultados)\n",
    "    # Redondear la predicción al entero más cercano y evitar negativos\n",
    "    df_forecast['Forecast'] = np.ceil(df_forecast['Forecast']).clip(lower=0)\n",
    "    # Agregar las columnas id_proveedor y ventana\n",
    "    df_forecast['id_proveedor'] = id_proveedor\n",
    "    df_forecast['ventana'] = ventana\n",
    "    df_forecast['algoritmo'] = 'ALGO_04'\n",
    "    \n",
    "        # Unir las ventas de los períodos con el forecast\n",
    "    df_forecast = pd.merge(df_forecast, sales_last, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_previous, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_same_year, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast.fillna(0, inplace=True)\n",
    "    \n",
    "    # Reordenar las columnas según la especificación\n",
    "    df_forecast = df_forecast[['id_proveedor', 'Codigo_Articulo', 'Sucursal', 'algoritmo', 'ventana', 'Forecast', \n",
    "                            'Average', 'ventas_last', 'ventas_previous', 'ventas_same_year']]\n",
    "    return df_forecast\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "# ALGO_05 Promedio de Venta SIMPLE (PVS) (Metodo Actual que usan los Compradores)\n",
    "###----------------------------------------------------------------\n",
    "def Calcular_Demanda_ALGO_05(df, id_proveedor, etiqueta, ventana, current_date):\n",
    "    # Lista para almacenar los resultados del pronóstico\n",
    "    resultados = []\n",
    "\n",
    "    # Definir rangos de fechas para cada período\n",
    "    last_period_start = current_date - pd.Timedelta(days=ventana - 1)\n",
    "    last_period_end = current_date\n",
    "\n",
    "    previous_period_start = current_date - pd.Timedelta(days=2 * ventana - 1)\n",
    "    previous_period_end = current_date - pd.Timedelta(days=ventana)\n",
    "\n",
    "    same_period_last_year_start = current_date - pd.DateOffset(years=1) - pd.Timedelta(days=ventana - 1)\n",
    "    same_period_last_year_end = current_date - pd.DateOffset(years=1)\n",
    "\n",
    "    # Filtrar los datos para cada uno de los períodos\n",
    "    df_last = df[(df['Fecha'] >= last_period_start) & (df['Fecha'] <= last_period_end)]\n",
    "    df_previous = df[(df['Fecha'] >= previous_period_start) & (df['Fecha'] <= previous_period_end)]\n",
    "    df_same_year = df[(df['Fecha'] >= same_period_last_year_start) & (df['Fecha'] <= same_period_last_year_end)]\n",
    "\n",
    "    # Agregar las ventas (unidades) por artículo y sucursal para cada período\n",
    "    sales_last = df_last.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                        .sum().reset_index().rename(columns={'Unidades': 'ventas_last'})\n",
    "    sales_previous = df_previous.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_previous'})\n",
    "    sales_same_year = df_same_year.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_same_year'})\n",
    "    \n",
    "    # Agrupar los datos por 'Codigo_Articulo' y 'Sucursal'\n",
    "    for (codigo, sucursal), grupo in df.groupby(['Codigo_Articulo', 'Sucursal']):\n",
    "        # Establecer 'Fecha' como índice y ordenar los datos\n",
    "        grupo = grupo.set_index('Fecha').sort_index()\n",
    "        \n",
    "        # Resamplear a diario sumando las ventas\n",
    "        ventas_diarias = grupo['Unidades'].resample('D').sum().fillna(0)\n",
    "        \n",
    "        # Seleccionar un periodo reciente para calcular la media; por ejemplo, los últimos 30 días\n",
    "        # Si hay menos de 30 días de datos, se utiliza el periodo disponible\n",
    "        ventas_recientes = ventas_diarias[-30:]\n",
    "        media_diaria = ventas_recientes.mean()\n",
    "        \n",
    "        # Pronosticar la demanda para el periodo de reposición\n",
    "        pronostico = media_diaria * ventana\n",
    "        \n",
    "        resultados.append({\n",
    "            'Codigo_Articulo': codigo,\n",
    "            'Sucursal': sucursal,\n",
    "            'Forecast': round(pronostico, 2),\n",
    "            'Average': round(media_diaria, 3)\n",
    "        })\n",
    "\n",
    "    # Crear el DataFrame de pronósticos\n",
    "    df_forecast = pd.DataFrame(resultados)\n",
    "        # Redondear la predicción al entero más cercano\n",
    "    df_forecast['Forecast'] = np.ceil(df_forecast['Forecast']).clip(lower=0)\n",
    "    df_forecast['Average'] = round(df_forecast['Forecast'] /ventana ,3)\n",
    "    \n",
    "    # Agregar las columnas id_proveedor y ventana\n",
    "    df_forecast['id_proveedor'] = id_proveedor\n",
    "    df_forecast['ventana'] = ventana\n",
    "    df_forecast['algoritmo'] = 'ALGO_05'\n",
    "    \n",
    "    # Unir las ventas de los períodos con el forecast\n",
    "    df_forecast = pd.merge(df_forecast, sales_last, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_previous, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_same_year, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast.fillna(0, inplace=True)\n",
    "    \n",
    "    # Reordenar las columnas según la especificación\n",
    "    df_forecast = df_forecast[['id_proveedor', 'Codigo_Articulo', 'Sucursal', 'algoritmo', 'ventana', 'Forecast', \n",
    "                            'Average', 'ventas_last', 'ventas_previous', 'ventas_same_year']]\n",
    "    \n",
    "    return df_forecast\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "# ALGO_06 Demanda Agrupada Semanal -  Modelo Holt (TENDENCIA)\n",
    "###----------------------------------------------------------------\n",
    "def Calcular_Demanda_ALGO_06(df, id_proveedor, etiqueta, ventana, current_date):\n",
    "    print('Dentro del Calcular_Demanda_ALGO_06')\n",
    "    print(f'FORECAST Holt control: {id_proveedor} - {etiqueta} - ventana: {ventana}')\n",
    "\n",
    "    # Convertir ventana a entero y calcular forecast_window en semanas\n",
    "    try:\n",
    "        forecast_window = int(ventana) // 7  # Semanas de forecast\n",
    "        if forecast_window < 4:\n",
    "            raise ValueError(\"La ventana debe ser al menos 28 días para calcular el forecast.\")\n",
    "    except ValueError:\n",
    "        print(\"Error: La ventana proporcionada no es válida.\")\n",
    "        return pd.DataFrame()  # Retornar DataFrame vacío en caso de error\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    # Definir rangos de fechas para cada período\n",
    "    last_period_start = current_date - pd.Timedelta(days=ventana - 1)\n",
    "    last_period_end = current_date\n",
    "\n",
    "    previous_period_start = current_date - pd.Timedelta(days=2 * ventana - 1)\n",
    "    previous_period_end = current_date - pd.Timedelta(days=ventana)\n",
    "\n",
    "    same_period_last_year_start = current_date - pd.DateOffset(years=1) - pd.Timedelta(days=ventana - 1)\n",
    "    same_period_last_year_end = current_date - pd.DateOffset(years=1)\n",
    "\n",
    "    # Filtrar los datos para cada uno de los períodos\n",
    "    df_last = df[(df['Fecha'] >= last_period_start) & (df['Fecha'] <= last_period_end)]\n",
    "    df_previous = df[(df['Fecha'] >= previous_period_start) & (df['Fecha'] <= previous_period_end)]\n",
    "    df_same_year = df[(df['Fecha'] >= same_period_last_year_start) & (df['Fecha'] <= same_period_last_year_end)]\n",
    "\n",
    "    # Agregar las ventas (unidades) por artículo y sucursal para cada período\n",
    "    sales_last = df_last.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                        .sum().reset_index().rename(columns={'Unidades': 'ventas_last'})\n",
    "    sales_previous = df_previous.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_previous'})\n",
    "    sales_same_year = df_same_year.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_same_year'})\n",
    "\n",
    "    # Agrupar los datos por 'Codigo_Articulo' y 'Sucursal'\n",
    "    for (codigo, sucursal), grupo in df.groupby(['Codigo_Articulo', 'Sucursal']):\n",
    "        # Ordenar cronológicamente y fijar 'Fecha' como índice\n",
    "        grupo = grupo.set_index('Fecha').sort_index()\n",
    "\n",
    "        # Resamplear a frecuencia semanal sumando las ventas y rellenando semanas sin datos\n",
    "        ventas_semanales = grupo['Unidades'].resample('W').sum().fillna(0)\n",
    "\n",
    "        # Verificar que la serie tenga suficientes datos para ajustar el modelo\n",
    "        if len(ventas_semanales) < 4:  # Se requieren al menos 4 semanas de datos\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Ajustar el modelo Holt con tendencia aditiva\n",
    "            modelo = Holt(ventas_semanales)\n",
    "            modelo_ajustado = modelo.fit(smoothing_level=0.8, smoothing_slope=0.2)  \n",
    "            \n",
    "            # Realizar el forecast para la ventana definida (semanal)\n",
    "            pronostico = modelo_ajustado.forecast(forecast_window)\n",
    "            \n",
    "            # La demanda esperada es la suma de las predicciones semanales en el periodo\n",
    "            forecast_total = pronostico.sum()\n",
    "        except Exception as e:\n",
    "            print(f\"Error al ajustar el modelo para Código_Articulo {codigo} y Sucursal {sucursal}: {e}\")\n",
    "            forecast_total = 0  # En caso de error, asignar 0\n",
    "\n",
    "        # Agregar resultado al listado\n",
    "        resultados.append({\n",
    "            'Codigo_Articulo': codigo,\n",
    "            'Sucursal': sucursal,\n",
    "            'Forecast': round(forecast_total, 2)\n",
    "        })\n",
    "\n",
    "    # Crear el DataFrame final con los resultados del forecast\n",
    "    df_forecast = pd.DataFrame(resultados)\n",
    "\n",
    "    # Verificar si el DataFrame tiene datos antes de continuar\n",
    "    if df_forecast.empty:\n",
    "        print(\"Advertencia: No se generaron pronósticos debido a falta de datos.\")\n",
    "        return df_forecast  # Retornar DataFrame vacío\n",
    "\n",
    "    # Redondear la predicción al entero más cercano y evitar valores negativos\n",
    "    df_forecast['Forecast'] = np.ceil(df_forecast['Forecast']).clip(lower=0)\n",
    "    \n",
    "    # Calcular el promedio semanal si forecast_window > 0\n",
    "    df_forecast['Average'] = round(df_forecast['Forecast'] / ventana, 3) if ventana > 0 else 0\n",
    "\n",
    "    # Unir las ventas de los períodos con el forecast\n",
    "    df_forecast = pd.merge(df_forecast, sales_last, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_previous, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_same_year, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "\n",
    "    # Rellenar valores NaN con 0\n",
    "    df_forecast.fillna(0, inplace=True)\n",
    "\n",
    "    # Agregar las columnas id_proveedor, ventana y algoritmo\n",
    "    df_forecast['id_proveedor'] = id_proveedor\n",
    "    df_forecast['ventana'] = ventana\n",
    "    df_forecast['algoritmo'] = 'ALGO_06'\n",
    "\n",
    "    # Reordenar las columnas según la especificación\n",
    "    df_forecast = df_forecast[['id_proveedor', 'Codigo_Articulo', 'Sucursal', 'algoritmo', 'ventana', 'Forecast', \n",
    "                            'Average', 'ventas_last', 'ventas_previous', 'ventas_same_year']]\n",
    "\n",
    "    return df_forecast\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "# RUTINAS DE PROCESAMIENTO DE ALGORITMOS\n",
    "###----------------------------------------------------------------  \n",
    "\n",
    "def Procesar_ALGO_06(data, proveedor, etiqueta, ventana, fecha):\n",
    "    df_forecast = Calcular_Demanda_ALGO_06(data, proveedor, etiqueta, ventana, fecha)    # Exportar el resultado a un CSV para su posterior procesamiento\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    df_forecast.to_csv(f'{folder}/{etiqueta}_ALGO_06_Solicitudes_Compra.csv', index=False)\n",
    "    print(f'-> ** Solicitudes Exportadas: {etiqueta}_ALGO_06_Solicitudes_Compra.csv *** : ventana: {ventana}  - {fecha}')\n",
    "    \n",
    "    # df_validacion = Calcular_Demanda_Extendida_ALGO_06(data, ventana, proveedor, etiqueta, fecha)\n",
    "    # df_validacion['Codigo_Articulo']= df_validacion['Codigo_Articulo'].astype(int)\n",
    "    # df_validacion['Sucursal']= df_validacion['Sucursal'].astype(int)\n",
    "    # df_validacion.to_csv(f'{folder}/{etiqueta}_ALGO_06_Datos_Validacion.csv', index=False)\n",
    "    # print(f'-> ** Validación Exportada: {etiqueta}_ALGO_06_Datos_Validacion.csv *** : ventana: {ventana}  - {fecha}')\n",
    "    \n",
    "    Exportar_Pronostico(df_forecast, proveedor, etiqueta, 'ALGO_06')  # Impactar Datos en la Interface   \n",
    "    return\n",
    "    \n",
    "def Procesar_ALGO_05(data, proveedor, etiqueta, ventana, fecha):\n",
    "    \n",
    "        # Determinar la fecha base\n",
    "    if fecha is None:\n",
    "        fecha = data['Fecha'].max()  # Se toma la última fecha en los datos\n",
    "    else:\n",
    "        fecha = pd.to_datetime(fecha)  # Se asegura que sea un objeto datetime\n",
    "        \n",
    "    df_forecast = Calcular_Demanda_ALGO_05(data, proveedor, etiqueta, ventana, fecha)    # Exportar el resultado a un CSV para su posterior procesamiento\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    df_forecast.to_csv(f'{folder}/{etiqueta}_ALGO_05_Solicitudes_Compra.csv', index=False)\n",
    "    \n",
    "    Exportar_Pronostico(df_forecast, proveedor, etiqueta, 'ALGO_05')  # Impactar Datos en la Interface   \n",
    "    return\n",
    "\n",
    "def Procesar_ALGO_04(data, proveedor, etiqueta, ventana, current_date=None,  alfa=None):    \n",
    "    # Asignar valores por defecto si los factores no están definidos\n",
    "    alfa = 0.5 if alfa is None else float(alfa)\n",
    "    \n",
    "    # Determinar la fecha base\n",
    "    if current_date is None:\n",
    "        current_date = data['Fecha'].max()  # Se toma la última fecha en los datos\n",
    "    else:\n",
    "        current_date = pd.to_datetime(current_date)  # Se asegura que sea un objeto datetime\n",
    "    \n",
    "    # Parámetro de suavizado (alpha); valores cercanos a 1 dan más peso a los datos recientes\n",
    "    \n",
    "    print(f'--> ALGO_04 ventana {ventana} - fecha {current_date} Peso de los Factores Utilizados: Factor Alpha: {alfa} ')\n",
    "        \n",
    "    df_forecast = Calcular_Demanda_ALGO_04(data, proveedor, etiqueta, ventana, current_date, alfa)\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    df_forecast.to_csv(f'{folder}/{etiqueta}_ALGO_04_Solicitudes_Compra.csv', index=False)   # Exportar el resultado a un CSV para su posterior procesamiento\n",
    "    \n",
    "    Exportar_Pronostico(df_forecast, proveedor, etiqueta, 'ALGO_04')  # Impactar Datos en la Interface        \n",
    "    return\n",
    "\n",
    "def Procesar_ALGO_03(data, proveedor, etiqueta, ventana, fecha, periodos=None, f2=None, f3=None):    \n",
    "    # Asignar valores por defecto si los factores no están definidos\n",
    "    periodos = 7 if periodos is None else int(periodos)\n",
    "    f2 = 'add' if f2 is None else str(f2)  # Incorporar Efecto Estacionalidad\n",
    "    f3 = 'add' if f3 is None else str(f3) # Informprar Efecto Tendencia Anual\n",
    "    \n",
    "    print(f'--> ALGO_03 ventana {ventana} - Factores Utilizados: Períodos: {periodos} estacionalidad: {f2} tendencia: {f3}')\n",
    "        \n",
    "    df_forecast = Calcular_Demanda_ALGO_03(data, proveedor, etiqueta, ventana, fecha, periodos, f2, f3)\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    df_forecast.to_csv(f'{folder}/{etiqueta}_ALGO_03_Solicitudes_Compra.csv', index=False)   # Exportar el resultado a un CSV para su posterior procesamiento\n",
    "    print(f'-> ** Datos Exportados: {etiqueta}_ALGO_03_Solicitudes_Compra.csv *** : ventana: {ventana}  - {fecha}')\n",
    "    Exportar_Pronostico(df_forecast, proveedor, etiqueta, 'ALGO_03')  # Impactar Datos en la Interface        \n",
    "    return\n",
    "\n",
    "def Procesar_ALGO_02(data, proveedor, etiqueta, ventana, fecha):    \n",
    "    print(f'--> ALGO_02 ventana {ventana} - Holt - No usa Factores')\n",
    "        \n",
    "    df_forecast = Calcular_Demanda_ALGO_02(data, proveedor, etiqueta, ventana, fecha)\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    df_forecast.to_csv(f'{folder}/{etiqueta}_ALGO_02_Solicitudes_Compra.csv', index=False)   # Exportar el resultado a un CSV para su posterior procesamiento\n",
    "    print(f'-> ** Datos Exportados: {etiqueta}_ALGO_02_Solicitudes_Compra.csv *** : ventana: {ventana}  - {fecha}')\n",
    "    Exportar_Pronostico(df_forecast, proveedor, etiqueta, 'ALGO_02')  # Impactar Datos en la Interface        \n",
    "    return\n",
    "\n",
    "def Procesar_ALGO_01(data, proveedor, etiqueta, ventana, fecha, factor_last=None, factor_previous=None, factor_year=None):    \n",
    "    # Asignar valores por defecto si los factores no están definidos\n",
    "    factor_last = 77 if factor_last is None else int(factor_last)\n",
    "    factor_previous = 22 if factor_previous is None else int(factor_previous)\n",
    "    factor_year = 11 if factor_year is None else int(factor_year)\n",
    "\n",
    "    print(f'--> ALGO_01 ventana {ventana} - Peso de los Factores Utilizados: último: {factor_last} previo: {factor_previous} año anterior: {factor_year}')\n",
    "        \n",
    "    df_forecast = Calcular_Demanda_ALGO_01(data, proveedor, etiqueta, ventana, fecha, factor_last, factor_previous, factor_year)\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    df_forecast.to_csv(f'{folder}/{etiqueta}_ALGO_01_Solicitudes_Compra.csv', index=False)   # Exportar el resultado a un CSV para su posterior procesamiento\n",
    "    \n",
    "    Exportar_Pronostico(df_forecast, proveedor, etiqueta, 'ALGO_01')  # Impactar Datos en la Interface        \n",
    "    return\n",
    "\n",
    "# RUTINA PRINCIPAL para obtener el pronóstico\n",
    "def get_forecast( id_proveedor, lbl_proveedor, period_lengh=30, algorithm='basic', f1=None, f2=None, f3=None, current_date=None ):\n",
    "    \"\"\"\n",
    "    Genera la predicción de demanda según el algoritmo seleccionado.\n",
    "\n",
    "    Parámetros:\n",
    "    - id_proveedor: ID del proveedor.\n",
    "    - lbl_proveedor: Etiqueta del proveedor.\n",
    "    - period_lengh: Número de días del período a analizar (por defecto 30).\n",
    "    - algorithm: Algoritmo a utilizar.\n",
    "    - current_date: Fecha de referencia; si es None, se toma la fecha máxima de los datos.\n",
    "    - factores de ponderación: F1, F2, F3  (No importa en que unidades estén, luego los hace relativos al total del peso)\n",
    "\n",
    "    Retorna:\n",
    "    - Un DataFrame con las predicciones.\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Dentro del get_forecast')\n",
    "    print(f'FORECAST control: {id_proveedor} - {lbl_proveedor} - ventana: {period_lengh} - {algorithm} factores: {f1} - {f2} - {f3}')\n",
    "    # Generar los datos de entrada\n",
    "    data, articulos = generar_datos(id_proveedor, lbl_proveedor, period_lengh)\n",
    "\n",
    "        # Determinar la fecha base\n",
    "    if current_date is None:\n",
    "        current_date = data['Fecha'].max()  # Se toma la última fecha en los datos\n",
    "    else:\n",
    "        current_date = pd.to_datetime(current_date)  # Se asegura que sea un objeto datetime\n",
    "    print(f'Fecha actual {current_date}')\n",
    "    \n",
    "\n",
    "    # Selección del algoritmo de predicción\n",
    "    match algorithm:\n",
    "        case 'ALGO_01':\n",
    "            return Procesar_ALGO_01(data, id_proveedor, lbl_proveedor, period_lengh, current_date, f1, f2, f3)  # Promedio Ponderado x 3 Factores\n",
    "        case 'ALGO_02':\n",
    "            return Procesar_ALGO_02(data, id_proveedor, lbl_proveedor, period_lengh, current_date) # Doble Exponencial - Modelo Holt (Tendencia)\n",
    "        case 'ALGO_03':\n",
    "            return Procesar_ALGO_03(data, id_proveedor, lbl_proveedor, period_lengh, current_date, f1, f2, f3) # Triple Exponencial Holt-WInter (Tendencia + Estacionalidad) (periodos, add, add)\n",
    "        case 'ALGO_04':\n",
    "            return Procesar_ALGO_04(data, id_proveedor, lbl_proveedor, period_lengh, current_date, f1) # EWMA con Factor alpha\n",
    "        case 'ALGO_05':\n",
    "            return Procesar_ALGO_05(data, id_proveedor, lbl_proveedor, period_lengh, current_date) # Promedio Venta Simple en Ventana\n",
    "        case 'ALGO_06':\n",
    "            return Procesar_ALGO_06(data, id_proveedor, lbl_proveedor, period_lengh, current_date) # Tendencias Ventas Semanales\n",
    "        case _:\n",
    "            raise ValueError(f\"Error: El algoritmo '{algorithm}' no está implementado.\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3. Operaciones CRUD para spl_supply_forecast_execution\n",
    "# -----------------------------------------------------------\n",
    "def get_execution(execution_id):\n",
    "    conn = Open_Conn_Postgres()\n",
    "    if conn is None:\n",
    "        return None\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        query = \"\"\"\n",
    "            SELECT id, description, name, \"timestamp\", supply_forecast_model_id, \n",
    "                ext_supplier_code, supplier_id, supply_forecast_execution_status_id\n",
    "            FROM public.spl_supply_forecast_execution\n",
    "            WHERE id = %s\n",
    "        \"\"\"\n",
    "        cur.execute(query, (execution_id,))\n",
    "        row = cur.fetchone()\n",
    "        cur.close()\n",
    "        if row:\n",
    "            return {\n",
    "                \"id\": row[0],\n",
    "                \"description\": row[1],\n",
    "                \"name\": row[2],\n",
    "                \"timestamp\": row[3],\n",
    "                \"supply_forecast_model_id\": row[4],\n",
    "                \"ext_supplier_code\": row[5],\n",
    "                \"supplier_id\": row[6],\n",
    "                \"supply_forecast_execution_status_id\": row[7]\n",
    "            }\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error en get_execution: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        Close_Connection(conn)\n",
    "\n",
    "def update_execution(execution_id, **kwargs):\n",
    "    if not kwargs:\n",
    "        print(\"No hay valores para actualizar\")\n",
    "        return None\n",
    "\n",
    "    conn = Open_Conn_Postgres()\n",
    "    if conn is None:\n",
    "        return None\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        set_clause = \", \".join([f\"{key} = %s\" for key in kwargs.keys()])\n",
    "        values = list(kwargs.values())\n",
    "        values.append(execution_id)\n",
    "\n",
    "        query = f\"\"\"\n",
    "            UPDATE public.spl_supply_forecast_execution\n",
    "            SET {set_clause}\n",
    "            WHERE id = %s\n",
    "        \"\"\"\n",
    "        cur.execute(query, tuple(values))\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        return get_execution(execution_id)  # Retorna la ejecución actualizada\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error en update_execution: {e}\")\n",
    "        conn.rollback()\n",
    "        return None\n",
    "    finally:\n",
    "        Close_Connection(conn)\n",
    "\n",
    "def get_excecution_excecute_by_status(status):\n",
    "    if not status:\n",
    "        print(\"No hay estados para filtrar\")\n",
    "        return None\n",
    "    \n",
    "    conn = Open_Conn_Postgres()\n",
    "    if conn is None:\n",
    "        return None\n",
    "    try:\n",
    "        query = f\"\"\"\n",
    "            SELECT \n",
    "                a.id, \n",
    "                a.description, \n",
    "                a.name, \n",
    "\t\t\t\tm.method,\n",
    "                a.\"timestamp\", \n",
    "                a.supply_forecast_model_id, \n",
    "                a.ext_supplier_code, \n",
    "                a.graphic, \n",
    "                a.monthly_net_margin_in_millions, \n",
    "                a.monthly_purchases_in_millions, \n",
    "                a.monthly_sales_in_millions, \n",
    "                a.sotck_days AS stock_days,  -- Posible corrección\n",
    "                a.sotck_days_colors AS stock_days_colors, -- Posible corrección\n",
    "                a.supplier_id, \n",
    "                a.supply_forecast_execution_status_id,\n",
    "                b.supply_forecast_execution_schedule_id AS forecast_execution_schedule_id, \n",
    "                b.id AS forecast_execution_execute_id\n",
    "            FROM public.spl_supply_forecast_execution a\n",
    "            LEFT JOIN public.spl_supply_forecast_execution_execute b\n",
    "                ON b.supply_forecast_execution_id = a.id\n",
    "\t\t\tLEFT JOIN public.spl_supply_forecast_model m\n",
    "\t\t\t\tON a.supply_forecast_model_id= m.id\n",
    "            WHERE a.supply_forecast_execution_status_id = {status};\n",
    "        \"\"\"\n",
    "        # Ejecutar la consulta SQL\n",
    "        fexsts = pd.read_sql(query, conn)\n",
    "        return fexsts\n",
    "    except Exception as e:\n",
    "        print(f\"Error en get_excecution_status: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        Close_Connection(conn) \n",
    "\n",
    "\n",
    "def get_execution_parameter(supply_forecast_model_id, execution_id):\n",
    "    conn = Open_Postgres_retry()\n",
    "    if conn is None:\n",
    "        return None\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        query = \"\"\"\n",
    "            SELECT \n",
    "                mp.name, \n",
    "                mp.data_type, \n",
    "                mp.default_value, \n",
    "                ep.value, \n",
    "                mp.id,  \n",
    "                mp.supply_forecast_model_id, \n",
    "                ep.supply_forecast_execution_id\n",
    "            FROM public.spl_supply_forecast_model_parameter mp\t\n",
    "            LEFT JOIN public.spl_supply_forecast_execution_parameter ep\n",
    "                ON ep.supply_forecast_model_parameter_id = mp.id\n",
    "            WHERE mp.supply_forecast_model_id = %s\n",
    "                AND ep.supply_forecast_execution_id = %s\n",
    "        \"\"\"\n",
    "\n",
    "        # Ejecutar la consulta de manera segura\n",
    "        cur.execute(query, (supply_forecast_model_id, execution_id))\n",
    "\n",
    "        # Obtener los resultados\n",
    "        result = cur.fetchall()\n",
    "\n",
    "        # Convertir los resultados a un DataFrame de pandas\n",
    "        columns = [\"name\", \"data_type\", \"default_value\", \"value\", \"id\", \"supply_forecast_model_id\", \"supply_forecast_execution_id\"]\n",
    "        df_parameters = pd.DataFrame(result, columns=columns)\n",
    "\n",
    "        cur.close()\n",
    "        return df_parameters\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error en get_execution_parameter: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        Close_Connection(conn)\n",
    "\n",
    "# Final del MODULO FUNCIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OBTNER LISTA PENDIENTE DE EJECUCIÓN CON ESTADO 10\n",
    "# -------------------- RUTINA PRINCIPAL --------------------\n",
    "\n",
    "# Leer Dataframe de FORECAST EXECUTION LISTOS PARA IMPORTAR A CONNEXA (DE 10 A 20)\n",
    "fes = get_excecution_excecute_by_status(10)\n",
    "\n",
    "for index, row in fes[fes[\"supply_forecast_execution_status_id\"] == 10].iterrows():\n",
    "    algoritmo = row[\"name\"]\n",
    "    name = algoritmo.split('_ALGO')[0]\n",
    "    method = row[\"method\"]\n",
    "    execution_id = row[\"id\"]\n",
    "    id_proveedor = row[\"ext_supplier_code\"]\n",
    "    forecast_execution_execute_id = row[\"forecast_execution_execute_id\"]\n",
    "    supplier_id = row[\"supplier_id\"]\n",
    "    supply_forecast_model_id = row[\"supply_forecast_model_id\"]\n",
    "\n",
    "    print(f\"Algoritmo: {method}  - Name: {name}  id: Proveedor {id_proveedor}\")\n",
    "    print(f\"exceution_id: {execution_id} model_id: {supply_forecast_model_id} ----------------------------------------------------\")\n",
    "\n",
    "    try:\n",
    "        # Leer Parámetros de Ejecución\n",
    "        df_params = get_execution_parameter(supply_forecast_model_id, execution_id)\n",
    "        \n",
    "        # Mostrar los datos\n",
    "        tools.display_dataframe_to_user(name=\"Parámetros de Ejecución\", dataframe=df_params)\n",
    "        \n",
    "        # Convertir df_params a un diccionario para acceder dinámicamente\n",
    "        param_dict = df_params.set_index('name')['value'].to_dict() if df_params is not None and not df_params.empty else {}\n",
    "\n",
    "        # Extraer valores de forma segura, asignando un valor por defecto si no existe el parámetro\n",
    "        try:\n",
    "            ventana = int(float(param_dict.get('1_Window', 30)))  # Convierte a float primero, luego a int (por si viene como '30.0')\n",
    "        except (ValueError, TypeError):\n",
    "            ventana = 30  # Valor por defecto si falla la conversión\n",
    "        \n",
    "        f1 = param_dict.get('f1', None)  # Si no está 'f1', asigna None\n",
    "        f2 = param_dict.get('f2', None)  # Si no está 'f2', asigna None\n",
    "        f3 = param_dict.get('f3', None)  # Si no está 'f3', asigna None\n",
    "\n",
    "        print(f'Parametros extraídos: ventana={ventana}, f1={f1}, f2={f2}, f3={f3}')        \n",
    "        print(f'Procesando: {id_proveedor} - {name} - ventana: {ventana} - {method} factores: {f1} - {f2} - {f3}')\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # Procesar el pronóstico según el algoritmo seleccionado\n",
    "        # ----------------------------------------------------------------\n",
    "        print('   --> Actualizado Estado a 15 Iniciando la Ejecución')\n",
    "        update_execution(\n",
    "            execution_id,\n",
    "            supply_forecast_execution_status_id=15\n",
    "        )\n",
    "\n",
    "        print(f\"✅ Estado actualizado a 15 para {execution_id}\")\n",
    "        get_forecast(id_proveedor, name, ventana, method, f1, f2, f3)    \n",
    "        \n",
    "        # Actualizar en base de datos\n",
    "        update_execution(\n",
    "            execution_id,\n",
    "            supply_forecast_execution_status_id=20\n",
    "        )        \n",
    "        print('------------------------------------------------------------------')\n",
    "        print('   --> Ejecución Finalizada')\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(f\"❌ Error procesando {name}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
