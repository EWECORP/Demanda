{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S10 - RUTINA INICIAL - Genera FORECAST a partir de estado 10 - PLANIFICADO\n",
    "\n",
    "De acuerdo a los par√°metros especificados, recorre los que tengan estado 10 para proceder a realizar el FORECAST.\n",
    "\n",
    "Luego Acutaliza a estado 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUTINA INICIAL - FORECAST\n",
    "\n",
    "1) Leer archivo Solicitudes_Compra\n",
    "2) Leer datos adicionales y id relacionados\n",
    "3) Leer datos adicionales de la T710_Estadis_Reposici√≥n\n",
    "4) Generar GRAFICOS\n",
    "5) Actulizar Estado en connexa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Recopilaci√≥n de Funciones\n",
    "\n",
    "Se compilan los Algoritmos Probados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRERIAS NECESARIAS \n",
    "import base64\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# LIBRERIAS NECESARIAS \n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from dotenv import dotenv_values\n",
    "import psycopg2 as pg2    # Conectores para Postgres\n",
    "import pyodbc  # Conector para SQL Server\n",
    "import time  # Para medir el tiempo de ejecuci√≥n\n",
    "import getpass  # Para obtener el usuario del sistema operativo\n",
    "import uuid  # Importar la librer√≠a uuid\n",
    "# Mostrar el DataFrame resultante\n",
    "import ace_tools_open as tools\n",
    "\n",
    "# Evitar Mensajes Molestos\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category= FutureWarning)\n",
    "\n",
    "secrets = dotenv_values(\".env\")   # Connection String from .env\n",
    "folder = secrets[\"FOLDER_DATOS\"]\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Liberias para Algoritmos\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.holtwinters import Holt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo importa lo necesario desde el m√≥dulo de funciones\n",
    "from funciones_forecast import (\n",
    "    get_forecast,\n",
    "    generar_datos,\n",
    "    Procesar_ALGO_01,\n",
    "    Procesar_ALGO_02,\n",
    "    Procesar_ALGO_03,\n",
    "    Procesar_ALGO_04,\n",
    "    Procesar_ALGO_05,\n",
    "    Procesar_ALGO_06,    \n",
    "    generar_datos,    \n",
    "    get_execution_execute_by_status,\n",
    "    get_full_parameters,\n",
    "    update_execution,\n",
    "    update_execution_execute\n",
    ")\n",
    "\n",
    "# FUNCIONES LOCALES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUTINAS EXPORTADAS A FUNCIONES_FORECAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generar_datos(id_proveedor, etiqueta, ventana):\n",
    "    secrets = dotenv_values(\".env\")   # Connection String from .env\n",
    "    folder = secrets[\"FOLDER_DATOS\"]\n",
    "    \n",
    "    #  Intento recuperar datos cacheados\n",
    "    try:\n",
    "        data = pd.read_csv(f'{folder}/{etiqueta}.csv')\n",
    "        data['Codigo_Articulo']= data['Codigo_Articulo'].astype(int)\n",
    "        data['Sucursal']= data['Sucursal'].astype(int)\n",
    "        data['Fecha']= pd.to_datetime(data['Fecha'])\n",
    "\n",
    "        articulos = pd.read_csv(f'{folder}/{etiqueta}_articulos.csv')\n",
    "        #articulos.head()\n",
    "        print(f\"-> Datos Recuperados del CACHE: {id_proveedor}, Label: {etiqueta}\")\n",
    "        return data, articulos\n",
    "    except:     \n",
    "        print(f\"-> Generando datos para ID: {id_proveedor}, Label: {etiqueta}\")\n",
    "        # Configuraci√≥n de conexi√≥n\n",
    "        conn = Open_Connection()\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # FILTRA solo PRODUCTOS HABILITADOS y Traer datos de STOCK y PENDIENTES desde PRODUCCI√ìN\n",
    "        # ----------------------------------------------------------------\n",
    "        query = f\"\"\"\n",
    "        SELECT A.[C_PROVEEDOR_PRIMARIO]\n",
    "            ,S.[C_ARTICULO]\n",
    "            ,S.[C_SUCU_EMPR]\n",
    "            ,S.[I_PRECIO_VTA]\n",
    "            ,S.[I_COSTO_ESTADISTICO]\n",
    "            ,S.[Q_FACTOR_VTA_SUCU]\n",
    "            ,S.[Q_BULTOS_PENDIENTE_OC]-- OJO esto est√° en BULTOS DIARCO\n",
    "            ,S.[Q_PESO_PENDIENTE_OC]\n",
    "            ,S.[Q_UNID_PESO_PEND_RECEP_TRANSF]\n",
    "            ,ST.Q_UNID_ARTICULO AS Q_STOCK_UNIDADES-- Stock Cierre Dia Anterior\n",
    "            ,ST.Q_PESO_ARTICULO AS Q_STOCK_PESO\n",
    "            ,S.[M_OFERTA_SUCU]\n",
    "            ,S.[M_HABILITADO_SUCU]\n",
    "            ,S.[M_FOLDER]\n",
    "            ,A.M_BAJA  --- Puede no ser necesaria al hacer inner\n",
    "            --,S.[Q_UNID_PESO_VTA_MES_ACTUAL]\n",
    "            ,S.[F_ULTIMA_VTA]\n",
    "            ,S.[Q_VTA_ULTIMOS_15DIAS]-- OJO esto est√° en BULTOS DIARCO\n",
    "            ,S.[Q_VTA_ULTIMOS_30DIAS]-- OJO esto est√° en BULTOS DIARCO\n",
    "            ,S.[Q_TRANSF_PEND]-- OJO esto est√° en BULTOS DIARCO\n",
    "            ,S.[Q_TRANSF_EN_PREP]-- OJO esto est√° en BULTOS DIARCO\n",
    "            --,A.[N_ARTICULO]\n",
    "            ,A.[C_FAMILIA]\n",
    "            ,A.[C_RUBRO]\n",
    "            ,A.[C_CLASIFICACION_COMPRA] -- ojo nombre erroneo en la contratabla\n",
    "            ,(R.[Q_VENTA_30_DIAS] + R.[Q_VENTA_15_DIAS]) AS Q_VENTA_ACUM_30 -- OJO esto est√° en BULTOS DIARCO\n",
    "            ,R.[Q_DIAS_CON_STOCK] -- Cantidad de dias para promediar venta diaria\n",
    "            ,R.[Q_REPONER] -- OJO esto est√° en BULTOS DIARCO\n",
    "            ,R.[Q_REPONER_INCLUIDO_SOBRE_STOCK]-- OJO esto est√° en BULTOS DIARCO (Venta Promedio * Comprar Para + Lead Time - STOCK - PEND, OC)\n",
    "                --- Ojo la venta promerio excluye  las oferta para no alterar el promedio\n",
    "            ,R.[Q_VENTA_DIARIA_NORMAL]-- OJO esto est√° en BULTOS DIARCO\n",
    "            ,R.[Q_DIAS_STOCK]\n",
    "            ,R.[Q_DIAS_SOBRE_STOCK]\n",
    "            ,R.[Q_DIAS_ENTREGA_PROVEEDOR]\n",
    "                \n",
    "        FROM [DIARCOP001].[DiarcoP].[dbo].[T051_ARTICULOS_SUCURSAL] S\n",
    "        INNER JOIN [DIARCOP001].[DiarcoP].[dbo].[T050_ARTICULOS] A\n",
    "            ON A.[C_ARTICULO] = S.[C_ARTICULO]\n",
    "        LEFT JOIN [DIARCOP001].[DiarcoP].[dbo].[T060_STOCK] ST\n",
    "            ON ST.C_ARTICULO = S.[C_ARTICULO] \n",
    "            AND ST.C_SUCU_EMPR = S.[C_SUCU_EMPR]\n",
    "        LEFT JOIN [DIARCOP001].[DiarcoP].[dbo].[T055_ARTICULOS_PARAM_STOCK] P\n",
    "            ON P.[C_SUCU_EMPR] = S.[C_SUCU_EMPR]\n",
    "            AND P.[C_FAMILIA] = A.[C_FAMILIA]\n",
    "            AND P.[C_RUBRO] = A.[C_RUBRO]\n",
    "            AND P.[C_CLAISIFICACION_COMPRA] = A.[C_CLASIFICACION_COMPRA]  -- ojo nombre erroneo\n",
    "        AND P.[C_FAMILIA] =A.[C_FAMILIA]\n",
    "        LEFT JOIN [DIARCOP001].[DiarcoP].[dbo].[T710_ESTADIS_REPOSICION] R\n",
    "            ON R.[C_ARTICULO] = S.[C_ARTICULO]\n",
    "            AND R.[C_SUCU_EMPR] = S.[C_SUCU_EMPR]\n",
    "\n",
    "        WHERE S.[M_HABILITADO_SUCU] = 'S' -- Permitido Reponer\n",
    "            AND A.M_BAJA = 'N'  -- Activo en Maestro Art√≠culos\n",
    "            AND A.[C_PROVEEDOR_PRIMARIO] = {id_proveedor} -- Solo del Proveedor\n",
    "        \n",
    "        ORDER BY S.[C_ARTICULO],S.[C_SUCU_EMPR];\n",
    "        \"\"\"\n",
    "        # Ejecutar la consulta SQL\n",
    "        articulos = pd.read_sql(query, conn)\n",
    "        file_path = f'{folder}/{etiqueta}_Articulos.csv'\n",
    "        articulos['C_PROVEEDOR_PRIMARIO']= articulos['C_PROVEEDOR_PRIMARIO'].astype(int)\n",
    "        articulos['C_ARTICULO']= articulos['C_ARTICULO'].astype(int)\n",
    "        articulos['C_FAMILIA']= articulos['C_FAMILIA'].astype(int)\n",
    "        articulos['C_RUBRO']= articulos['C_RUBRO'].astype(int)\n",
    "            # Convertir a enteros y reemplazar valores nulos por el valor de ventana\n",
    "        articulos['Q_DIAS_STOCK'] = articulos['Q_DIAS_STOCK'].fillna(ventana).astype(int)\n",
    "        articulos['Q_DIAS_SOBRE_STOCK'] = articulos['Q_DIAS_SOBRE_STOCK'].fillna(0).astype(int)\n",
    "        articulos.to_csv(file_path, index=False, encoding='utf-8')        \n",
    "        print(f\"---> Datos de Art√≠culos guardados: {file_path}\")\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # Consulta SQL para obtener las VENTAS de un proveedor espec√≠fico   \n",
    "        # Reemplazar {proveedor} en la consulta con el ID de la tienda actual\n",
    "        # ----------------------------------------------------------------\n",
    "        query = f\"\"\"\n",
    "        SELECT V.[F_VENTA] as Fecha\n",
    "            ,V.[C_ARTICULO] as Codigo_Articulo\n",
    "            ,V.[C_SUCU_EMPR] as Sucursal\n",
    "            ,V.[I_PRECIO_VENTA] as Precio\n",
    "            ,V.[I_PRECIO_COSTO] as Costo\n",
    "            ,V.[Q_UNIDADES_VENDIDAS] as Unidades\n",
    "            ,V.[C_FAMILIA] as Familia\n",
    "            ,A.[C_RUBRO] as Rubro\n",
    "            ,A.[C_SUBRUBRO_1] as SubRubro\n",
    "            ,LTRIM(RTRIM(REPLACE(REPLACE(REPLACE(A.N_ARTICULO, CHAR(9), ''), CHAR(13), ''), CHAR(10), ''))) as Nombre_Articulo\n",
    "            ,A.[C_CLASIFICACION_COMPRA] as Clasificacion\n",
    "        FROM [DCO-DBCORE-P02].[DiarcoEst].[dbo].[T702_EST_VTAS_POR_ARTICULO] V\n",
    "        LEFT JOIN [DCO-DBCORE-P02].[DiarcoEst].[dbo].[T050_ARTICULOS] A \n",
    "            ON V.C_ARTICULO = A.C_ARTICULO\n",
    "        WHERE A.[C_PROVEEDOR_PRIMARIO] = {id_proveedor} AND V.F_VENTA >= '20210101' AND A.M_BAJA ='N'\n",
    "        ORDER BY V.F_VENTA ;\n",
    "        \"\"\"\n",
    "\n",
    "        # Ejecutar la consulta SQL\n",
    "        demanda = pd.read_sql(query, conn)\n",
    "        \n",
    "        # UNIR Y FILTRAR solo la demanda de los Hart√≠culos VALIDOS.\n",
    "        # Realizar la uni√≥n (merge) de los DataFrames por las claves especificadas\n",
    "        data = pd.merge(\n",
    "            articulos,  # DataFrame de art√≠culos\n",
    "            demanda,    # DataFrame de demanda\n",
    "            left_on=['C_ARTICULO', 'C_SUCU_EMPR'],  # Claves en 'articulos'\n",
    "            right_on=['Codigo_Articulo', 'Sucursal'],  # Claves en 'demanda'\n",
    "            how='inner'  # Solo traer los productos que est√°n en 'articulos'\n",
    "        )\n",
    "            \n",
    "        # Guardar los resultados en un archivo CSV con el nombre del Proveedor\n",
    "        # en el  mismo formato que hubiera generado el Query.\n",
    "        # Esto se utilizar√≠a como cache de datos.\n",
    "\n",
    "        file_path = f'{folder}/{etiqueta}.csv'\n",
    "        data['C_ARTICULO']= data['C_ARTICULO'].astype(int)\n",
    "        data['C_SUCU_EMPR']= data['C_SUCU_EMPR'].astype(int)\n",
    "        data['C_FAMILIA']= articulos['C_FAMILIA'].astype(int)\n",
    "        data['C_RUBRO']= articulos['C_RUBRO'].astype(int)\n",
    "        data['Codigo_Articulo']= data['Codigo_Articulo'].astype(int)\n",
    "        data['Sucursal']= data['Sucursal'].astype(int)\n",
    "        data.to_csv(file_path, index=False, encoding='utf-8')\n",
    "        print(f\"---> Datos de RECUPERACI√ìN guardados: {file_path}\")  \n",
    "\n",
    "        # Eliminar Columnas Innecesarias\n",
    "        data = data[['Fecha', 'Codigo_Articulo', 'Sucursal', 'Unidades']]\n",
    "        \n",
    "        # Guardar los datos Compactos de VENTAS en un archivo CSV con el nombre del Proveedor y sufijo _Ventas\n",
    "        file_path = f'{folder}/{etiqueta}_Ventas.csv'\n",
    "        data.to_csv(file_path, index=False, encoding='utf-8')\n",
    "        print(f\"---> Datos de Ventas guardados: {file_path}\")  \n",
    "        \n",
    "        # Cerrar la conexi√≥n despu√©s de la iteraci√≥n\n",
    "        Close_Connection(conn)\n",
    "        return data, articulos\n",
    "    \n",
    "def obtener_datos_stock(id_proveedor, etiqueta):\n",
    "    secrets = dotenv_values(\".env\")   # Connection String from .env\n",
    "    folder = secrets[\"FOLDER_DATOS\"]\n",
    "    \n",
    "    #  Intento recuperar datos cacheados\n",
    "    try:         \n",
    "        print(f\"-> Generando datos para ID: {id_proveedor}, Label: {etiqueta}\")\n",
    "        # Configuraci√≥n de conexi√≥n\n",
    "        conn = Open_Connection()\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # FILTRA solo PRODUCTOS HABILITADOS y Traer datos de STOCK y PENDIENTES desde PRODUCCI√ìN\n",
    "        # ----------------------------------------------------------------\n",
    "        query = f\"\"\"              \n",
    "        SELECT A.[C_PROVEEDOR_PRIMARIO] as Codigo_Proveedor\n",
    "            ,S.[C_ARTICULO] as Codigo_Articulo\n",
    "            ,S.[C_SUCU_EMPR] as Codigo_Sucursal\n",
    "            ,S.[I_PRECIO_VTA] as Precio_Venta\n",
    "            ,S.[I_COSTO_ESTADISTICO] as Precio_Costo\n",
    "            ,S.[Q_FACTOR_VTA_SUCU] as Factor_Venta\n",
    "            ,ST.Q_UNID_ARTICULO + ST.Q_PESO_ARTICULO AS Stock_Unidades-- Stock Cierre Dia Anterior\n",
    "            ,(R.[Q_VENTA_30_DIAS] + R.[Q_VENTA_15_DIAS]) * S.[Q_FACTOR_VTA_SUCU] AS Venta_Unidades_30_Dias -- OJO convertida desde BULTOS DIARCO\n",
    "                    \n",
    "            ,(ST.Q_UNID_ARTICULO + ST.Q_PESO_ARTICULO)* S.[I_COSTO_ESTADISTICO] AS Stock_Valorizado-- Stock Cierre Dia Anterior\n",
    "            ,(R.[Q_VENTA_30_DIAS] + R.[Q_VENTA_15_DIAS]) * S.[Q_FACTOR_VTA_SUCU] * S.[I_COSTO_ESTADISTICO] AS Venta_Valorizada\n",
    "\n",
    "            ,ROUND(((ST.Q_UNID_ARTICULO + ST.Q_PESO_ARTICULO)* S.[I_COSTO_ESTADISTICO]) / \t\n",
    "                ((R.[Q_VENTA_30_DIAS] + R.[Q_VENTA_15_DIAS]+0.0001) * S.[Q_FACTOR_VTA_SUCU] * S.[I_COSTO_ESTADISTICO] ),0) * 30\n",
    "                AS Dias_Stock\n",
    "                    \n",
    "            ,S.[F_ULTIMA_VTA]\n",
    "            ,S.[Q_VTA_ULTIMOS_15DIAS] * S.[Q_FACTOR_VTA_SUCU] AS VENTA_UNIDADES_1Q -- OJO esto est√° en BULTOS DIARCO\n",
    "            ,S.[Q_VTA_ULTIMOS_30DIAS] * S.[Q_FACTOR_VTA_SUCU] AS VENTA_UNIDADES_2Q -- OJO esto est√° en BULTOS DIARCO\n",
    "                \n",
    "        FROM [DIARCOP001].[DiarcoP].[dbo].[T051_ARTICULOS_SUCURSAL] S\n",
    "        INNER JOIN [DIARCOP001].[DiarcoP].[dbo].[T050_ARTICULOS] A\n",
    "            ON A.[C_ARTICULO] = S.[C_ARTICULO]\n",
    "        LEFT JOIN [DIARCOP001].[DiarcoP].[dbo].[T060_STOCK] ST\n",
    "            ON ST.C_ARTICULO = S.[C_ARTICULO] \n",
    "            AND ST.C_SUCU_EMPR = S.[C_SUCU_EMPR]\n",
    "        LEFT JOIN [DIARCOP001].[DiarcoP].[dbo].[T710_ESTADIS_REPOSICION] R\n",
    "            ON R.[C_ARTICULO] = S.[C_ARTICULO]\n",
    "            AND R.[C_SUCU_EMPR] = S.[C_SUCU_EMPR]\n",
    "\n",
    "        WHERE S.[M_HABILITADO_SUCU] = 'S' -- Permitido Reponer\n",
    "            AND A.M_BAJA = 'N'  -- Activo en Maestro Art√≠culos\n",
    "            AND A.[C_PROVEEDOR_PRIMARIO] = {id_proveedor} -- Solo del Proveedor\n",
    "                        \n",
    "        ORDER BY S.[C_ARTICULO],S.[C_SUCU_EMPR];\n",
    "        \"\"\"\n",
    "        # Ejecutar la consulta SQL\n",
    "        df_stock = pd.read_sql(query, conn)\n",
    "        file_path = f'{folder}/{etiqueta}_Stock.csv'\n",
    "        df_stock['Codigo_Proveedor']= df_stock['Codigo_Proveedor'].astype(int)\n",
    "        df_stock['Codigo_Articulo']= df_stock['Codigo_Articulo'].astype(int)\n",
    "        df_stock['Codigo_Sucursal']= df_stock['Codigo_Sucursal'].astype(int)\n",
    "        df_stock.fillna(0, inplace= True)\n",
    "        # df_stock.to_csv(file_path, index=False, encoding='utf-8')        \n",
    "        print(f\"---> Datos de STOCK guardados: {file_path}\")\n",
    "        return df_stock\n",
    "    except Exception as e:\n",
    "        print(f\"Error en get_execution: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        Close_Connection(conn)\n",
    "\n",
    "def obtener_demora_oc(id_proveedor, etiqueta):\n",
    "    secrets = dotenv_values(\".env\")   # Connection String from .env\n",
    "    folder = secrets[\"FOLDER_DATOS\"]\n",
    "    \n",
    "    #  Intento recuperar datos cacheados\n",
    "    try:         \n",
    "        print(f\"-> Generando datos para ID: {id_proveedor}, Label: {etiqueta}\")\n",
    "        # Configuraci√≥n de conexi√≥n\n",
    "        conn = Open_Connection()\n",
    "        # ----------------------------------------------------------------\n",
    "        # FILTRA solo PRODUCTOS HABILITADOS y Traer datos de STOCK y PENDIENTES desde PRODUCCI√ìN\n",
    "        # ----------------------------------------------------------------\n",
    "        query = f\"\"\"              \n",
    "        SELECT  [C_OC]\n",
    "            ,[U_PREFIJO_OC]\n",
    "            ,[U_SUFIJO_OC]      \n",
    "            ,[U_DIAS_LIMITE_ENTREGA]\n",
    "            , DATEADD(DAY, [U_DIAS_LIMITE_ENTREGA], [F_ENTREGA]) as FECHA_LIMITE\n",
    "            , DATEDIFF (DAY, DATEADD(DAY, [U_DIAS_LIMITE_ENTREGA], [F_ENTREGA]), GETDATE()) as Demora\n",
    "            ,[C_PROVEEDOR] as Codigo_Proveedor\n",
    "            ,[C_SUCU_COMPRA] as Codigo_Sucursal\n",
    "            ,[C_SUCU_DESTINO]\n",
    "            ,[C_SUCU_DESTINO_ALT]\n",
    "            ,[C_SITUAC]\n",
    "            ,[F_SITUAC]\n",
    "            ,[F_ALTA_SIST]\n",
    "            ,[F_EMISION]\n",
    "            ,[F_ENTREGA]    \n",
    "            ,[C_USUARIO_OPERADOR]    \n",
    "            \n",
    "        FROM [DIARCOP001].[DiarcoP].[dbo].[T080_OC_CABE]  \n",
    "        WHERE [C_SITUAC] = 1\n",
    "        AND C_PROVEEDOR = {id_proveedor} \n",
    "        AND DATEADD(DAY, [U_DIAS_LIMITE_ENTREGA], [F_ENTREGA]) < GETDATE();\n",
    "        \"\"\"\n",
    "        # Ejecutar la consulta SQL\n",
    "        df_demoras = pd.read_sql(query, conn)\n",
    "        df_demoras['Codigo_Proveedor']= df_demoras['Codigo_Proveedor'].astype(int)\n",
    "        df_demoras['Codigo_Sucursal']= df_demoras['Codigo_Sucursal'].astype(int)\n",
    "        df_demoras['Demora']= df_demoras['Demora'].astype(int)\n",
    "        df_demoras.fillna(0, inplace= True)         \n",
    "        print(f\"---> Datos de OC DEMORADAS Recuperados: {etiqueta}\")\n",
    "        return df_demoras\n",
    "    except Exception as e:\n",
    "        print(f\"Error en get_execution: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        Close_Connection(conn)\n",
    "\n",
    "def Exportar_Pronostico(df_forecast, proveedor, etiqueta, algoritmo):\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    \n",
    "    # tools.display_dataframe_to_user(name=\"SET de Datos del Proveedor\", dataframe=df_forecast)\n",
    "    # df_forecast.info()\n",
    "    #print(f'-> ** Pronostico Guardado en: {folder}/{etiqueta}_{algoritmo}_Pronostico.csv **')\n",
    "    #df_forecast.to_csv(f'{folder}/{etiqueta}_{algoritmo}_Pronostico.csv', index=False)\n",
    "    \n",
    "    ## GUARDAR TABLA EN POSTGRES\n",
    "    usuario = getpass.getuser()  # Obtiene el usuario del sistema operativo\n",
    "    fecha_actual = datetime.today().strftime('%Y-%m-%d')  # Obtiene la fecha de hoy en formato 'YYYY-MM-DD'\n",
    "    conn = Open_Diarco_Data()\n",
    "    \n",
    "    # Query de inserci√≥n\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO public.f_oc_precarga_connexa (\n",
    "        c_proveedor, c_articulo, c_sucu_empr, q_forecast_unidades, f_alta_forecast, c_usuario_forecast, create_date\n",
    "    ) VALUES (%s, %s, %s, %s, %s, %s, %s);\n",
    "    \"\"\"\n",
    "\n",
    "    # Convertir el DataFrame a una lista de tuplas para la inserci√≥n en bloque\n",
    "    data_to_insert = [\n",
    "        (proveedor, row['Codigo_Articulo'], row['Sucursal'], row['Forecast'], fecha_actual, usuario, fecha_actual)\n",
    "        for _, row in df_forecast.iterrows()\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.executemany(insert_query, data_to_insert)\n",
    "        conn.commit()\n",
    "        print(f\"‚úÖ Inserci√≥n completada: {len(data_to_insert)} registros insertados.\")\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"‚ùå Error en la inserci√≥n: {e}\")\n",
    "    finally:\n",
    "        Close_Connection(conn)\n",
    "        print(\"‚úÖ Conexi√≥n cerrada.\")\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "#     ALGORITMOS\n",
    "###----------------------------------------------------------------\n",
    "# ALGO_01 Promedio de Ventas Ponderado \n",
    "###---------------------------------------------------------------- \n",
    "def Calcular_Demanda_ALGO_01(df, id_proveedor, etiqueta, period_length, current_date, factor_last, factor_previous, factor_year):\n",
    "    print('Dentro del Calcular_Demanda_ALGO_01')\n",
    "    print(f'FORECAST control: {id_proveedor} - {etiqueta} - ventana: {period_length} - factores: {factor_last} - {factor_previous} - {factor_year}')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Convertir Par√°metros a INT o FLOAT\n",
    "    period_length = int(period_length)  # Asegurarse de que sea un entero\n",
    "    factor_last = float(factor_last)\n",
    "    factor_previous = float(factor_previous)\n",
    "    factor_year = float(factor_year)\n",
    "    # Convertir la columna 'Fecha' a tipo datetime si no lo est√°\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['Fecha']):\n",
    "        df['Fecha'] = pd.to_datetime(df['Fecha'], errors='coerce')\n",
    "        df.dropna(subset=['Fecha'], inplace=True)  # Eliminar filas con fechas inv√°lidas\n",
    "        \n",
    "    \n",
    "    # Definir rangos de fechas para cada per√≠odo\n",
    "    last_period_start = current_date - pd.Timedelta(days=period_length - 1)\n",
    "    last_period_end = current_date\n",
    "\n",
    "    previous_period_start = current_date - pd.Timedelta(days=2 * period_length - 1)\n",
    "    previous_period_end = current_date - pd.Timedelta(days=period_length)\n",
    "\n",
    "    same_period_last_year_start = current_date - pd.DateOffset(years=1) - pd.Timedelta(days=period_length - 1)\n",
    "    same_period_last_year_end = current_date - pd.DateOffset(years=1)\n",
    "\n",
    "    # Filtrar los datos para cada uno de los per√≠odos\n",
    "    df_last = df[(df['Fecha'] >= last_period_start) & (df['Fecha'] <= last_period_end)]\n",
    "    df_previous = df[(df['Fecha'] >= previous_period_start) & (df['Fecha'] <= previous_period_end)]\n",
    "    df_same_year = df[(df['Fecha'] >= same_period_last_year_start) & (df['Fecha'] <= same_period_last_year_end)]\n",
    "\n",
    "    # Agregar las ventas (unidades) por art√≠culo y sucursal para cada per√≠odo\n",
    "    sales_last = df_last.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                        .sum().reset_index().rename(columns={'Unidades': 'ventas_last'})\n",
    "    sales_previous = df_previous.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_previous'})\n",
    "    sales_same_year = df_same_year.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_same_year'})\n",
    "\n",
    "    # Unir la informaci√≥n de los tres per√≠odos\n",
    "    df_forecast = pd.merge(sales_last, sales_previous, on=['Codigo_Articulo', 'Sucursal'], how='outer')\n",
    "    df_forecast = pd.merge(df_forecast, sales_same_year, on=['Codigo_Articulo', 'Sucursal'], how='outer')\n",
    "    df_forecast.fillna(0, inplace=True)\n",
    "\n",
    "    # Calcular la demanda estimada como el promedio de las ventas de los tres per√≠odos\n",
    "    df_forecast['Forecast'] = (df_forecast['ventas_last'] * factor_last +\n",
    "                               df_forecast['ventas_previous'] * factor_previous +\n",
    "                               df_forecast['ventas_same_year'] * factor_year) \n",
    "                                # / (factor_year + factor_last + factor_previous) Antes divid√≠a por la Sumatoria. Ahora sigo el peso absoluto de los factores.\n",
    "    elapsed = round(time.time() - start_time, 2)\n",
    "    print(f\"üñºÔ∏è Preparaci√≥n de Datos - Tiempo: {elapsed} seg\")\n",
    "    # Redondear la predicci√≥n al entero m√°s cercano  y eliminar los Negativos\n",
    "    df_forecast['Forecast'] = np.ceil(df_forecast['Forecast']).clip(lower=0)\n",
    "    df_forecast['Average'] = round(df_forecast['Forecast'] /period_length ,3)\n",
    "    # Agregar las columnas id_proveedor y ventana\n",
    "    df_forecast['id_proveedor'] = id_proveedor\n",
    "    df_forecast['algoritmo'] = 'ALGO_01'\n",
    "    df_forecast['ventana'] = period_length\n",
    "    df_forecast['f1'] = factor_last\n",
    "    df_forecast['f2'] = factor_previous\n",
    "    df_forecast['f3'] = factor_year\n",
    "    df_forecast['Fecha_Pronostico'] = current_date \n",
    "\n",
    "    # Reordenar las columnas seg√∫n la especificaci√≥n\n",
    "    df_forecast = df_forecast[['id_proveedor', 'Codigo_Articulo', 'Sucursal',  'algoritmo', 'ventana', 'f1', 'f2', 'f3', 'Fecha_Pronostico',\n",
    "                            'Forecast', 'Average','ventas_last', 'ventas_previous', 'ventas_same_year']]\n",
    "    \n",
    "    elapsed = round(time.time() - start_time, 2)\n",
    "    print(f\"üñºÔ∏è Demanda Calculada - Tiempo: {elapsed} seg\")\n",
    "    return df_forecast\n",
    "\n",
    "\n",
    "    # Borrar Columnas Innecesarias\n",
    "    # forecast_df.drop(columns=['ventas_last', 'ventas_previous', 'ventas_same_year'], inplace=True)\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "# ALGO_02 Doble Exponencial -  Modelo Holt (TENDENCIA)\n",
    "###----------------------------------------------------------------\n",
    "def Calcular_Demanda_ALGO_02(df, id_proveedor, etiqueta, ventana, current_date):\n",
    "    print('Dentro del Calcular_Demanda_ALGO_02')\n",
    "    print(f'FORECAST Holt control: {id_proveedor} - {etiqueta} - ventana: {ventana} ')\n",
    "\n",
    "        # Ajustar el modelo Holt-Winters: \n",
    "        # - trend: 'add' para tendencia aditiva\n",
    "        # - seasonal: 'add' para estacionalidad aditiva\n",
    "        # - seasonal_periods: 7 (para estacionalidad semanal)\n",
    "    # Configurar la ventana de pron√≥stico (por ejemplo, 30 d√≠as o 45 d√≠as)\n",
    "    #forecast_window = 30  # Cambia a 45 si es necesario\n",
    "    # Lista para almacenar los resultados del forecast\n",
    "    resultados = []\n",
    "    \n",
    "    # Definir rangos de fechas para cada per√≠odo\n",
    "    last_period_start = current_date - pd.Timedelta(days=ventana - 1)\n",
    "    last_period_end = current_date\n",
    "\n",
    "    previous_period_start = current_date - pd.Timedelta(days=2 * ventana - 1)\n",
    "    previous_period_end = current_date - pd.Timedelta(days=ventana)\n",
    "\n",
    "    same_period_last_year_start = current_date - pd.DateOffset(years=1) - pd.Timedelta(days=ventana - 1)\n",
    "    same_period_last_year_end = current_date - pd.DateOffset(years=1)\n",
    "\n",
    "    # Filtrar los datos para cada uno de los per√≠odos\n",
    "    df_last = df[(df['Fecha'] >= last_period_start) & (df['Fecha'] <= last_period_end)]\n",
    "    df_previous = df[(df['Fecha'] >= previous_period_start) & (df['Fecha'] <= previous_period_end)]\n",
    "    df_same_year = df[(df['Fecha'] >= same_period_last_year_start) & (df['Fecha'] <= same_period_last_year_end)]\n",
    "\n",
    "    # Agregar las ventas (unidades) por art√≠culo y sucursal para cada per√≠odo\n",
    "    sales_last = df_last.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                        .sum().reset_index().rename(columns={'Unidades': 'ventas_last'})\n",
    "    sales_previous = df_previous.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_previous'})\n",
    "    sales_same_year = df_same_year.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_same_year'})\n",
    "\n",
    "    # Agrupar los datos por 'Codigo_Articulo' y 'Sucursal'\n",
    "    for (codigo, sucursal), grupo in df.groupby(['Codigo_Articulo', 'Sucursal']):\n",
    "        # Ordenar cronol√≥gicamente y fijar 'Fecha' como √≠ndice\n",
    "        grupo = grupo.set_index('Fecha').sort_index()\n",
    "        \n",
    "        # Resamplear a frecuencia diaria sumando las ventas y rellenando d√≠as sin datos\n",
    "        ventas_diarias = grupo['Unidades'].resample('D').sum().fillna(0)\n",
    "        \n",
    "        # Verificar que la serie tenga suficientes datos para ajustar el modelo\n",
    "        if len(ventas_diarias) < 2 * 7:  # por ejemplo, al menos dos ciclos de la estacionalidad semanal\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Ajustar el modelo Holt\n",
    "            # - trend: 'add' para tendencia aditiva\n",
    "            # - seasonal: 'add' para estacionalidad aditiva\n",
    "            # - seasonal_periods: 7 (para estacionalidad semanal)\n",
    "            modelo = Holt(ventas_diarias)\n",
    "            modelo_ajustado = modelo.fit(optimized=True)\n",
    "            \n",
    "            # Realizar el forecast para la ventana definida\n",
    "            pronostico = modelo_ajustado.forecast(ventana)\n",
    "            \n",
    "            # La demanda esperada es la suma de las predicciones diarias en el periodo\n",
    "            forecast_total = pronostico.sum()\n",
    "        except Exception as e:\n",
    "            # Si ocurre alg√∫n error en el ajuste, puedes asignar un valor nulo o manejarlo de otra forma\n",
    "            forecast_total = None\n",
    "        \n",
    "        resultados.append({\n",
    "            'Codigo_Articulo': codigo,\n",
    "            'Sucursal': sucursal,\n",
    "            'Forecast': round(forecast_total, 2) if forecast_total is not None else None\n",
    "        })\n",
    "\n",
    "    # Crear el DataFrame final con los resultados del forecast\n",
    "    df_forecast = pd.DataFrame(resultados)\n",
    "    # Redondear la predicci√≥n al entero m√°s cercano\n",
    "    df_forecast['Forecast'] = np.ceil(df_forecast['Forecast']).clip(lower=0)\n",
    "    df_forecast['Average'] = round(df_forecast['Forecast'] /ventana ,3)\n",
    "    \n",
    "        # Agregar las columnas id_proveedor y ventana\n",
    "    df_forecast['id_proveedor'] = id_proveedor\n",
    "    df_forecast['ventana'] = ventana\n",
    "    df_forecast['algoritmo'] = 'ALGO_02'\n",
    "    \n",
    "        # Unir las ventas de los per√≠odos con el forecast\n",
    "    df_forecast = pd.merge(df_forecast, sales_last, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_previous, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_same_year, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast.fillna(0, inplace=True)\n",
    "\n",
    "    # Reordenar las columnas seg√∫n la especificaci√≥n\n",
    "    df_forecast = df_forecast[['id_proveedor', 'Codigo_Articulo', 'Sucursal', 'algoritmo', 'ventana', 'Forecast', \n",
    "                            'Average', 'ventas_last', 'ventas_previous', 'ventas_same_year']]\n",
    "    \n",
    "    return df_forecast\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "# ALGO_03 Suavizado Exponencial -  Modelo Holt-Winters (TENDENCIA + ESTACIONALIDAD)\n",
    "###----------------------------------------------------------------\n",
    "def Calcular_Demanda_ALGO_03(df, id_proveedor, etiqueta, ventana, current_date, periodos, f2, f3):\n",
    "    print('Dentro del Calcular_Demanda_ALGO_03')\n",
    "    print(f'FORECAST control: {id_proveedor} - {etiqueta} - ventana: {ventana} - factores: Per√≠odos Estacionalidad  {periodos} - Tendencia: {f2} - Estacionalidad: {f3}')\n",
    "\n",
    "        # Ajustar el modelo Holt-Winters: \n",
    "        # - trend: 'add' para tendencia aditiva\n",
    "        # - seasonal: 'add' para estacionalidad aditiva\n",
    "        # - seasonal_periods: 7 (para estacionalidad semanal)\n",
    "    # Configurar la ventana de pron√≥stico (por ejemplo, 30 d√≠as o 45 d√≠as)\n",
    "    #forecast_window = 30  # Cambia a 45 si es necesario\n",
    "    # Lista para almacenar los resultados del forecast\n",
    "    resultados = []\n",
    "    \n",
    "    # Definir rangos de fechas para cada per√≠odo\n",
    "    last_period_start = current_date - pd.Timedelta(days=ventana - 1)\n",
    "    last_period_end = current_date\n",
    "\n",
    "    previous_period_start = current_date - pd.Timedelta(days=2 * ventana - 1)\n",
    "    previous_period_end = current_date - pd.Timedelta(days=ventana)\n",
    "\n",
    "    same_period_last_year_start = current_date - pd.DateOffset(years=1) - pd.Timedelta(days=ventana - 1)\n",
    "    same_period_last_year_end = current_date - pd.DateOffset(years=1)\n",
    "\n",
    "    # Filtrar los datos para cada uno de los per√≠odos\n",
    "    df_last = df[(df['Fecha'] >= last_period_start) & (df['Fecha'] <= last_period_end)]\n",
    "    df_previous = df[(df['Fecha'] >= previous_period_start) & (df['Fecha'] <= previous_period_end)]\n",
    "    df_same_year = df[(df['Fecha'] >= same_period_last_year_start) & (df['Fecha'] <= same_period_last_year_end)]\n",
    "\n",
    "    # Agregar las ventas (unidades) por art√≠culo y sucursal para cada per√≠odo\n",
    "    sales_last = df_last.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                        .sum().reset_index().rename(columns={'Unidades': 'ventas_last'})\n",
    "    sales_previous = df_previous.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_previous'})\n",
    "    sales_same_year = df_same_year.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_same_year'})\n",
    "    \n",
    "    # Agrupar los datos por 'Codigo_Articulo' y 'Sucursal'\n",
    "    for (codigo, sucursal), grupo in df.groupby(['Codigo_Articulo', 'Sucursal']):\n",
    "        # Ordenar cronol√≥gicamente y fijar 'Fecha' como √≠ndice\n",
    "        grupo = grupo.set_index('Fecha').sort_index()\n",
    "        \n",
    "        # Resamplear a frecuencia diaria sumando las ventas y rellenando d√≠as sin datos\n",
    "        ventas_diarias = grupo['Unidades'].resample('D').sum().fillna(0)\n",
    "        \n",
    "        # Verificar que la serie tenga suficientes datos para ajustar el modelo\n",
    "        if len(ventas_diarias) < 2 * 7:  # por ejemplo, al menos dos ciclos de la estacionalidad semanal\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Ajustar el modelo Holt-Winters: \n",
    "            # - trend: 'add' para tendencia aditiva\n",
    "            # - seasonal: 'add' para estacionalidad aditiva\n",
    "            # - seasonal_periods: 7 (para estacionalidad semanal)\n",
    "            modelo = ExponentialSmoothing(ventas_diarias, trend=f2, seasonal=f3, seasonal_periods=periodos)\n",
    "            modelo_ajustado = modelo.fit(optimized=True)\n",
    "            \n",
    "            # Realizar el forecast para la ventana definida\n",
    "            pronostico = modelo_ajustado.forecast(ventana)\n",
    "            \n",
    "            # La demanda esperada es la suma de las predicciones diarias en el periodo\n",
    "            forecast_total = pronostico.sum()\n",
    "        except Exception as e:\n",
    "            # Si ocurre alg√∫n error en el ajuste, puedes asignar un valor nulo o manejarlo de otra forma\n",
    "            forecast_total = None\n",
    "        \n",
    "        resultados.append({\n",
    "            'Codigo_Articulo': codigo,\n",
    "            'Sucursal': sucursal,\n",
    "            'Forecast': round(forecast_total, 2) if forecast_total is not None else None\n",
    "        })\n",
    "\n",
    "    # Crear el DataFrame final con los resultados del forecast\n",
    "    df_forecast = pd.DataFrame(resultados)\n",
    "    # Redondear la predicci√≥n al entero m√°s cercano\n",
    "    df_forecast['Forecast'] = np.ceil(df_forecast['Forecast']).clip(lower=0)\n",
    "    df_forecast['Average'] = round(df_forecast['Forecast'] /ventana ,3)\n",
    "    \n",
    "        # Agregar las columnas id_proveedor y ventana\n",
    "    df_forecast['id_proveedor'] = id_proveedor\n",
    "    df_forecast['ventana'] = ventana\n",
    "    df_forecast['algoritmo'] = 'ALGO_03'\n",
    "    \n",
    "        # Unir las ventas de los per√≠odos con el forecast\n",
    "    df_forecast = pd.merge(df_forecast, sales_last, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_previous, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_same_year, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast.fillna(0, inplace=True)\n",
    "\n",
    "    # Reordenar las columnas seg√∫n la especificaci√≥n\n",
    "    df_forecast = df_forecast[['id_proveedor', 'Codigo_Articulo', 'Sucursal', 'algoritmo', 'ventana', 'Forecast', \n",
    "                            'Average', 'ventas_last', 'ventas_previous', 'ventas_same_year']]\n",
    "    return df_forecast\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "# ALGO_04 Suavizado Exponencial Simple -  Modelo de Media Movil Exponencial Ponderada (EWMA) x Factor alpha\n",
    "###----------------------------------------------------------------\n",
    "def Calcular_Demanda_ALGO_04(df, id_proveedor, etiqueta, ventana, current_date, alpha):\n",
    "    print('Dentro del Calcular_Demanda_ALGO_04')\n",
    "    print(f'FORECAST control: {id_proveedor} - {etiqueta} - ventana: {ventana} - Fator Alpha: {alpha} ')\n",
    "\n",
    "    # Configurar la ventana de pron√≥stico (por ejemplo, 30 o 45 d√≠as)\n",
    "    #forecast_window = 45  # Puedes cambiarlo a 45 seg√∫n tus necesidades\n",
    "    # Par√°metro de suavizado (alpha); valores cercanos a 1 dan m√°s peso a los datos recientes\n",
    "    #alpha = 0.3\n",
    "\n",
    "    # Lista para almacenar los resultados del forecast\n",
    "    resultados = []\n",
    "    \n",
    "    # Definir rangos de fechas para cada per√≠odo\n",
    "    last_period_start = current_date - pd.Timedelta(days=ventana - 1)\n",
    "    last_period_end = current_date\n",
    "\n",
    "    previous_period_start = current_date - pd.Timedelta(days=2 * ventana - 1)\n",
    "    previous_period_end = current_date - pd.Timedelta(days=ventana)\n",
    "\n",
    "    same_period_last_year_start = current_date - pd.DateOffset(years=1) - pd.Timedelta(days=ventana - 1)\n",
    "    same_period_last_year_end = current_date - pd.DateOffset(years=1)\n",
    "\n",
    "    # Filtrar los datos para cada uno de los per√≠odos\n",
    "    df_last = df[(df['Fecha'] >= last_period_start) & (df['Fecha'] <= last_period_end)]\n",
    "    df_previous = df[(df['Fecha'] >= previous_period_start) & (df['Fecha'] <= previous_period_end)]\n",
    "    df_same_year = df[(df['Fecha'] >= same_period_last_year_start) & (df['Fecha'] <= same_period_last_year_end)]\n",
    "\n",
    "    # Agregar las ventas (unidades) por art√≠culo y sucursal para cada per√≠odo\n",
    "    sales_last = df_last.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                        .sum().reset_index().rename(columns={'Unidades': 'ventas_last'})\n",
    "    sales_previous = df_previous.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_previous'})\n",
    "    sales_same_year = df_same_year.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_same_year'})\n",
    "    \n",
    "    # Agrupar los datos por 'Codigo_Articulo' y 'Sucursal'\n",
    "    for (codigo, sucursal), grupo in df.groupby(['Codigo_Articulo', 'Sucursal']):\n",
    "        # Ordenar cronol√≥gicamente y fijar 'Fecha' como √≠ndice\n",
    "        grupo = grupo.set_index('Fecha').sort_index()\n",
    "        \n",
    "        # Resamplear a frecuencia diaria sumando las ventas y rellenando d√≠as sin datos\n",
    "        ventas_diarias = grupo['Unidades'].resample('D').sum().fillna(0)\n",
    "        \n",
    "        # Calcular el suavizado exponencial (EWMA) sobre la serie de ventas diarias\n",
    "        ewma_series = ventas_diarias.ewm(alpha=alpha, adjust=False).mean()\n",
    "        \n",
    "        # Tomamos el √∫ltimo valor suavizado como forecast diario\n",
    "        ultimo_ewma = ewma_series.iloc[-1]\n",
    "        \n",
    "        # El pron√≥stico total para la ventana definida es el pron√≥stico diario multiplicado por la cantidad de d√≠as\n",
    "        forecast_total = ultimo_ewma * ventana\n",
    "        \n",
    "        resultados.append({\n",
    "            'Codigo_Articulo': codigo,\n",
    "            'Sucursal': sucursal,\n",
    "            'Forecast': round(forecast_total, 2),\n",
    "            'Average': round(ultimo_ewma, 3)\n",
    "        })\n",
    "\n",
    "    # Crear el DataFrame final con los resultados\n",
    "    df_forecast = pd.DataFrame(resultados)\n",
    "    # Redondear la predicci√≥n al entero m√°s cercano y evitar negativos\n",
    "    df_forecast['Forecast'] = np.ceil(df_forecast['Forecast']).clip(lower=0)\n",
    "    # Agregar las columnas id_proveedor y ventana\n",
    "    df_forecast['id_proveedor'] = id_proveedor\n",
    "    df_forecast['ventana'] = ventana\n",
    "    df_forecast['algoritmo'] = 'ALGO_04'\n",
    "    \n",
    "        # Unir las ventas de los per√≠odos con el forecast\n",
    "    df_forecast = pd.merge(df_forecast, sales_last, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_previous, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_same_year, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast.fillna(0, inplace=True)\n",
    "    \n",
    "    # Reordenar las columnas seg√∫n la especificaci√≥n\n",
    "    df_forecast = df_forecast[['id_proveedor', 'Codigo_Articulo', 'Sucursal', 'algoritmo', 'ventana', 'Forecast', \n",
    "                            'Average', 'ventas_last', 'ventas_previous', 'ventas_same_year']]\n",
    "    return df_forecast\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "# ALGO_05 Promedio de Venta SIMPLE (PVS) (Metodo Actual que usan los Compradores)\n",
    "###----------------------------------------------------------------\n",
    "def Calcular_Demanda_ALGO_05(df, id_proveedor, etiqueta, ventana, current_date):\n",
    "    # Lista para almacenar los resultados del pron√≥stico\n",
    "    resultados = []\n",
    "\n",
    "    # Definir rangos de fechas para cada per√≠odo\n",
    "    last_period_start = current_date - pd.Timedelta(days=ventana - 1)\n",
    "    last_period_end = current_date\n",
    "\n",
    "    previous_period_start = current_date - pd.Timedelta(days=2 * ventana - 1)\n",
    "    previous_period_end = current_date - pd.Timedelta(days=ventana)\n",
    "\n",
    "    same_period_last_year_start = current_date - pd.DateOffset(years=1) - pd.Timedelta(days=ventana - 1)\n",
    "    same_period_last_year_end = current_date - pd.DateOffset(years=1)\n",
    "\n",
    "    # Filtrar los datos para cada uno de los per√≠odos\n",
    "    df_last = df[(df['Fecha'] >= last_period_start) & (df['Fecha'] <= last_period_end)]\n",
    "    df_previous = df[(df['Fecha'] >= previous_period_start) & (df['Fecha'] <= previous_period_end)]\n",
    "    df_same_year = df[(df['Fecha'] >= same_period_last_year_start) & (df['Fecha'] <= same_period_last_year_end)]\n",
    "\n",
    "    # Agregar las ventas (unidades) por art√≠culo y sucursal para cada per√≠odo\n",
    "    sales_last = df_last.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                        .sum().reset_index().rename(columns={'Unidades': 'ventas_last'})\n",
    "    sales_previous = df_previous.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_previous'})\n",
    "    sales_same_year = df_same_year.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_same_year'})\n",
    "    \n",
    "    # Agrupar los datos por 'Codigo_Articulo' y 'Sucursal'\n",
    "    for (codigo, sucursal), grupo in df.groupby(['Codigo_Articulo', 'Sucursal']):\n",
    "        # Establecer 'Fecha' como √≠ndice y ordenar los datos\n",
    "        grupo = grupo.set_index('Fecha').sort_index()\n",
    "        \n",
    "        # Resamplear a diario sumando las ventas\n",
    "        ventas_diarias = grupo['Unidades'].resample('D').sum().fillna(0)\n",
    "        \n",
    "        # Seleccionar un periodo reciente para calcular la media; por ejemplo, los √∫ltimos 30 d√≠as\n",
    "        # Si hay menos de 30 d√≠as de datos, se utiliza el periodo disponible\n",
    "        ventas_recientes = ventas_diarias[-30:]\n",
    "        media_diaria = ventas_recientes.mean()\n",
    "        \n",
    "        # Pronosticar la demanda para el periodo de reposici√≥n\n",
    "        pronostico = media_diaria * ventana\n",
    "        \n",
    "        resultados.append({\n",
    "            'Codigo_Articulo': codigo,\n",
    "            'Sucursal': sucursal,\n",
    "            'Forecast': round(pronostico, 2),\n",
    "            'Average': round(media_diaria, 3)\n",
    "        })\n",
    "\n",
    "    # Crear el DataFrame de pron√≥sticos\n",
    "    df_forecast = pd.DataFrame(resultados)\n",
    "        # Redondear la predicci√≥n al entero m√°s cercano\n",
    "    df_forecast['Forecast'] = np.ceil(df_forecast['Forecast']).clip(lower=0)\n",
    "    df_forecast['Average'] = round(df_forecast['Forecast'] /ventana ,3)\n",
    "    \n",
    "    # Agregar las columnas id_proveedor y ventana\n",
    "    df_forecast['id_proveedor'] = id_proveedor\n",
    "    df_forecast['ventana'] = ventana\n",
    "    df_forecast['algoritmo'] = 'ALGO_05'\n",
    "    \n",
    "    # Unir las ventas de los per√≠odos con el forecast\n",
    "    df_forecast = pd.merge(df_forecast, sales_last, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_previous, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_same_year, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast.fillna(0, inplace=True)\n",
    "    \n",
    "    # Reordenar las columnas seg√∫n la especificaci√≥n\n",
    "    df_forecast = df_forecast[['id_proveedor', 'Codigo_Articulo', 'Sucursal', 'algoritmo', 'ventana', 'Forecast', \n",
    "                            'Average', 'ventas_last', 'ventas_previous', 'ventas_same_year']]\n",
    "    \n",
    "    return df_forecast\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "# ALGO_06 Demanda Agrupada Semanal -  Modelo Holt (TENDENCIA)\n",
    "###----------------------------------------------------------------\n",
    "def Calcular_Demanda_ALGO_06(df, id_proveedor, etiqueta, ventana, current_date):\n",
    "    print('Dentro del Calcular_Demanda_ALGO_06')\n",
    "    print(f'FORECAST Holt control: {id_proveedor} - {etiqueta} - ventana: {ventana}')\n",
    "\n",
    "    # Convertir ventana a entero y calcular forecast_window en semanas\n",
    "    try:\n",
    "        forecast_window = int(ventana) // 7  # Semanas de forecast\n",
    "        if forecast_window < 4:\n",
    "            raise ValueError(\"La ventana debe ser al menos 28 d√≠as para calcular el forecast.\")\n",
    "    except ValueError:\n",
    "        print(\"Error: La ventana proporcionada no es v√°lida.\")\n",
    "        return pd.DataFrame()  # Retornar DataFrame vac√≠o en caso de error\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    # Definir rangos de fechas para cada per√≠odo\n",
    "    last_period_start = current_date - pd.Timedelta(days=ventana - 1)\n",
    "    last_period_end = current_date\n",
    "\n",
    "    previous_period_start = current_date - pd.Timedelta(days=2 * ventana - 1)\n",
    "    previous_period_end = current_date - pd.Timedelta(days=ventana)\n",
    "\n",
    "    same_period_last_year_start = current_date - pd.DateOffset(years=1) - pd.Timedelta(days=ventana - 1)\n",
    "    same_period_last_year_end = current_date - pd.DateOffset(years=1)\n",
    "\n",
    "    # Filtrar los datos para cada uno de los per√≠odos\n",
    "    df_last = df[(df['Fecha'] >= last_period_start) & (df['Fecha'] <= last_period_end)]\n",
    "    df_previous = df[(df['Fecha'] >= previous_period_start) & (df['Fecha'] <= previous_period_end)]\n",
    "    df_same_year = df[(df['Fecha'] >= same_period_last_year_start) & (df['Fecha'] <= same_period_last_year_end)]\n",
    "\n",
    "    # Agregar las ventas (unidades) por art√≠culo y sucursal para cada per√≠odo\n",
    "    sales_last = df_last.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                        .sum().reset_index().rename(columns={'Unidades': 'ventas_last'})\n",
    "    sales_previous = df_previous.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_previous'})\n",
    "    sales_same_year = df_same_year.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_same_year'})\n",
    "\n",
    "    # Agrupar los datos por 'Codigo_Articulo' y 'Sucursal'\n",
    "    for (codigo, sucursal), grupo in df.groupby(['Codigo_Articulo', 'Sucursal']):\n",
    "        # Ordenar cronol√≥gicamente y fijar 'Fecha' como √≠ndice\n",
    "        grupo = grupo.set_index('Fecha').sort_index()\n",
    "\n",
    "        # Resamplear a frecuencia semanal sumando las ventas y rellenando semanas sin datos\n",
    "        ventas_semanales = grupo['Unidades'].resample('W').sum().fillna(0)\n",
    "\n",
    "        # Verificar que la serie tenga suficientes datos para ajustar el modelo\n",
    "        if len(ventas_semanales) < 4:  # Se requieren al menos 4 semanas de datos\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Ajustar el modelo Holt con tendencia aditiva\n",
    "            modelo = Holt(ventas_semanales)\n",
    "            modelo_ajustado = modelo.fit(smoothing_level=0.8, smoothing_slope=0.2)  \n",
    "            \n",
    "            # Realizar el forecast para la ventana definida (semanal)\n",
    "            pronostico = modelo_ajustado.forecast(forecast_window)\n",
    "            \n",
    "            # La demanda esperada es la suma de las predicciones semanales en el periodo\n",
    "            forecast_total = pronostico.sum()\n",
    "        except Exception as e:\n",
    "            print(f\"Error al ajustar el modelo para C√≥digo_Articulo {codigo} y Sucursal {sucursal}: {e}\")\n",
    "            forecast_total = 0  # En caso de error, asignar 0\n",
    "\n",
    "        # Agregar resultado al listado\n",
    "        resultados.append({\n",
    "            'Codigo_Articulo': codigo,\n",
    "            'Sucursal': sucursal,\n",
    "            'Forecast': round(forecast_total, 2)\n",
    "        })\n",
    "\n",
    "    # Crear el DataFrame final con los resultados del forecast\n",
    "    df_forecast = pd.DataFrame(resultados)\n",
    "\n",
    "    # Verificar si el DataFrame tiene datos antes de continuar\n",
    "    if df_forecast.empty:\n",
    "        print(\"Advertencia: No se generaron pron√≥sticos debido a falta de datos.\")\n",
    "        return df_forecast  # Retornar DataFrame vac√≠o\n",
    "\n",
    "    # Redondear la predicci√≥n al entero m√°s cercano y evitar valores negativos\n",
    "    df_forecast['Forecast'] = np.ceil(df_forecast['Forecast']).clip(lower=0)\n",
    "    \n",
    "    # Calcular el promedio semanal si forecast_window > 0\n",
    "    df_forecast['Average'] = round(df_forecast['Forecast'] / ventana, 3) if ventana > 0 else 0\n",
    "\n",
    "    # Unir las ventas de los per√≠odos con el forecast\n",
    "    df_forecast = pd.merge(df_forecast, sales_last, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_previous, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "    df_forecast = pd.merge(df_forecast, sales_same_year, on=['Codigo_Articulo', 'Sucursal'], how='left')\n",
    "\n",
    "    # Rellenar valores NaN con 0\n",
    "    df_forecast.fillna(0, inplace=True)\n",
    "\n",
    "    # Agregar las columnas id_proveedor, ventana y algoritmo\n",
    "    df_forecast['id_proveedor'] = id_proveedor\n",
    "    df_forecast['ventana'] = ventana\n",
    "    df_forecast['algoritmo'] = 'ALGO_06'\n",
    "\n",
    "    # Reordenar las columnas seg√∫n la especificaci√≥n\n",
    "    df_forecast = df_forecast[['id_proveedor', 'Codigo_Articulo', 'Sucursal', 'algoritmo', 'ventana', 'Forecast', \n",
    "                            'Average', 'ventas_last', 'ventas_previous', 'ventas_same_year']]\n",
    "\n",
    "    return df_forecast\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "# RUTINAS DE PROCESAMIENTO DE ALGORITMOS\n",
    "###----------------------------------------------------------------  \n",
    "\n",
    "def Procesar_ALGO_06(data, proveedor, etiqueta, ventana, fecha):\n",
    "    df_forecast = Calcular_Demanda_ALGO_06(data, proveedor, etiqueta, ventana, fecha)    # Exportar el resultado a un CSV para su posterior procesamiento\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    df_forecast.to_csv(f'{folder}/{etiqueta}_ALGO_06_Solicitudes_Compra.csv', index=False)\n",
    "    print(f'-> ** Solicitudes Exportadas: {etiqueta}_ALGO_06_Solicitudes_Compra.csv *** : ventana: {ventana}  - {fecha}')\n",
    "    \n",
    "    # df_validacion = Calcular_Demanda_Extendida_ALGO_06(data, ventana, proveedor, etiqueta, fecha)\n",
    "    # df_validacion['Codigo_Articulo']= df_validacion['Codigo_Articulo'].astype(int)\n",
    "    # df_validacion['Sucursal']= df_validacion['Sucursal'].astype(int)\n",
    "    # df_validacion.to_csv(f'{folder}/{etiqueta}_ALGO_06_Datos_Validacion.csv', index=False)\n",
    "    # print(f'-> ** Validaci√≥n Exportada: {etiqueta}_ALGO_06_Datos_Validacion.csv *** : ventana: {ventana}  - {fecha}')\n",
    "    \n",
    "    Exportar_Pronostico(df_forecast, proveedor, etiqueta, 'ALGO_06')  # Impactar Datos en la Interface   \n",
    "    return\n",
    "    \n",
    "def Procesar_ALGO_05(data, proveedor, etiqueta, ventana, fecha):\n",
    "    \n",
    "        # Determinar la fecha base\n",
    "    if fecha is None:\n",
    "        fecha = data['Fecha'].max()  # Se toma la √∫ltima fecha en los datos\n",
    "    else:\n",
    "        fecha = pd.to_datetime(fecha)  # Se asegura que sea un objeto datetime\n",
    "        \n",
    "    df_forecast = Calcular_Demanda_ALGO_05(data, proveedor, etiqueta, ventana, fecha)    # Exportar el resultado a un CSV para su posterior procesamiento\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    df_forecast.to_csv(f'{folder}/{etiqueta}_ALGO_05_Solicitudes_Compra.csv', index=False)\n",
    "    \n",
    "    Exportar_Pronostico(df_forecast, proveedor, etiqueta, 'ALGO_05')  # Impactar Datos en la Interface   \n",
    "    return\n",
    "\n",
    "def Procesar_ALGO_04(data, proveedor, etiqueta, ventana, current_date=None,  alfa=None):    \n",
    "    # Asignar valores por defecto si los factores no est√°n definidos\n",
    "    alfa = 0.5 if alfa is None else float(alfa)\n",
    "    \n",
    "    # Determinar la fecha base\n",
    "    if current_date is None:\n",
    "        current_date = data['Fecha'].max()  # Se toma la √∫ltima fecha en los datos\n",
    "    else:\n",
    "        current_date = pd.to_datetime(current_date)  # Se asegura que sea un objeto datetime\n",
    "    \n",
    "    # Par√°metro de suavizado (alpha); valores cercanos a 1 dan m√°s peso a los datos recientes\n",
    "    \n",
    "    print(f'--> ALGO_04 ventana {ventana} - fecha {current_date} Peso de los Factores Utilizados: Factor Alpha: {alfa} ')\n",
    "        \n",
    "    df_forecast = Calcular_Demanda_ALGO_04(data, proveedor, etiqueta, ventana, current_date, alfa)\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    df_forecast.to_csv(f'{folder}/{etiqueta}_ALGO_04_Solicitudes_Compra.csv', index=False)   # Exportar el resultado a un CSV para su posterior procesamiento\n",
    "    \n",
    "    Exportar_Pronostico(df_forecast, proveedor, etiqueta, 'ALGO_04')  # Impactar Datos en la Interface        \n",
    "    return\n",
    "\n",
    "def Procesar_ALGO_03(data, proveedor, etiqueta, ventana, fecha, periodos=None, f2=None, f3=None):    \n",
    "    # Asignar valores por defecto si los factores no est√°n definidos\n",
    "    periodos = 7 if periodos is None else int(periodos)\n",
    "    f2 = 'add' if f2 is None else str(f2)  # Incorporar Efecto Estacionalidad\n",
    "    f3 = 'add' if f3 is None else str(f3) # Informprar Efecto Tendencia Anual\n",
    "    \n",
    "    print(f'--> ALGO_03 ventana {ventana} - Factores Utilizados: Per√≠odos: {periodos} estacionalidad: {f2} tendencia: {f3}')\n",
    "        \n",
    "    df_forecast = Calcular_Demanda_ALGO_03(data, proveedor, etiqueta, ventana, fecha, periodos, f2, f3)\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    df_forecast.to_csv(f'{folder}/{etiqueta}_ALGO_03_Solicitudes_Compra.csv', index=False)   # Exportar el resultado a un CSV para su posterior procesamiento\n",
    "    print(f'-> ** Datos Exportados: {etiqueta}_ALGO_03_Solicitudes_Compra.csv *** : ventana: {ventana}  - {fecha}')\n",
    "    Exportar_Pronostico(df_forecast, proveedor, etiqueta, 'ALGO_03')  # Impactar Datos en la Interface        \n",
    "    return\n",
    "\n",
    "def Procesar_ALGO_02(data, proveedor, etiqueta, ventana, fecha):    \n",
    "    print(f'--> ALGO_02 ventana {ventana} - Holt - No usa Factores')\n",
    "        \n",
    "    df_forecast = Calcular_Demanda_ALGO_02(data, proveedor, etiqueta, ventana, fecha)\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    df_forecast.to_csv(f'{folder}/{etiqueta}_ALGO_02_Solicitudes_Compra.csv', index=False)   # Exportar el resultado a un CSV para su posterior procesamiento\n",
    "    print(f'-> ** Datos Exportados: {etiqueta}_ALGO_02_Solicitudes_Compra.csv *** : ventana: {ventana}  - {fecha}')\n",
    "    Exportar_Pronostico(df_forecast, proveedor, etiqueta, 'ALGO_02')  # Impactar Datos en la Interface        \n",
    "    return\n",
    "\n",
    "def Procesar_ALGO_01(data, proveedor, etiqueta, ventana, fecha, factor_last=None, factor_previous=None, factor_year=None):    \n",
    "    # Asignar valores por defecto si los factores no est√°n definidos\n",
    "    factor_last = 77 if factor_last is None else int(factor_last)\n",
    "    factor_previous = 22 if factor_previous is None else int(factor_previous)\n",
    "    factor_year = 11 if factor_year is None else int(factor_year)\n",
    "\n",
    "    print(f'--> ALGO_01 ventana {ventana} - Peso de los Factores Utilizados: √∫ltimo: {factor_last} previo: {factor_previous} a√±o anterior: {factor_year}')\n",
    "        \n",
    "    df_forecast = Calcular_Demanda_ALGO_01(data, proveedor, etiqueta, ventana, fecha, factor_last, factor_previous, factor_year)\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    df_forecast.to_csv(f'{folder}/{etiqueta}_ALGO_01_Solicitudes_Compra.csv', index=False)   # Exportar el resultado a un CSV para su posterior procesamiento\n",
    "    \n",
    "    Exportar_Pronostico(df_forecast, proveedor, etiqueta, 'ALGO_01')  # Impactar Datos en la Interface        \n",
    "    return\n",
    "\n",
    "# RUTINA PRINCIPAL para obtener el pron√≥stico\n",
    "def get_forecast( id_proveedor, lbl_proveedor, period_lengh=30, algorithm='basic', f1=None, f2=None, f3=None, current_date=None ):\n",
    "    \"\"\"\n",
    "    Genera la predicci√≥n de demanda seg√∫n el algoritmo seleccionado.\n",
    "\n",
    "    Par√°metros:\n",
    "    - id_proveedor: ID del proveedor.\n",
    "    - lbl_proveedor: Etiqueta del proveedor.\n",
    "    - period_lengh: N√∫mero de d√≠as del per√≠odo a analizar (por defecto 30).\n",
    "    - algorithm: Algoritmo a utilizar.\n",
    "    - current_date: Fecha de referencia; si es None, se toma la fecha m√°xima de los datos.\n",
    "    - factores de ponderaci√≥n: F1, F2, F3  (No importa en que unidades est√©n, luego los hace relativos al total del peso)\n",
    "\n",
    "    Retorna:\n",
    "    - Un DataFrame con las predicciones.\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Dentro del get_forecast')\n",
    "    print(f'FORECAST control: {id_proveedor} - {lbl_proveedor} - ventana: {period_lengh} - {algorithm} factores: {f1} - {f2} - {f3}')\n",
    "    # Generar los datos de entrada\n",
    "    data, articulos = generar_datos(id_proveedor, lbl_proveedor, period_lengh)\n",
    "\n",
    "        # Determinar la fecha base\n",
    "    if current_date is None:\n",
    "        current_date = data['Fecha'].max()  # Se toma la √∫ltima fecha en los datos\n",
    "    else:\n",
    "        current_date = pd.to_datetime(current_date)  # Se asegura que sea un objeto datetime\n",
    "    print(f'Fecha actual {current_date}')\n",
    "    \n",
    "\n",
    "    # Selecci√≥n del algoritmo de predicci√≥n\n",
    "    match algorithm:\n",
    "        case 'ALGO_01':\n",
    "            return Procesar_ALGO_01(data, id_proveedor, lbl_proveedor, period_lengh, current_date, f1, f2, f3)  # Promedio Ponderado x 3 Factores\n",
    "        case 'ALGO_02':\n",
    "            return Procesar_ALGO_02(data, id_proveedor, lbl_proveedor, period_lengh, current_date) # Doble Exponencial - Modelo Holt (Tendencia)\n",
    "        case 'ALGO_03':\n",
    "            return Procesar_ALGO_03(data, id_proveedor, lbl_proveedor, period_lengh, current_date, f1, f2, f3) # Triple Exponencial Holt-WInter (Tendencia + Estacionalidad) (periodos, add, add)\n",
    "        case 'ALGO_04':\n",
    "            return Procesar_ALGO_04(data, id_proveedor, lbl_proveedor, period_lengh, current_date, f1) # EWMA con Factor alpha\n",
    "        case 'ALGO_05':\n",
    "            return Procesar_ALGO_05(data, id_proveedor, lbl_proveedor, period_lengh, current_date) # Promedio Venta Simple en Ventana\n",
    "        case 'ALGO_06':\n",
    "            return Procesar_ALGO_06(data, id_proveedor, lbl_proveedor, period_lengh, current_date) # Tendencias Ventas Semanales\n",
    "        case _:\n",
    "            raise ValueError(f\"Error: El algoritmo '{algorithm}' no est√° implementado.\")\n",
    "\n",
    "\n",
    "\n",
    "# Final del MODULO FUNCIONES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEIDAS DESDE EL REPOSITORIO DE FUNCIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando ejecuci√≥n: 596_PROCTER - M√©todo: ALGO_01\n",
      "Algoritmo: ALGO_01  - Name: 596_PROCTER  id: Proveedor 596\n",
      "exceution_id: 9737c740-ba85-462f-b446-d61905e3d048 model_id: 6a84b864-a805-46dd-83ab-dfcb6f82badb ----------------------------------------------------\n",
      "Par√°metros de Ejecuci√≥n\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table id=\"itables_61852c29_fc7b_49f7_bdf9_fead8cab767a\" class=\"display nowrap\" data-quarto-disable-processing=\"true\" style=\"table-layout:auto;width:auto;margin:auto;caption-side:bottom\">\n",
       "<thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      \n",
       "      <th>name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>default_value</th>\n",
       "      <th>value</th>\n",
       "      <th>id</th>\n",
       "      <th>supply_forecast_model_id</th>\n",
       "      <th>supply_forecast_execution_id</th>\n",
       "    </tr>\n",
       "  </thead><tbody><tr>\n",
       "<td style=\"vertical-align:middle; text-align:left\">\n",
       "<a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
       "    <g style=\"fill:#d9d7fc\">\n",
       "        <path d=\"M100,400H500V357H100Z\" />\n",
       "        <path d=\"M100,300H400V257H100Z\" />\n",
       "        <path d=\"M0,200H400V157H0Z\" />\n",
       "        <path d=\"M100,100H500V57H100Z\" />\n",
       "        <path d=\"M100,350H500V307H100Z\" />\n",
       "        <path d=\"M100,250H400V207H100Z\" />\n",
       "        <path d=\"M0,150H400V107H0Z\" />\n",
       "        <path d=\"M100,50H500V7H100Z\" />\n",
       "    </g>\n",
       "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
       "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"0;0;400\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;300;0\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;400\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
       "            <g transform=\"translate(45 50) rotate(-45)\">\n",
       "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
       "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(450 152)\">\n",
       "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
       "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(50 352)\">\n",
       "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
       "                <polygon points=\"-35,10 0,45 35,10\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(75 250)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(425 250) rotate(180)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "        </g>\n",
       "    </g>\n",
       "</svg>\n",
       "</a>\n",
       "Loading ITables v2.2.4 from the internet...\n",
       "(need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
       "</tr></tbody>\n",
       "</table>\n",
       "<link href=\"https://www.unpkg.com/dt_for_itables@2.0.13/dt_bundle.css\" rel=\"stylesheet\">\n",
       "<script type=\"module\">\n",
       "    import {DataTable, jQuery as $} from 'https://www.unpkg.com/dt_for_itables@2.0.13/dt_bundle.js';\n",
       "\n",
       "    document.querySelectorAll(\"#itables_61852c29_fc7b_49f7_bdf9_fead8cab767a:not(.dataTable)\").forEach(table => {\n",
       "        if (!(table instanceof HTMLTableElement))\n",
       "            return;\n",
       "\n",
       "        // Define the table data\n",
       "        const data = [[\"1_Window\", \"int\", \"30\", \"45\", \"25ca4518-fd18-4c4b-b81c-f9b7b9de9db1\", \"6a84b864-a805-46dd-83ab-dfcb6f82badb\", \"9737c740-ba85-462f-b446-d61905e3d048\"], [\"2_Factor_Actual\", \"float\", \"0.8\", \"0.9\", \"60752a38-82ac-4e1a-8d17-3e84222f287f\", \"6a84b864-a805-46dd-83ab-dfcb6f82badb\", \"9737c740-ba85-462f-b446-d61905e3d048\"], [\"3_Factor_Previo\", \"float\", \"0.1\", \"0.1\", \"c1a82e8f-98a0-4b62-b8d6-2301f592262d\", \"6a84b864-a805-46dd-83ab-dfcb6f82badb\", \"9737c740-ba85-462f-b446-d61905e3d048\"], [\"4_Factor_A\\u00f1o_Anterior\", \"float\", \"0.1\", \"0.1\", \"2967c875-a2ac-49a7-8078-9342c60e1bb7\", \"6a84b864-a805-46dd-83ab-dfcb6f82badb\", \"9737c740-ba85-462f-b446-d61905e3d048\"]];\n",
       "\n",
       "        // Define the dt_args\n",
       "        let dt_args = {\"layout\": {\"topStart\": null, \"topEnd\": null, \"bottomStart\": null, \"bottomEnd\": null}, \"order\": [], \"warn_on_selected_rows_not_rendered\": true};\n",
       "        dt_args[\"data\"] = data;\n",
       "\n",
       "        \n",
       "        new DataTable(table, dt_args);\n",
       "    });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametros extra√≠dos: ventana=45, f1=0.9, f2=0.1, f3=0.1\n",
      "Procesando: 596 - 596_PROCTER - ventana: 45 - ALGO_01 factores: 0.9 - 0.1 - 0.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Solo importa lo necesario desde el m√≥dulo de funciones\n",
    "from funciones_forecast import (\n",
    "    get_forecast,\n",
    "    generar_datos,\n",
    "    Procesar_ALGO_01,\n",
    "    Procesar_ALGO_02,\n",
    "    Procesar_ALGO_03,\n",
    "    Procesar_ALGO_04,\n",
    "    Procesar_ALGO_05,\n",
    "    Procesar_ALGO_06,    \n",
    "    generar_datos,    \n",
    "    get_execution_execute_by_status,\n",
    "    get_full_parameters,\n",
    "    update_execution,\n",
    "    get_execution_parameter,\n",
    "    update_execution_execute\n",
    ")\n",
    "\n",
    "\n",
    "# OBTNER LISTA PENDIENTE DE EJECUCI√ìN CON ESTADO 10\n",
    "# -------------------- RUTINA PRINCIPAL --------------------\n",
    "\n",
    "# Ejecuta la rutina completa\n",
    "fes = get_execution_execute_by_status(10)\n",
    "for index, row in fes[fes[\"fee_status_id\"] == 10].iterrows():\n",
    "    algoritmo = row[\"name\"]\n",
    "    name = algoritmo.split('_ALGO')[0]\n",
    "    method = row[\"method\"]\n",
    "    execution_id = row[\"forecast_execution_id\"]\n",
    "    id_proveedor = row[\"ext_supplier_code\"]\n",
    "    forecast_execution_execute_id = row[\"forecast_execution_execute_id\"]\n",
    "    supplier_id = row[\"supplier_id\"]\n",
    "    supply_forecast_model_id = row[\"forecast_model_id\"]\n",
    "\n",
    "    print(f\"Procesando ejecuci√≥n: {name} - M√©todo: {method}\")\n",
    "\n",
    "    try:\n",
    "        df_params = get_full_parameters(supply_forecast_model_id, execution_id) \n",
    "        ventana = 30\n",
    "        f1 = f2 = f3 = None\n",
    "\n",
    "        try:\n",
    "            if df_params is not None and not df_params.empty:\n",
    "                if len(df_params) >= 1:\n",
    "                    ventana = int(float(df_params.iloc[0]['value']))\n",
    "                if len(df_params) >= 2:\n",
    "                    f1 = df_params.iloc[1]['value']\n",
    "                if len(df_params) >= 3:\n",
    "                    f2 = df_params.iloc[2]['value']\n",
    "                if len(df_params) >= 4:\n",
    "                    f3 = df_params.iloc[3]['value']\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error interpretando par√°metros: {e}\")\n",
    "            ventana = 30\n",
    "            f1 = f2 = f3 = None\n",
    "            \n",
    "        print(f\"Algoritmo: {method}  - Name: {name}  id: Proveedor {id_proveedor}\")\n",
    "        print(f\"Iniciando ESTADO (15) exceution_id: {execution_id} model_id: {supply_forecast_model_id} ----------------------------------------------------\")\n",
    "        \n",
    "        update_execution_execute(forecast_execution_execute_id, supply_forecast_execution_status_id=15)\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # Procesar el pron√≥stico seg√∫n el algoritmo seleccionado\n",
    "        # ----------------------------------------------------------------\n",
    "        get_forecast(id_proveedor, name, ventana, method, f1, f2, f3)        \n",
    "        update_execution_execute(forecast_execution_execute_id, supply_forecast_execution_status_id=20)\n",
    "        print('------------------------------------------------------------------')\n",
    "        print(\"‚úÖ Ejecuci√≥n completada con √©xito.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(f\"‚ùå Error procesando {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo de tipos como funciones de conversi√≥n\n",
    "type_map = {\n",
    "    'int': int,\n",
    "    'float': float,\n",
    "    'str': str,\n",
    "    'bool': lambda x: str(x).lower() in ['true', '1', 'yes']\n",
    "}\n",
    "\n",
    "# Asignaci√≥n din√°mica con conversi√≥n de tipo\n",
    "for i, row in df_params.iterrows():\n",
    "    convert = type_map.get(row['data_type'].lower(), str)  # Por defecto, str si el tipo no es reconocido\n",
    "    try:\n",
    "        value_converted = convert(row['value'])\n",
    "    except Exception:\n",
    "        value_converted = row['value']  # fallback por si hay error de conversi√≥n\n",
    "    globals()[f'f{i}'] = value_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Procesar_ALGO_01(data, proveedor, etiqueta, ventana, fecha, factor_last=None, factor_previous=None, factor_year=None):    \n",
    "    # Asignar valores por defecto si los factores no est√°n definidos\n",
    "    factor_last = 0.77 if factor_last is None else factor_last\n",
    "    factor_previous = 0.22 if factor_previous is None else factor_previous\n",
    "    factor_year = 0.11 if factor_year is None else factor_year\n",
    "\n",
    "    print(f'--> Procesar_ALGO_01 ventana {ventana} - Peso de los Factores Utilizados: √∫ltimo: {factor_last} previo: {factor_previous} a√±o anterior: {factor_year}')\n",
    "        \n",
    "    # df_forecast = Calcular_Demanda_ALGO_01(data, proveedor, etiqueta, ventana, fecha, factor_last, factor_previous, factor_year)\n",
    "    # df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    # df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    # df_forecast.to_csv(f'{folder}/{etiqueta}_ALGO_01_Solicitudes_Compra.csv', index=False)   # Exportar el resultado a un CSV para su posterior procesamiento\n",
    "    \n",
    "    # Exportar_Pronostico(df_forecast, proveedor, etiqueta, 'ALGO_01')  # Impactar Datos en la Interface        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROGRAMA PYTON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Solo importa lo necesario desde el m√≥dulo de funciones\n",
    "from funciones_forecast import (\n",
    "    get_forecast,\n",
    "    generar_datos,\n",
    "    #Procesar_ALGO_01,\n",
    "    Procesar_ALGO_02,\n",
    "    Procesar_ALGO_03,\n",
    "    Procesar_ALGO_04,\n",
    "    Procesar_ALGO_05,\n",
    "    Procesar_ALGO_06,    \n",
    "    generar_datos,    \n",
    "    get_execution_execute_by_status,\n",
    "    get_full_parameters,\n",
    "    update_execution\n",
    ")\n",
    "\n",
    "# FUNCIONES LOCALES\n",
    "# RUTINA PRINCIPAL para obtener el pron√≥stico\n",
    "def get_forecast( id_proveedor, lbl_proveedor, period_lengh=30, algorithm='basic', f1=None, f2=None, f3=None, current_date=None ):\n",
    "    \"\"\"\n",
    "    Genera la predicci√≥n de demanda seg√∫n el algoritmo seleccionado.\n",
    "\n",
    "    Par√°metros:\n",
    "    - id_proveedor: ID del proveedor.\n",
    "    - lbl_proveedor: Etiqueta del proveedor.\n",
    "    - period_lengh: N√∫mero de d√≠as del per√≠odo a analizar (por defecto 30).\n",
    "    - algorithm: Algoritmo a utilizar.\n",
    "    - current_date: Fecha de referencia; si es None, se toma la fecha m√°xima de los datos.\n",
    "    - factores de ponderaci√≥n: F1, F2, F3  (No importa en que unidades est√©n, luego los hace relativos al total del peso)\n",
    "\n",
    "    Retorna:\n",
    "    - Un DataFrame con las predicciones.\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Dentro del get_forecast')\n",
    "    print(f'FORECAST control: {id_proveedor} - {lbl_proveedor} - ventana: {period_lengh} - {algorithm} factores: {f1} - {f2} - {f3}')\n",
    "    # Generar los datos de entrada\n",
    "    data, articulos = generar_datos(id_proveedor, lbl_proveedor, period_lengh)\n",
    "\n",
    "    # Determinar la fecha base\n",
    "    if current_date is None:\n",
    "        current_date = data['Fecha'].max()  # Se toma la √∫ltima fecha en los datos\n",
    "    else:\n",
    "        current_date = pd.to_datetime(current_date)  # Se asegura que sea un objeto datetime\n",
    "    print(f'Fecha actual {current_date}')\n",
    "    \n",
    "\n",
    "    # Selecci√≥n del algoritmo de predicci√≥n\n",
    "    match algorithm:\n",
    "        case 'ALGO_01':\n",
    "            return Procesar_ALGO_01(data, id_proveedor, lbl_proveedor, period_lengh, current_date, f1, f2, f3)  # Promedio Ponderado x 3 Factores\n",
    "        case 'ALGO_02':\n",
    "            return Procesar_ALGO_02(data, id_proveedor, lbl_proveedor, period_lengh, current_date) # Doble Exponencial - Modelo Holt (Tendencia)\n",
    "        case 'ALGO_03':\n",
    "            return Procesar_ALGO_03(data, id_proveedor, lbl_proveedor, period_lengh, current_date, f1, f2, f3) # Triple Exponencial Holt-WInter (Tendencia + Estacionalidad) (periodos, add, add)\n",
    "        case 'ALGO_04':\n",
    "            return Procesar_ALGO_04(data, id_proveedor, lbl_proveedor, period_lengh, current_date, f1) # EWMA con Factor alpha\n",
    "        case 'ALGO_05':\n",
    "            return Procesar_ALGO_05(data, id_proveedor, lbl_proveedor, period_lengh, current_date) # Promedio Venta Simple en Ventana\n",
    "        case 'ALGO_06':\n",
    "            return Procesar_ALGO_06(data, id_proveedor, lbl_proveedor, period_lengh, current_date) # Tendencias Ventas Semanales\n",
    "        case _:\n",
    "            raise ValueError(f\"Error: El algoritmo '{algorithm}' no est√° implementado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'method', 'ext_supplier_code', 'last_execution',\n",
       "       'fee_status_id', 'timestamp', 'forecast_model_id',\n",
       "       'forecast_execution_id', 'forecast_execution_execute_id',\n",
       "       'forecast_execution_schedule_id', 'supplier_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fes = get_execution_execute_by_status(20)\n",
    "\n",
    "fes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïí Iniciando ejecuci√≥n programada del FORECAST ...\n",
      "Procesando ejecuci√≥n: 596_PROCTER - M√©todo: ALGO_01\n",
      "Dentro del get_forecast\n",
      "FORECAST control: 596 - 596_PROCTER - ventana: 45 - ALGO_01 factores: 0.9 - 0.1 - 0.1\n",
      "-> Datos Recuperados del CACHE: 596, Label: 596_PROCTER\n",
      "Fecha actual 2025-04-03 00:00:00\n",
      "--> Procesar_ALGO_01 ventana 45 - Peso de los Factores Utilizados: √∫ltimo: 0.9 previo: 0.1 a√±o anterior: 0.1\n",
      "‚úÖ Ejecuci√≥n completada con √©xito.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Aqu√≠ se inicia la ejecuci√≥n programada del pron√≥stico\n",
    "    print(\"üïí Iniciando ejecuci√≥n programada del FORECAST ...\")\n",
    "    try:\n",
    "        # Ejecuta la rutina completa\n",
    "        fes = get_execution_execute_by_status(10)\n",
    "        for index, row in fes[fes[\"fee_status_id\"] == 10].iterrows():\n",
    "            algoritmo = row[\"name\"]\n",
    "            name = algoritmo.split('_ALGO')[0]\n",
    "            method = row[\"method\"]\n",
    "            execution_id = row[\"forecast_execution_id\"]\n",
    "            id_proveedor = row[\"ext_supplier_code\"]\n",
    "            forecast_execution_execute_id = row[\"forecast_execution_execute_id\"]\n",
    "            supplier_id = row[\"supplier_id\"]\n",
    "            supply_forecast_model_id = row[\"forecast_model_id\"]\n",
    "\n",
    "            print(f\"Procesando ejecuci√≥n: {name} - M√©todo: {method}\")\n",
    "\n",
    "            try:\n",
    "                df_params = get_full_parameters(supply_forecast_model_id, execution_id)\n",
    "                # Convertir df_params a un diccionario para acceder din√°micamente\n",
    "                param_dict = df_params.set_index('name')['value'].to_dict() if df_params is not None and not df_params.empty else {}\n",
    "\n",
    "                # Extraer valores de forma segura, asignando un valor por defecto si no existe el par√°metro\n",
    "                try:            \n",
    "                    ventana =  int(float(df_params.iloc[0]['value']))\n",
    "                    f1 = df_params.iloc[1]['value']\n",
    "                    f2 = df_params.iloc[2]['value']\n",
    "                    f3 = df_params.iloc[3]['value']           \n",
    "            \n",
    "                except (ValueError, TypeError):\n",
    "                    ventana = 30  # Valor por defecto si falla la conversi√≥n\n",
    "\n",
    "                # update_execution(execution_id, supply_forecast_execution_status_id=15)\n",
    "                get_forecast(id_proveedor, name, ventana, method, f1, f2, f3)\n",
    "                # update_execution(execution_id, supply_forecast_execution_status_id=20)\n",
    "\n",
    "                print(\"‚úÖ Ejecuci√≥n completada con √©xito.\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error durante la ejecuci√≥n del forecast: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error general al iniciar ejecuciones programadas: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_execution_parameter() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_params \u001b[38;5;241m=\u001b[39m \u001b[43mget_execution_parameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43msupply_forecast_model_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: get_execution_parameter() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "df_params = get_execution_parameter(supply_forecast_model_id, execution_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
