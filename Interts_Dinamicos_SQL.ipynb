{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runinas para Ingresdo de Sucursales y Datos faltantes\n",
    "Cocina de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUTINA TRANSFERENCIA DE ARCHIVOS.\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# LIBRERIAS NECESARIAS \n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from dotenv import dotenv_values\n",
    "import psycopg2 as pg2    # Conectores para Postgres\n",
    "import pyodbc  # Conector para SQL Server\n",
    "import getpass  # Para obtener el usuario del sistema operativo\n",
    "import uuid  # Importar la librería uuid\n",
    "# Mostrar el DataFrame resultante\n",
    "import ace_tools_open as tools\n",
    "\n",
    "# Evitar Mensajes Molestos\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category= FutureWarning)\n",
    "\n",
    "secrets = dotenv_values(\".env\")   # Connection String from .env\n",
    "folder = secrets[\"FOLDER_DATOS\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# Funciones de conexión a la base de datos\n",
    "# -----------------------------------------------------------\n",
    "def Open_Conn_Postgres():\n",
    "    secrets = dotenv_values(\".env\")   # Cargar credenciales desde .env    \n",
    "    conn_str = f\"dbname={secrets['BASE4']} user={secrets['USUARIO4']} password={secrets['CONTRASENA4']} host={secrets['SERVIDOR4']} port={secrets['PUERTO4']}\"\n",
    "    try:    \n",
    "        conn = pg2.connect(conn_str)\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f'Error en la conexión: {e}')\n",
    "        return None\n",
    "\n",
    "def Open_Connection():\n",
    "    secrets = dotenv_values(\".env\")   # Connection String from .env\n",
    "    conn_str = f'DRIVER={secrets[\"DRIVER2\"]};SERVER={secrets[\"SERVIDOR2\"]};PORT={secrets[\"PUERTO2\"]};DATABASE={secrets[\"BASE2\"]};UID={secrets[\"USUARIO2\"]};PWD={secrets[\"CONTRASENA2\"]}'\n",
    "    # print (conn_str) \n",
    "    try:    \n",
    "        conn = pyodbc.connect(conn_str)\n",
    "        return conn\n",
    "    except:\n",
    "        print('Error en la Conexión')\n",
    "        return None\n",
    "\n",
    "def Close_Connection(conn): \n",
    "    conn.close()\n",
    "    return True\n",
    "\n",
    "# Helper para generar identificadores únicos\n",
    "def id_aleatorio():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "# OTRAS RUTINAS UTILES\n",
    "\n",
    "def get_excecution_excecute_by_status(status):\n",
    "    if not status:\n",
    "        print(\"No hay estados para filtrar\")\n",
    "        return None\n",
    "    \n",
    "    conn = Open_Conn_Postgres()\n",
    "    if conn is None:\n",
    "        return None\n",
    "    try:\n",
    "        query = f\"\"\"\n",
    "            SELECT \n",
    "                a.id, \n",
    "                a.description, \n",
    "                a.name, \n",
    "                a.\"timestamp\", \n",
    "                a.supply_forecast_model_id, \n",
    "                a.ext_supplier_code, \n",
    "                a.graphic, \n",
    "                a.monthly_net_margin_in_millions, \n",
    "                a.monthly_purchases_in_millions, \n",
    "                a.monthly_sales_in_millions, \n",
    "                a.sotck_days AS stock_days,  -- Posible corrección\n",
    "                a.sotck_days_colors AS stock_days_colors, -- Posible corrección\n",
    "                a.supplier_id, \n",
    "                a.supply_forecast_execution_status_id,\n",
    "                b.supply_forecast_execution_schedule_id AS forecast_execution_schedule_id, \n",
    "                b.id AS forecast_execution_execute_id\n",
    "            FROM public.spl_supply_forecast_execution a\n",
    "            LEFT JOIN public.spl_supply_forecast_execution_execute b\n",
    "                ON b.supply_forecast_execution_id = a.id\n",
    "            WHERE a.supply_forecast_execution_status_id = {status};\n",
    "        \"\"\"\n",
    "        # Ejecutar la consulta SQL\n",
    "        fexsts = pd.read_sql(query, conn)\n",
    "        return fexsts\n",
    "    except Exception as e:\n",
    "        print(f\"Error en get_excecution_status: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        Close_Connection(conn) \n",
    "\n",
    "\n",
    "def get_precios(id_proveedor):\n",
    "    conn = Open_Connection()\n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "        A.[C_PROVEEDOR_PRIMARIO],\n",
    "        S.[C_ARTICULO]\n",
    "        ,S.[C_SUCU_EMPR]\n",
    "        ,S.[I_PRECIO_VTA]\n",
    "        ,S.[I_COSTO_ESTADISTICO]\n",
    "        --,S.[M_HABILITADO_SUCU]\n",
    "        --,A.M_BAJA                   \n",
    "        FROM [DIARCOP001].[DiarcoP].[dbo].[T051_ARTICULOS_SUCURSAL] S\n",
    "        LEFT JOIN [DIARCOP001].[DiarcoP].[dbo].[T050_ARTICULOS] A\n",
    "            ON A.[C_ARTICULO] = S.[C_ARTICULO]\n",
    "        \n",
    "        WHERE S.[M_HABILITADO_SUCU] = 'S' -- Permitido Reponer\n",
    "            AND A.M_BAJA = 'N'  -- Activo en Maestro Artículos\n",
    "            AND A.[C_PROVEEDOR_PRIMARIO] = {id_proveedor} -- Solo del Proveedor        \n",
    "        ORDER BY S.[C_ARTICULO],S.[C_SUCU_EMPR];\n",
    "    \"\"\"\n",
    "    # Ejecutar la consulta SQL\n",
    "    precios = pd.read_sql(query, conn)\n",
    "    precios['C_PROVEEDOR_PRIMARIO']= precios['C_PROVEEDOR_PRIMARIO'].astype(int)\n",
    "    precios['C_ARTICULO']= precios['C_ARTICULO'].astype(int)\n",
    "    precios['C_SUCU_EMPR']= precios['C_SUCU_EMPR'].astype(int)\n",
    "    return precios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SANDBOX para Pruebas Manuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_proveedor = '98'\n",
    "name= '98_FRATELLI_BRANCA'\n",
    "forecast_execution_id ='0cd32842-0726-438b-856f-78a67d4c6455'\n",
    "forecast_execution_excecute_id ='01307697-fcd2-4bcd-af58-474f90cea46d'\n",
    "supplier_id = '27275183-cf6e-4865-ad33-d1ccd3d32e2e'\n",
    "algoritmo = '98_FRATELLI_BRANCA_ALGO_01'\n",
    "\n",
    "\n",
    "df_forecast_ext = pd.read_csv(f'{folder}/{algoritmo}_Pronostico_Extendido.csv')\n",
    "df_forecast_ext['Codigo_Articulo']= df_forecast_ext['Codigo_Articulo'].astype(int)\n",
    "df_forecast_ext['Sucursal']= df_forecast_ext['Sucursal'].astype(int)\n",
    "df_forecast_ext.fillna(0)   # Por si se filtró algún missing value\n",
    "\n",
    "\n",
    "# Mostrar la tabla con los gráficos en base64\n",
    "\n",
    "tools.display_dataframe_to_user(name=\"Forecast Extendido\", dataframe=df_forecast_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"❗Filas con site_id inválido:\", df_forecast_ext['site_id'].isna().sum())\n",
    "print(\"❗Filas con product_id inválido:\", df_forecast_ext['product_id'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizar_site_ids(df_forecast_ext, conn):\n",
    "    \"\"\"Reemplaza site_id en df_forecast_ext con datos válidos desde fnd_site\"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT code, name, id FROM public.fnd_site\n",
    "    WHERE company_id = 'e7498b2e-2669-473f-ab73-e2c8b4dcc585'\n",
    "    ORDER BY code \n",
    "    \"\"\"\n",
    "    stores = pd.read_sql(query, conn)\n",
    "    stores = stores[pd.to_numeric(stores['code'], errors='coerce').notna()].copy()\n",
    "    stores['code'] = stores['code'].astype(int)\n",
    "\n",
    "    # Eliminar site_id anterior si ya existía\n",
    "    df_forecast_ext = df_forecast_ext.drop(columns=['site_id'], errors='ignore')\n",
    "\n",
    "    # Merge con los stores para obtener site_id\n",
    "    df_forecast_ext = df_forecast_ext.merge(\n",
    "        stores[['code', 'id']],\n",
    "        left_on='Sucursal',\n",
    "        right_on='code',\n",
    "        how='left'\n",
    "    ).rename(columns={'id': 'site_id'})\n",
    "\n",
    "    # Validar valores faltantes\n",
    "    missing = df_forecast_ext[df_forecast_ext['site_id'].isna()]\n",
    "    if not missing.empty:\n",
    "        print(f\"⚠️ Faltan site_id en {len(missing)} registros\")\n",
    "        missing.to_csv(f\"{folder}/{name}_Missing_Site_IDs.csv\", index=False)\n",
    "    else:\n",
    "        print(\"✅ Todos los registros tienen site_id válido\")\n",
    "\n",
    "    return df_forecast_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = Open_Conn_Postgres()\n",
    "df_forecast_ext = actualizar_site_ids(df_forecast_ext, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast_ext_nan = df_forecast_ext[df_forecast_ext['site_id'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fes = get_excecution_excecute_by_status(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(\n",
    "    df_forecast_ext,  # DataFrame de artículos\n",
    "    precio,    # DataFrame de precios\n",
    "    left_on =['Codigo_Articulo', 'Sucursal'],  # Claves en 'forecast'\n",
    "    right_on=['C_ARTICULO', 'C_SUCU_EMPR'],  # Claves en 'precios'\n",
    "    how='left'  # Solo traer los productos que están en 'forecast'\n",
    ")\n",
    "df_merged['TOT_VENTA'] = (df_merged['Forecast'] * df_merged['I_PRECIO_VTA'] / 1000).round(2)\n",
    "df_merged['TOT_COSTO'] = (df_merged['Forecast'] * df_merged['I_COSTO_ESTADISTICO'] / 1000).round(2)\n",
    "df_merged['MARGEN'] = (df_merged['TOT_VENTA'] - df_merged['TOT_COSTO'] / 1000).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperar Solicitudes de Compra Extended\n",
    "df_suc_faltantes = pd.read_csv(f'{folder}/Sucursales_Faltantes.csv', delimiter=\";\", dtype=str)\n",
    "df_suc_faltantes.columns = df_suc_faltantes.columns.str.strip()  # Elimina espacios adicionales\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar el INSERT dinámicamente\n",
    "insert_queries = []\n",
    "for _, row in df_suc_faltantes.iterrows():\n",
    "    query = f\"\"\"\n",
    "        INSERT INTO public.fnd_site(\n",
    "            id, address, latitude, longitude, name, \"timestamp\", type, code, company_id\n",
    "        ) VALUES (\n",
    "            gen_random_uuid(), \n",
    "            '{row['address']}', \n",
    "            {row['latitude'] if row['latitude'] else 'NULL'}, \n",
    "            {row['longitude'] if row['longitude'] else 'NULL'}, \n",
    "            '{row['name']}', \n",
    "            '{row['fecha_hora']}', \n",
    "            '{row['type']}', \n",
    "            {row['code']}, \n",
    "            '{row['company_id']}'\n",
    "        );\n",
    "    \"\"\"\n",
    "    insert_queries.append(query)\n",
    "\n",
    "# Guardar los inserts en un archivo SQL para ejecutarlo luego\n",
    "sql_file_path = f\"{folder}/insert_sucursales.sql\"\n",
    "with open(sql_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.writelines(\"\\n\".join(insert_queries))\n",
    "\n",
    "print(f\"Archivo SQL generado en: {sql_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "def ejecutar_inserts(sql_file):\n",
    "    conn = None\n",
    "    try:\n",
    "        # Conectar a la base de datos\n",
    "        conn = Open_Conn_Postgres()\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        # Leer el archivo SQL y ejecutarlo\n",
    "        with open(sql_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            sql_script = f.read()\n",
    "        \n",
    "        cur.execute(sql_script)\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        print(\"Sucursales insertadas correctamente en la base de datos.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error ejecutando el insert: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "# Ejecutar los inserts\n",
    "ejecutar_inserts(sql_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LISTAR PARÄMETROS DE CONFIGURACIÓN del MODELO\n",
    "\n",
    "query = \"\"\"\"\n",
    "\n",
    "SELECT  m.method, m.name as detalle, p.name, p.data_type, p.default_value\n",
    "\tFROM public.spl_supply_forecast_model m\n",
    "\tLEFT JOIN public.spl_supply_forecast_model_parameter p\n",
    "\tON p.supply_forecast_model_id = m.id\n",
    "\tORDER BY m.method, p.name;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#### FORECAS EXCECUTION PARAMETERS FULL\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT  e.name, m.method, e.ext_supplier_code, \n",
    "\t\tp.name, p.data_type, p.default_value, fep.value,\n",
    "\t\te.id as supply_forecast_execution_id, p.id as supply_forecast_model_parameter_id, \n",
    "\t\tfep.id as supply_forecast_execution_parameter_id\n",
    "\t\t---, e.description,  e.supply_forecast_model_id,\n",
    "\tFROM public.spl_supply_forecast_execution e\n",
    "\tLEFT JOIN public.spl_supply_forecast_model m\n",
    "\tON m.id = e.supply_forecast_model_id\n",
    "\tLEFT JOIN public.spl_supply_forecast_model_parameter p\n",
    "\tON p.supply_forecast_model_id = m.id\n",
    "\tLEFT JOIN public.spl_supply_forecast_execution_parameter fep\n",
    "\tON fep.supply_forecast_model_parameter_id = p.id\n",
    "\n",
    "\tORDER BY e.ext_supplier_code, m.method, p.name\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# INSERTAR EXCECUTION PARAMETER\n",
    "\n",
    "query = \"\"\"\n",
    "INSERT INTO public.spl_supply_forecast_execution_parameter (\n",
    "    id, \"timestamp\", supply_forecast_execution_id, supply_forecast_model_parameter_id, value\n",
    ")\n",
    "VALUES\n",
    "-- d0b0117f\n",
    "(uuid_generate_v4(), CURRENT_TIMESTAMP, 'cd0c3052-5853-4294-83e5-83ae0cee1407', 'ddfceb28-1a6a-49e6-8230-49e9f2a4313c', 'add'),\n",
    "(uuid_generate_v4(), CURRENT_TIMESTAMP, 'cd0c3052-5853-4294-83e5-83ae0cee1407', '064efda1-f8b1-46a7-8e14-6971c801b386', 'add')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
