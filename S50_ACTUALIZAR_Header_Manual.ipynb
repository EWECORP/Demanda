{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S50 - ACTUALIZAR DATOS DEL HEADER ya Existentes en CONNEXA \n",
    "\n",
    "Parte de los forecast executión que están en estado 50 (Ya publicados OK), Genera los datos acumulados del registro excec y sube los archivos a connexa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías estándar\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "from random import randint\n",
    "\n",
    "# Importar librerías de terceros\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Importar funciones necesarias del módulo `funciones_forecast`\n",
    "from funciones_forecast import (\n",
    "    Open_Conn_Postgres,\n",
    "    Open_Connection,\n",
    "    Close_Connection,\n",
    "    get_execution_by_status,\n",
    "    Open_Postgres_retry,\n",
    "    mover_archivos_procesados,\n",
    "    actualizar_site_ids,\n",
    "    insertar_graficos_forecast,\n",
    "    get_precios,\n",
    "    get_execution_execute_by_status,\n",
    "    update_execution,\n",
    "    update_execution_execute,\n",
    "    create_execution_execute_result,\n",
    "    generar_mini_grafico,\n",
    "    generar_grafico_base64\n",
    ")\n",
    "\n",
    "# Importar librerías adicionales necesarias\n",
    "import ace_tools_open as tools\n",
    "\n",
    "# Cargar configuraciones desde archivo `.env`\n",
    "secrets = dotenv_values(\".env\")\n",
    "folder = secrets[\"FOLDER_DATOS\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fes = get_execution_execute_by_status(50)\n",
    "tools.display_dataframe_to_user(name=\"Contenido de Archivos Markdown\", dataframe=fes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJECUTABLE PYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_datos_stock(id_proveedor, etiqueta):\n",
    "    secrets = dotenv_values(\".env\")   # Connection String from .env\n",
    "    folder = secrets[\"FOLDER_DATOS\"]\n",
    "    \n",
    "    #  Intento recuperar datos cacheados\n",
    "    try:         \n",
    "        print(f\"-> Generando datos para ID: {id_proveedor}, Label: {etiqueta}\")\n",
    "        # Configuración de conexión\n",
    "        conn = Open_Connection()\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # FILTRA solo PRODUCTOS HABILITADOS y Traer datos de STOCK y PENDIENTES desde PRODUCCIÓN\n",
    "        # ----------------------------------------------------------------\n",
    "        query = f\"\"\"              \n",
    "        SELECT A.[C_PROVEEDOR_PRIMARIO] as Codigo_Proveedor\n",
    "            ,S.[C_ARTICULO] as Codigo_Articulo\n",
    "            ,S.[C_SUCU_EMPR] as Codigo_Sucursal\n",
    "            ,S.[I_PRECIO_VTA] as Precio_Venta\n",
    "            ,S.[I_COSTO_ESTADISTICO] as Precio_Costo\n",
    "            ,S.[Q_FACTOR_VTA_SUCU] as Factor_Venta\n",
    "            ,ST.Q_UNID_ARTICULO + ST.Q_PESO_ARTICULO AS Stock_Unidades-- Stock Cierre Dia Anterior\n",
    "            ,(R.[Q_VENTA_30_DIAS] + R.[Q_VENTA_15_DIAS]) * S.[Q_FACTOR_VTA_SUCU] AS Venta_Unidades_30_Dias -- OJO convertida desde BULTOS DIARCO\n",
    "                    \n",
    "            ,(ST.Q_UNID_ARTICULO + ST.Q_PESO_ARTICULO)* S.[I_COSTO_ESTADISTICO] AS Stock_Valorizado-- Stock Cierre Dia Anterior\n",
    "            ,(R.[Q_VENTA_30_DIAS] + R.[Q_VENTA_15_DIAS]) * S.[Q_FACTOR_VTA_SUCU] * S.[I_COSTO_ESTADISTICO] AS Venta_Valorizada\n",
    "\n",
    "            ,ROUND(((ST.Q_UNID_ARTICULO + ST.Q_PESO_ARTICULO)* S.[I_COSTO_ESTADISTICO]) / \t\n",
    "                ((R.[Q_VENTA_30_DIAS] + R.[Q_VENTA_15_DIAS]+0.0001) * S.[Q_FACTOR_VTA_SUCU] * S.[I_COSTO_ESTADISTICO] ),0) * 30\n",
    "                AS Dias_Stock\n",
    "                    \n",
    "            ,S.[F_ULTIMA_VTA]\n",
    "            ,S.[Q_VTA_ULTIMOS_15DIAS] * S.[Q_FACTOR_VTA_SUCU] AS VENTA_UNIDADES_1Q -- OJO esto está en BULTOS DIARCO\n",
    "            ,S.[Q_VTA_ULTIMOS_30DIAS] * S.[Q_FACTOR_VTA_SUCU] AS VENTA_UNIDADES_2Q -- OJO esto está en BULTOS DIARCO\n",
    "                \n",
    "        FROM [DIARCOP001].[DiarcoP].[dbo].[T051_ARTICULOS_SUCURSAL] S\n",
    "        INNER JOIN [DIARCOP001].[DiarcoP].[dbo].[T050_ARTICULOS] A\n",
    "            ON A.[C_ARTICULO] = S.[C_ARTICULO]\n",
    "        LEFT JOIN [DIARCOP001].[DiarcoP].[dbo].[T060_STOCK] ST\n",
    "            ON ST.C_ARTICULO = S.[C_ARTICULO] \n",
    "            AND ST.C_SUCU_EMPR = S.[C_SUCU_EMPR]\n",
    "        LEFT JOIN [DIARCOP001].[DiarcoP].[dbo].[T710_ESTADIS_REPOSICION] R\n",
    "            ON R.[C_ARTICULO] = S.[C_ARTICULO]\n",
    "            AND R.[C_SUCU_EMPR] = S.[C_SUCU_EMPR]\n",
    "\n",
    "        WHERE S.[M_HABILITADO_SUCU] = 'S' -- Permitido Reponer\n",
    "            AND A.M_BAJA = 'N'  -- Activo en Maestro Artículos\n",
    "            AND A.[C_PROVEEDOR_PRIMARIO] = {id_proveedor} -- Solo del Proveedor\n",
    "                        \n",
    "        ORDER BY S.[C_ARTICULO],S.[C_SUCU_EMPR];\n",
    "        \"\"\"\n",
    "        # Ejecutar la consulta SQL\n",
    "        df_stock = pd.read_sql(query, conn)\n",
    "        file_path = f'{folder}/{etiqueta}_Stock.csv'\n",
    "        df_stock['Codigo_Proveedor']= df_stock['Codigo_Proveedor'].astype(int)\n",
    "        df_stock['Codigo_Articulo']= df_stock['Codigo_Articulo'].astype(int)\n",
    "        df_stock['Codigo_Sucursal']= df_stock['Codigo_Sucursal'].astype(int)\n",
    "        df_stock.fillna(0, inplace= True)\n",
    "        # df_stock.to_csv(file_path, index=False, encoding='utf-8')        \n",
    "        print(f\"---> Datos de STOCK guardados: {file_path}\")\n",
    "        return df_stock\n",
    "    except Exception as e:\n",
    "        print(f\"Error en get_execution: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        Close_Connection(conn)\n",
    "\n",
    "\n",
    "def obtener_demora_oc(id_proveedor, etiqueta):\n",
    "    secrets = dotenv_values(\".env\")   # Connection String from .env\n",
    "    folder = secrets[\"FOLDER_DATOS\"]\n",
    "    \n",
    "    #  Intento recuperar datos cacheados\n",
    "    try:         \n",
    "        print(f\"-> Generando datos para ID: {id_proveedor}, Label: {etiqueta}\")\n",
    "        # Configuración de conexión\n",
    "        conn = Open_Connection()\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # FILTRA solo PRODUCTOS HABILITADOS y Traer datos de STOCK y PENDIENTES desde PRODUCCIÓN\n",
    "        # ----------------------------------------------------------------\n",
    "        query = f\"\"\"              \n",
    "        SELECT  [C_OC]\n",
    "            ,[U_PREFIJO_OC]\n",
    "            ,[U_SUFIJO_OC]      \n",
    "            ,[U_DIAS_LIMITE_ENTREGA]\n",
    "            , DATEADD(DAY, [U_DIAS_LIMITE_ENTREGA], [F_ENTREGA]) as FECHA_LIMITE\n",
    "            , DATEDIFF (DAY, DATEADD(DAY, [U_DIAS_LIMITE_ENTREGA], [F_ENTREGA]), GETDATE()) as Demora\n",
    "            ,[C_PROVEEDOR] as Codigo_Proveedor\n",
    "            ,[C_SUCU_COMPRA] as Codigo_Sucursal\n",
    "            ,[C_SUCU_DESTINO]\n",
    "            ,[C_SUCU_DESTINO_ALT]\n",
    "            ,[C_SITUAC]\n",
    "            ,[F_SITUAC]\n",
    "            ,[F_ALTA_SIST]\n",
    "            ,[F_EMISION]\n",
    "            ,[F_ENTREGA]    \n",
    "            ,[C_USUARIO_OPERADOR]    \n",
    "            \n",
    "        FROM [DIARCOP001].[DiarcoP].[dbo].[T080_OC_CABE]  \n",
    "        WHERE [C_SITUAC] = 1\n",
    "        AND C_PROVEEDOR = {id_proveedor} \n",
    "        AND DATEADD(DAY, [U_DIAS_LIMITE_ENTREGA], [F_ENTREGA]) < GETDATE();\n",
    "        \"\"\"\n",
    "        # Ejecutar la consulta SQL\n",
    "        df_demoras = pd.read_sql(query, conn)\n",
    "        df_demoras['Codigo_Proveedor']= df_demoras['Codigo_Proveedor'].astype(int)\n",
    "        df_demoras['Codigo_Sucursal']= df_demoras['Codigo_Sucursal'].astype(int)\n",
    "        df_demoras['Demora']= df_demoras['Demora'].astype(int)\n",
    "        df_demoras.fillna(0, inplace= True)         \n",
    "        print(f\"---> Datos de OC DEMORADAS Recuperados: {etiqueta}\")\n",
    "        return df_demoras\n",
    "    except Exception as e:\n",
    "        print(f\"Error en get_execution: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        Close_Connection(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Leer Dataframe de FORECAST EXECUTION  de Estado 50 y Actualizar HEADER\n",
    "fes = get_execution_execute_by_status(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 36\t- 1 - \tEstaod OC Pendiente         -                        \tPendiente \n",
    "* 36\t- 2 -\tEstado OC Cerrada           -                       \tCumplida  \n",
    "* 36\t- 3 -\tEstado OC Anulada           -                       \tAnulada   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S50 ACTUALIZAR SOLO CABECERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elegido = '140_UNILEVER_ALGO_05'\n",
    "# for index, row in fes[fes[\"name\"] == elegido].iterrows():\n",
    "    \n",
    "for index, row in fes[fes[\"fee_status_id\"] == 50].iterrows():\n",
    "    algoritmo = row[\"name\"]\n",
    "    name = algoritmo.split('_ALGO')[0]\n",
    "    execution_id = row[\"forecast_execution_id\"]\n",
    "    id_proveedor = row[\"ext_supplier_code\"]\n",
    "    forecast_execution_execute_id = row[\"forecast_execution_execute_id\"]\n",
    "    supplier_id = row[\"supplier_id\"]\n",
    "    \n",
    "    folderP = folder + '/procesado'\n",
    "\n",
    "    print(f\"Algoritmo: {algoritmo}  - Name: {name} exce_id: {forecast_execution_execute_id} id: Proveedor {id_proveedor}\")\n",
    "    print(f\"supplier-id: {supplier_id} ----------------------------------------------------\")\n",
    "\n",
    "    try:\n",
    "        df_stock = obtener_datos_stock(id_proveedor= id_proveedor, etiqueta= algoritmo )\n",
    "        total_stock_valorizado = float(round(df_stock['Stock_Valorizado'].sum() / 1000000, 2))\n",
    "        total_venta_valorizada = float(round(df_stock['Venta_Valorizada'].sum() / 1000000, 2))\n",
    "        days= int( total_stock_valorizado / total_venta_valorizada * 30 )\n",
    "           \n",
    "        # Definición de condiciones\n",
    "        # Condiciones\n",
    "        if days > 30:\n",
    "            semaforo= 'green'\n",
    "        elif 10 < days <= 30:\n",
    "            semaforo ='yellow'\n",
    "        elif days <= 10:\n",
    "            semaforo ='red'\n",
    "        else:\n",
    "            semaforo = 'white' # Valor predeterminado\n",
    "\n",
    "        df_demora = obtener_demora_oc(id_proveedor= id_proveedor, etiqueta= algoritmo )\n",
    "        if df_demora.empty:  # Verifica si el DataFrame está vacío\n",
    "            maximo_atraso_oc = 0\n",
    "        else:\n",
    "            maximo_atraso_oc = int(round(df_demora['Demora'].max()))\n",
    "\n",
    "        # Actualizar en base de datos            \n",
    "        update_execution_execute(\n",
    "            forecast_execution_execute_id,\n",
    "            # supply_forecast_execution_status_id=50,\n",
    "            # monthly_sales_in_millions=total_venta,\n",
    "            # monthly_purchases_in_millions=total_costo,\n",
    "            # monthly_net_margin_in_millions=total_margen,\n",
    "            # graphic=mini_grafico,\n",
    "            # total_products=total_productos,\n",
    "            # total_units=total_unidades,\n",
    "            # otif = randint(70, 100),  # Simulación de OTIF entre 70 y 100\n",
    "            sotck_days = days, # Simulación de stock_days entre 10 y 76              \n",
    "            sotck_days_colors = semaforo, # Simulación de semaforo\n",
    "            maximum_backorder_days = maximo_atraso_oc # Simulación de oc_delay entre 0 y 45\n",
    "            \n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Stock Actualizado para {execution_id}\")\n",
    "        \n",
    "        # # ✅ Morver Archivo a carpeta de Procesado ....\n",
    "        # mover_archivos_procesados(algoritmo, folder)\n",
    "        # print(f\"✅ Archivo movido a Procesado: {algoritmo}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_stock.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARCHES y ARREGLO DE PROBLEMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ARREGLAR PROBLEMAS\n",
    "df_sin_duplicados = df_forecast_ext.drop_duplicates(subset=['Codigo_Articulo', 'Sucursal'], keep='first')\n",
    "file_path = f\"{folder}/{algoritmo}_Pronostico_Extendido_Con_Graficos.csv\"\n",
    "df_sin_duplicados.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Función para decodificar y mostrar una imagen en Jupyter Notebook\n",
    "    \n",
    "img_data = base64.b64decode(mini_grafico)\n",
    "buffer = BytesIO(img_data)\n",
    "\n",
    "# Mostrar la imagen en Jupyter Notebook\n",
    "display(Image(buffer.getvalue()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualizar en base de datos            \n",
    "update_execution_execute(\n",
    "    forecast_execution_execute_id,\n",
    "    supply_forecast_execution_status_id=50,\n",
    "    monthly_sales_in_millions=total_venta,\n",
    "    monthly_purchases_in_millions=total_costo,\n",
    "    monthly_net_margin_in_millions=total_margen,\n",
    "    graphic=mini_grafico,\n",
    "    total_products=total_productos,\n",
    "    total_units=total_unidades,\n",
    "    otif = randint(70, 100),  # Simulación de OTIF entre 70 y 100\n",
    "    sotck_days = randint(10,76), # Simulación de stock_days entre 10 y 76\n",
    "    sotck_days_colors ='green', # Simulación de semaforo\n",
    "    maximum_backorder_days = randint(0,45) # Simulación de oc_delay entre 0 y 45\n",
    "    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
