{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S50 - ACTUALIZAR DATOS DEL HEADER ya Existentes en CONNEXA \n",
    "\n",
    "Parte de los forecast executión que están en estado 50 (Ya publicados OK), Genera los datos acumulados del registro excec y sube los archivos a connexa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías estándar\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "from random import randint\n",
    "\n",
    "# Importar librerías de terceros\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Importar funciones necesarias del módulo `funciones_forecast`\n",
    "from funciones_forecast import (\n",
    "    Open_Conn_Postgres,\n",
    "    Open_Connection,\n",
    "    Close_Connection,\n",
    "    get_execution_by_status,\n",
    "    Open_Postgres_retry,\n",
    "    mover_archivos_procesados,\n",
    "    actualizar_site_ids,\n",
    "    insertar_graficos_forecast,\n",
    "    get_precios,\n",
    "    get_execution_execute_by_status,\n",
    "    update_execution,\n",
    "    update_execution_execute,\n",
    "    create_execution_execute_result,\n",
    "    generar_mini_grafico,\n",
    "    generar_grafico_base64\n",
    ")\n",
    "\n",
    "# Importar librerías adicionales necesarias\n",
    "import ace_tools_open as tools\n",
    "\n",
    "# Cargar configuraciones desde archivo `.env`\n",
    "secrets = dotenv_values(\".env\")\n",
    "folder = secrets[\"FOLDER_DATOS\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenido de Archivos Markdown\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table id=\"itables_1972bdea_5735_4c66_89d2_80d97dc8da66\" class=\"display nowrap\" data-quarto-disable-processing=\"true\" style=\"table-layout:auto;width:auto;margin:auto;caption-side:bottom\">\n",
       "<thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      \n",
       "      <th>name</th>\n",
       "      <th>method</th>\n",
       "      <th>ext_supplier_code</th>\n",
       "      <th>last_execution</th>\n",
       "      <th>fee_status_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>forecast_model_id</th>\n",
       "      <th>forecast_execution_id</th>\n",
       "      <th>forecast_execution_execute_id</th>\n",
       "      <th>forecast_execution_schedule_id</th>\n",
       "      <th>supplier_id</th>\n",
       "    </tr>\n",
       "  </thead><tbody><tr>\n",
       "<td style=\"vertical-align:middle; text-align:left\">\n",
       "<a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
       "    <g style=\"fill:#d9d7fc\">\n",
       "        <path d=\"M100,400H500V357H100Z\" />\n",
       "        <path d=\"M100,300H400V257H100Z\" />\n",
       "        <path d=\"M0,200H400V157H0Z\" />\n",
       "        <path d=\"M100,100H500V57H100Z\" />\n",
       "        <path d=\"M100,350H500V307H100Z\" />\n",
       "        <path d=\"M100,250H400V207H100Z\" />\n",
       "        <path d=\"M0,150H400V107H0Z\" />\n",
       "        <path d=\"M100,50H500V7H100Z\" />\n",
       "    </g>\n",
       "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
       "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"0;0;400\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;300;0\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;400\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
       "            <g transform=\"translate(45 50) rotate(-45)\">\n",
       "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
       "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(450 152)\">\n",
       "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
       "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(50 352)\">\n",
       "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
       "                <polygon points=\"-35,10 0,45 35,10\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(75 250)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(425 250) rotate(180)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "        </g>\n",
       "    </g>\n",
       "</svg>\n",
       "</a>\n",
       "Loading ITables v2.2.4 from the internet...\n",
       "(need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
       "</tr></tbody>\n",
       "</table>\n",
       "<link href=\"https://www.unpkg.com/dt_for_itables@2.0.13/dt_bundle.css\" rel=\"stylesheet\">\n",
       "<script type=\"module\">\n",
       "    import {DataTable, jQuery as $} from 'https://www.unpkg.com/dt_for_itables@2.0.13/dt_bundle.js';\n",
       "\n",
       "    document.querySelectorAll(\"#itables_1972bdea_5735_4c66_89d2_80d97dc8da66:not(.dataTable)\").forEach(table => {\n",
       "        if (!(table instanceof HTMLTableElement))\n",
       "            return;\n",
       "\n",
       "        // Define the table data\n",
       "        const data = [[\"25_LA_VIRGINIA_ALGO_05\", \"ALGO_05\", \"25\", true, 50, \"2025-03-17 19:01:57.634754\", \"96f4dafb-258a-487f-93f2-dd20954c1958\", \"6545d815-ddba-4ab8-af80-d5e3ea9449fe\", \"1a3dba71-caa6-49c8-98c2-146fac81a891\", \"2f432909-56e3-4741-8cc1-248facfb2ab0\", \"8a99b126-1a87-4ae9-86ce-5411ba14e4e4\"], [\"98_FRATELLI_BRANCA_ALGO_05\", \"ALGO_05\", \"98\", true, 50, \"2025-03-17 19:01:58.577542\", \"96f4dafb-258a-487f-93f2-dd20954c1958\", \"dd3daca0-2db3-4325-90ea-7c985a2cfe30\", \"06a74134-ab33-4401-ae66-ac6cfdcf33e4\", \"6e77d6e2-c3f8-46ba-a500-78178c549bd1\", \"27275183-cf6e-4865-ad33-d1ccd3d32e2e\"], [\"62_ARCOR_ALGO_05\", \"ALGO_05\", \"62\", true, 50, \"2025-03-17 19:01:57.978913\", \"96f4dafb-258a-487f-93f2-dd20954c1958\", \"a85ef5dd-b12a-4a27-a4b5-80b78d10cdf7\", \"a97250ed-3d31-4338-b493-659ebcb96691\", \"fde047d6-2fe5-475d-873c-bb85dbca84fa\", \"f603814e-c2d8-49b2-8738-24f9cc0a7e89\"], [\"327_PALADINI_ALGO_05\", \"ALGO_05\", \"327\", true, 50, \"2025-03-17 19:01:59.838855\", \"96f4dafb-258a-487f-93f2-dd20954c1958\", \"4b190aad-9303-45ae-8bd0-56b7392cc1bb\", \"b9f50c39-9004-4eba-92d6-dc5b1947f7ec\", \"946feb88-dbf3-4c09-ac77-c2c897d86824\", \"76dae300-bd67-4577-bf45-19be518968c6\"], [\"189_BODEGAS_LOPEZ_ALGO_05\", \"ALGO_05\", \"189\", true, 50, \"2025-03-17 19:01:59.498074\", \"96f4dafb-258a-487f-93f2-dd20954c1958\", \"28698426-7037-461b-b1e9-c2ba21031b6a\", \"ed7848d3-5dcb-41d2-9c36-0c4bdc468fbc\", \"53d56b7e-48ac-4001-98de-2e4e20b079d4\", \"8e6e66f7-2482-451b-a656-5a1999343186\"], [\"20_MOLINOS_ALGO_05\", \"ALGO_05\", \"20\", true, 50, \"2025-03-17 19:01:57.265487\", \"96f4dafb-258a-487f-93f2-dd20954c1958\", \"9cb3a4f9-1600-4522-879c-38b68a4bfe9a\", \"e10d6fa2-5a2f-411b-9e75-03340d3f397a\", \"27e7d0fe-92c8-4902-9eb6-c7522794d58d\", \"f006a0c2-6da6-46d6-b014-a6de03cd522c\"], [\"140_UNILEVER_ALGO_05\", \"ALGO_05\", \"140\", true, 50, \"2025-03-17 19:01:59.161097\", \"96f4dafb-258a-487f-93f2-dd20954c1958\", \"9ab2bd99-9a2e-458e-bed5-bfba8aeb3dda\", \"dc632c16-1310-40e7-b36c-b34bd22af857\", \"b8758113-cb90-4874-98c5-061909b91ff8\", \"1b76764e-334b-45df-abc7-526b1c6da5fa\"], [\"1465_QUICKFOOD_ALGO_05\", \"ALGO_05\", \"1465\", true, 50, \"2025-03-17 19:02:00.176938\", \"96f4dafb-258a-487f-93f2-dd20954c1958\", \"ed865d50-61e5-45de-b58b-6fdf557fb069\", \"5d47fe53-654a-4894-a9e8-d6ab8dd10c12\", \"39525ad4-42f4-49d0-8655-01d36a5b752d\", \"6e44e060-64b8-4562-a2e1-5874c6390466\"], [\"25_LA_VIRGINIA_ALGO_01\", \"ALGO_01\", \"25\", true, 50, \"2025-03-17 19:01:53.784314\", \"6a84b864-a805-46dd-83ab-dfcb6f82badb\", \"6fd161ef-000d-4e0e-aef0-249eb2f3db5b\", \"01307697-fcd2-4bcd-af58-474f90cea46d\", \"dc176612-7b08-46a9-afeb-a312d844717e\", \"8a99b126-1a87-4ae9-86ce-5411ba14e4e4\"], [\"596_PROCTER_ALGO_01\", \"ALGO_01\", \"596\", true, 50, \"2025-04-02 13:40:52.824866\", \"6a84b864-a805-46dd-83ab-dfcb6f82badb\", \"9737c740-ba85-462f-b446-d61905e3d048\", \"d6726d21-a0cc-44d8-84ea-52a05eccb50a\", \"7c767ae8-5b92-4993-a467-206df536fe02\", \"8bfb27a1-516f-488f-9eda-9a6fbc5acf4b\"], [\"8449_CAGNOLI_ALGO_01\", \"ALGO_01\", \"8449\", true, 50, \"2025-03-26 20:36:58.494699\", \"6a84b864-a805-46dd-83ab-dfcb6f82badb\", \"755a3eea-1d81-40d9-b460-74fa60747db6\", \"17424524-c497-4353-9809-162d0167e18c\", \"32abaafb-4d14-47a9-a919-ec4aca3e66a7\", \"63e106bb-1179-4565-ac9f-a6a4be36d689\"], [\"189_BODEGAS_LOPEZ_ALGO_01\", \"ALGO_01\", \"189\", true, 50, \"2025-03-17 19:01:54.133420\", \"6a84b864-a805-46dd-83ab-dfcb6f82badb\", \"d0b0117f-60f2-4e52-9e40-0f1871233ac9\", \"3eb65876-e91a-47ea-bcb9-d3252546bd86\", \"d4507a06-eae1-49ff-af61-19864add7abf\", \"8e6e66f7-2482-451b-a656-5a1999343186\"]];\n",
       "\n",
       "        // Define the dt_args\n",
       "        let dt_args = {\"layout\": {\"topStart\": \"pageLength\", \"topEnd\": \"search\", \"bottomStart\": \"info\", \"bottomEnd\": \"paging\"}, \"order\": [], \"warn_on_selected_rows_not_rendered\": true};\n",
       "        dt_args[\"data\"] = data;\n",
       "\n",
       "        \n",
       "        new DataTable(table, dt_args);\n",
       "    });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fes = get_execution_execute_by_status(50)\n",
    "tools.display_dataframe_to_user(name=\"Contenido de Archivos Markdown\", dataframe=fes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJECUTABLE PYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_datos_stock(id_proveedor, etiqueta):\n",
    "    secrets = dotenv_values(\".env\")   # Connection String from .env\n",
    "    folder = secrets[\"FOLDER_DATOS\"]\n",
    "    \n",
    "    #  Intento recuperar datos cacheados\n",
    "    try:         \n",
    "        print(f\"-> Generando datos para ID: {id_proveedor}, Label: {etiqueta}\")\n",
    "        # Configuración de conexión\n",
    "        conn = Open_Connection()\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # FILTRA solo PRODUCTOS HABILITADOS y Traer datos de STOCK y PENDIENTES desde PRODUCCIÓN\n",
    "        # ----------------------------------------------------------------\n",
    "        query = f\"\"\"              \n",
    "        SELECT A.[C_PROVEEDOR_PRIMARIO] as Codigo_Proveedor\n",
    "            ,S.[C_ARTICULO] as Codigo_Articulo\n",
    "            ,S.[C_SUCU_EMPR] as Codigo_Sucursal\n",
    "            ,S.[I_PRECIO_VTA] as Precio_Venta\n",
    "            ,S.[I_COSTO_ESTADISTICO] as Precio_Costo\n",
    "            ,S.[Q_FACTOR_VTA_SUCU] as Factor_Venta\n",
    "            ,ST.Q_UNID_ARTICULO + ST.Q_PESO_ARTICULO AS Stock_Unidades-- Stock Cierre Dia Anterior\n",
    "            ,(R.[Q_VENTA_30_DIAS] + R.[Q_VENTA_15_DIAS]) * S.[Q_FACTOR_VTA_SUCU] AS Venta_Unidades_30_Dias -- OJO convertida desde BULTOS DIARCO\n",
    "                    \n",
    "            ,(ST.Q_UNID_ARTICULO + ST.Q_PESO_ARTICULO)* S.[I_COSTO_ESTADISTICO] AS Stock_Valorizado-- Stock Cierre Dia Anterior\n",
    "            ,(R.[Q_VENTA_30_DIAS] + R.[Q_VENTA_15_DIAS]) * S.[Q_FACTOR_VTA_SUCU] * S.[I_COSTO_ESTADISTICO] AS Venta_Valorizada\n",
    "\n",
    "            ,ROUND(((ST.Q_UNID_ARTICULO + ST.Q_PESO_ARTICULO)* S.[I_COSTO_ESTADISTICO]) / \t\n",
    "                ((R.[Q_VENTA_30_DIAS] + R.[Q_VENTA_15_DIAS]+0.0001) * S.[Q_FACTOR_VTA_SUCU] * S.[I_COSTO_ESTADISTICO] ),0) * 30\n",
    "                AS Dias_Stock\n",
    "                    \n",
    "            ,S.[F_ULTIMA_VTA]\n",
    "            ,S.[Q_VTA_ULTIMOS_15DIAS] * S.[Q_FACTOR_VTA_SUCU] AS VENTA_UNIDADES_1Q -- OJO esto está en BULTOS DIARCO\n",
    "            ,S.[Q_VTA_ULTIMOS_30DIAS] * S.[Q_FACTOR_VTA_SUCU] AS VENTA_UNIDADES_2Q -- OJO esto está en BULTOS DIARCO\n",
    "                \n",
    "        FROM [DIARCOP001].[DiarcoP].[dbo].[T051_ARTICULOS_SUCURSAL] S\n",
    "        INNER JOIN [DIARCOP001].[DiarcoP].[dbo].[T050_ARTICULOS] A\n",
    "            ON A.[C_ARTICULO] = S.[C_ARTICULO]\n",
    "        LEFT JOIN [DIARCOP001].[DiarcoP].[dbo].[T060_STOCK] ST\n",
    "            ON ST.C_ARTICULO = S.[C_ARTICULO] \n",
    "            AND ST.C_SUCU_EMPR = S.[C_SUCU_EMPR]\n",
    "        LEFT JOIN [DIARCOP001].[DiarcoP].[dbo].[T710_ESTADIS_REPOSICION] R\n",
    "            ON R.[C_ARTICULO] = S.[C_ARTICULO]\n",
    "            AND R.[C_SUCU_EMPR] = S.[C_SUCU_EMPR]\n",
    "\n",
    "        WHERE S.[M_HABILITADO_SUCU] = 'S' -- Permitido Reponer\n",
    "            AND A.M_BAJA = 'N'  -- Activo en Maestro Artículos\n",
    "            AND A.[C_PROVEEDOR_PRIMARIO] = {id_proveedor} -- Solo del Proveedor\n",
    "                        \n",
    "        ORDER BY S.[C_ARTICULO],S.[C_SUCU_EMPR];\n",
    "        \"\"\"\n",
    "        # Ejecutar la consulta SQL\n",
    "        df_stock = pd.read_sql(query, conn)\n",
    "        file_path = f'{folder}/{etiqueta}_Stock.csv'\n",
    "        df_stock['Codigo_Proveedor']= df_stock['Codigo_Proveedor'].astype(int)\n",
    "        df_stock['Codigo_Articulo']= df_stock['Codigo_Articulo'].astype(int)\n",
    "        df_stock['Codigo_Sucursal']= df_stock['Codigo_Sucursal'].astype(int)\n",
    "        df_stock.fillna(0, inplace= True)\n",
    "        # df_stock.to_csv(file_path, index=False, encoding='utf-8')        \n",
    "        print(f\"---> Datos de STOCK guardados: {file_path}\")\n",
    "        return df_stock\n",
    "    except Exception as e:\n",
    "        print(f\"Error en get_execution: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        Close_Connection(conn)\n",
    "\n",
    "\n",
    "def obtener_demora_oc(id_proveedor, etiqueta):\n",
    "    secrets = dotenv_values(\".env\")   # Connection String from .env\n",
    "    folder = secrets[\"FOLDER_DATOS\"]\n",
    "    \n",
    "    #  Intento recuperar datos cacheados\n",
    "    try:         \n",
    "        print(f\"-> Generando datos para ID: {id_proveedor}, Label: {etiqueta}\")\n",
    "        # Configuración de conexión\n",
    "        conn = Open_Connection()\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # FILTRA solo PRODUCTOS HABILITADOS y Traer datos de STOCK y PENDIENTES desde PRODUCCIÓN\n",
    "        # ----------------------------------------------------------------\n",
    "        query = f\"\"\"              \n",
    "        SELECT  [C_OC]\n",
    "            ,[U_PREFIJO_OC]\n",
    "            ,[U_SUFIJO_OC]      \n",
    "            ,[U_DIAS_LIMITE_ENTREGA]\n",
    "            , DATEADD(DAY, [U_DIAS_LIMITE_ENTREGA], [F_ENTREGA]) as FECHA_LIMITE\n",
    "            , DATEDIFF (DAY, DATEADD(DAY, [U_DIAS_LIMITE_ENTREGA], [F_ENTREGA]), GETDATE()) as Demora\n",
    "            ,[C_PROVEEDOR] as Codigo_Proveedor\n",
    "            ,[C_SUCU_COMPRA] as Codigo_Sucursal\n",
    "            ,[C_SUCU_DESTINO]\n",
    "            ,[C_SUCU_DESTINO_ALT]\n",
    "            ,[C_SITUAC]\n",
    "            ,[F_SITUAC]\n",
    "            ,[F_ALTA_SIST]\n",
    "            ,[F_EMISION]\n",
    "            ,[F_ENTREGA]    \n",
    "            ,[C_USUARIO_OPERADOR]    \n",
    "            \n",
    "        FROM [DIARCOP001].[DiarcoP].[dbo].[T080_OC_CABE]  \n",
    "        WHERE [C_SITUAC] = 1\n",
    "        AND C_PROVEEDOR = {id_proveedor} \n",
    "        AND DATEADD(DAY, [U_DIAS_LIMITE_ENTREGA], [F_ENTREGA]) < GETDATE();\n",
    "        \"\"\"\n",
    "        # Ejecutar la consulta SQL\n",
    "        df_demoras = pd.read_sql(query, conn)\n",
    "        df_demoras['Codigo_Proveedor']= df_demoras['Codigo_Proveedor'].astype(int)\n",
    "        df_demoras['Codigo_Sucursal']= df_demoras['Codigo_Sucursal'].astype(int)\n",
    "        df_demoras['Demora']= df_demoras['Demora'].astype(int)\n",
    "        df_demoras.fillna(0, inplace= True)         \n",
    "        print(f\"---> Datos de OC DEMORADAS Recuperados: {etiqueta}\")\n",
    "        return df_demoras\n",
    "    except Exception as e:\n",
    "        print(f\"Error en get_execution: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        Close_Connection(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Leer Dataframe de FORECAST EXECUTION  de Estado 50 y Actualizar HEADER\n",
    "fes = get_execution_execute_by_status(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 36\t- 1 - \tEstaod OC Pendiente         -                        \tPendiente \n",
    "* 36\t- 2 -\tEstado OC Cerrada           -                       \tCumplida  \n",
    "* 36\t- 3 -\tEstado OC Anulada           -                       \tAnulada   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algoritmo: 596_PROCTER_ALGO_01  - Name: 596_PROCTER exce_id: d6726d21-a0cc-44d8-84ea-52a05eccb50a id: Proveedor 596\n",
      "supplier-id: 8bfb27a1-516f-488f-9eda-9a6fbc5acf4b ----------------------------------------------------\n",
      "-> Datos Recuperados del CACHE: 596, Label: 596_PROCTER\n",
      "❗Filas con site_id inválido: 0\n",
      "❗Filas con product_id inválido: 0\n",
      "⚠️ El DataFrame ya contiene precios y costos. Merge evitado para 596\n"
     ]
    }
   ],
   "source": [
    "elegido = '596_PROCTER_ALGO_01'\n",
    "for index, row in fes[fes[\"name\"] == elegido].iterrows():\n",
    "   \n",
    "# for index, row in fes[fes[\"fee_status_id\"] == 50].iterrows():\n",
    "    algoritmo = row[\"name\"]\n",
    "    name = algoritmo.split('_ALGO')[0]\n",
    "    execution_id = row[\"forecast_execution_id\"]\n",
    "    id_proveedor = row[\"ext_supplier_code\"]\n",
    "    forecast_execution_execute_id = row[\"forecast_execution_execute_id\"]\n",
    "    supplier_id = row[\"supplier_id\"]\n",
    "\n",
    "    folderP = folder + '/procesado'\n",
    "\n",
    "    print(f\"Algoritmo: {algoritmo}  - Name: {name} exce_id: {forecast_execution_execute_id} id: Proveedor {id_proveedor}\")\n",
    "    print(f\"supplier-id: {supplier_id} ----------------------------------------------------\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S50 ACTUALIZAR SOLO CABECERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algoritmo: 596_PROCTER_ALGO_01  - Name: 596_PROCTER exce_id: d6726d21-a0cc-44d8-84ea-52a05eccb50a id: Proveedor 596\n",
      "supplier-id: 8bfb27a1-516f-488f-9eda-9a6fbc5acf4b ----------------------------------------------------\n",
      "-> Generando datos para ID: 596, Label: 596_PROCTER_ALGO_01\n",
      "---> Datos de STOCK guardados: data/596_PROCTER_ALGO_01_Stock.csv\n",
      "-> Generando datos para ID: 596, Label: 596_PROCTER_ALGO_01\n",
      "---> Datos de OC DEMORADAS Recuperados: 596_PROCTER_ALGO_01\n",
      "✅ Stock Actualizado para 9737c740-ba85-462f-b446-d61905e3d048\n"
     ]
    }
   ],
   "source": [
    "elegido = '596_PROCTER_ALGO_01'\n",
    "for index, row in fes[fes[\"name\"] == elegido].iterrows():\n",
    "    \n",
    "# for index, row in fes[fes[\"fee_status_id\"] == 50].iterrows():\n",
    "    algoritmo = row[\"name\"]\n",
    "    name = algoritmo.split('_ALGO')[0]\n",
    "    execution_id = row[\"forecast_execution_id\"]\n",
    "    id_proveedor = row[\"ext_supplier_code\"]\n",
    "    forecast_execution_execute_id = row[\"forecast_execution_execute_id\"]\n",
    "    supplier_id = row[\"supplier_id\"]\n",
    "    \n",
    "    folderP = folder + '/procesado'\n",
    "\n",
    "    print(f\"Algoritmo: {algoritmo}  - Name: {name} exce_id: {forecast_execution_execute_id} id: Proveedor {id_proveedor}\")\n",
    "    print(f\"supplier-id: {supplier_id} ----------------------------------------------------\")\n",
    "\n",
    "    try: \n",
    "        # Leer forecast extendido\n",
    "        df_forecast_ext = pd.read_csv(f'{folderP}/{algoritmo}_Pronostico_Extendido.csv')\n",
    "        df_forecast_ext['Codigo_Articulo'] = df_forecast_ext['Codigo_Articulo'].astype(int)\n",
    "        df_forecast_ext['Sucursal'] = df_forecast_ext['Sucursal'].astype(int)\n",
    "        df_forecast_ext.fillna(0, inplace=True)\n",
    "        print(f\"-> Datos Recuperados del CACHE: {id_proveedor}, Label: {name}\")\n",
    "        print(\"❗Filas con site_id inválido:\", df_forecast_ext['site_id'].isna().sum())\n",
    "        print(\"❗Filas con product_id inválido:\", df_forecast_ext['product_id'].isna().sum())\n",
    "\n",
    "        # Hacer merge solo si no existen las columnas de precios y costos\n",
    "        if 'I_PRECIO_VTA' not in df_forecast_ext.columns or 'I_COSTO_ESTADISTICO' not in df_forecast_ext.columns:\n",
    "            print(f\"❌ ERROR: Falta la columna requerida '{col}' procedemos a actualizar {id_proveedor}\")\n",
    "            precio = get_precios(id_proveedor)\n",
    "            precio['C_ARTICULO'] = precio['C_ARTICULO'].astype(int)\n",
    "            precio['C_SUCU_EMPR'] = precio['C_SUCU_EMPR'].astype(int)\n",
    "\n",
    "            df_forecast_ext = df_forecast_ext.merge(\n",
    "                precio,\n",
    "                left_on=['Codigo_Articulo', 'Sucursal'],\n",
    "                right_on=['C_ARTICULO', 'C_SUCU_EMPR'],\n",
    "                how='left'\n",
    "            )\n",
    "        else:\n",
    "            print(f\"⚠️ El DataFrame ya contiene precios y costos. Merge evitado para {id_proveedor}\")\n",
    "\n",
    "        # Cálculo de métricas x Línea en miles\n",
    "        df_forecast_ext['Forecast_VENTA'] = (df_forecast_ext['Forecast'] * df_forecast_ext['I_PRECIO_VTA'] / 1000).round(2)\n",
    "        df_forecast_ext['Forecast_COSTO'] = (df_forecast_ext['Forecast'] * df_forecast_ext['I_COSTO_ESTADISTICO'] / 1000).round(2)\n",
    "        df_forecast_ext['MARGEN'] = (df_forecast_ext['Forecast_VENTA'] - df_forecast_ext['Forecast_COSTO'])\n",
    "\n",
    "        # Asegurar que los valores son del tipo float (nativo de Python)\n",
    "        total_venta = float(round(df_forecast_ext['Forecast_VENTA'].sum() / 1000, 2))\n",
    "        total_costo = float(round(df_forecast_ext['Forecast_COSTO'].sum() / 1000, 2))\n",
    "        total_margen = float(round(df_forecast_ext['MARGEN'].sum() / 1000, 2))\n",
    "        total_productos = df_forecast_ext['Codigo_Articulo'].nunique()\n",
    "        total_unidades = float(round(df_forecast_ext['Forecast'].sum() , 0))\n",
    "        \n",
    "            # Mini gráfico\n",
    "        mini_grafico = generar_mini_grafico(folderP, name)\n",
    "        \n",
    "        # DATOS COMPLEMENTARIOS\n",
    "        df_stock = obtener_datos_stock(id_proveedor= id_proveedor, etiqueta= algoritmo )\n",
    "        total_stock_valorizado = float(round(df_stock['Stock_Valorizado'].sum() / 1000000, 2))\n",
    "        total_venta_valorizada = float(round(df_stock['Venta_Valorizada'].sum() / 1000000, 2))\n",
    "        days= int( total_stock_valorizado / total_venta_valorizada * 30 )\n",
    "        # Condiciones Dias de STOCK\n",
    "        if days > 30:\n",
    "            semaforo= 'green'\n",
    "        elif 10 < days <= 30:\n",
    "            semaforo ='yellow'\n",
    "        elif days <= 10:\n",
    "            semaforo ='red'\n",
    "        else:\n",
    "            semaforo = 'white' # Valor predeterminado\n",
    "\n",
    "        # DEMORA de OC\n",
    "        df_demora = obtener_demora_oc(id_proveedor= id_proveedor, etiqueta= algoritmo )\n",
    "        if df_demora.empty:  # Verifica si el DataFrame está vacío\n",
    "            maximo_atraso_oc = 0\n",
    "        else:\n",
    "            maximo_atraso_oc = int(round(df_demora['Demora'].max()))\n",
    "        \n",
    "        # ARTICULOS FALTANTES\n",
    "        articulos_faltantes = df_stock[df_stock[\"Stock_Unidades\"] == 0][\"Codigo_Articulo\"].nunique()\n",
    "        if articulos_faltantes > 5:\n",
    "            quiebres= 'R'\n",
    "        elif 1 < articulos_faltantes <= 5:\n",
    "            quiebres ='Y'\n",
    "        elif articulos_faltantes <= 1:\n",
    "            quiebres ='G'\n",
    "        else:\n",
    "            quiebres = 'white' # Valor predeterminado\n",
    "                                \n",
    "        # update_execution_execute(\n",
    "        #     forecast_execution_execute_id,\n",
    "        #     otif = randint(70, 100),  # Simulación de OTIF entre 70 y 100\n",
    "        #     sotck_days = days, # Viene de la Nueva Rutina              \n",
    "        #     sotck_days_colors = semaforo, # Nueva Rutina\n",
    "        #     maximum_backorder_days = maximo_atraso_oc, # Calcula Mäxima Demora\n",
    "        #     contains_breaks = quiebres  # ICONO de FALTANTES\n",
    "        # )\n",
    "\n",
    "        # print(f\"✅ Stock Actualizado para {execution_id}\")\n",
    "        \n",
    "        # # ✅ Morver Archivo a carpeta de Procesado ....\n",
    "        # mover_archivos_procesados(algoritmo, folder)\n",
    "        # print(f\"✅ Archivo movido a Procesado: {algoritmo}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_execution_execute(\n",
    "    forecast_execution_execute_id,\n",
    "    supply_forecast_execution_status_id=50,\n",
    "    monthly_sales_in_millions=total_venta,\n",
    "    monthly_purchases_in_millions=total_costo,\n",
    "    monthly_net_margin_in_millions=total_margen,\n",
    "    graphic=mini_grafico,\n",
    "    total_products=total_productos,\n",
    "    total_units=total_unidades,\n",
    "    otif = randint(70, 100),  # Simulación de OTIF entre 70 y 100\n",
    "    sotck_days = days, # Viene de la Nueva Rutina              \n",
    "    sotck_days_colors = semaforo, # Nueva Rutina\n",
    "    maximum_backorder_days = maximo_atraso_oc, # Calcula Mäxima Demora\n",
    "    contains_breaks = quiebres  # ICONO de FALTANTES\n",
    ")\n",
    "\n",
    "print(f\"✅ Stock Actualizado para {execution_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_faltantes = df_stock[df_stock[\"Stock_Unidades\"] == 0]\n",
    "tools.display_dataframe_to_user(name=\"Articulos con FALTANTES\", dataframe=df_stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARCHES y ARREGLO DE PROBLEMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTUALZAR STOCK execution_result\n",
    "\n",
    "conn = Open_Connection()\n",
    "        \n",
    "# ----------------------------------------------------------------\n",
    "# FILTRA solo PRODUCTOS HABILITADOS y Traer datos de STOCK y PENDIENTES desde PRODUCCIÓN\n",
    "# ----------------------------------------------------------------\n",
    "query = f\"\"\"              \n",
    "SELECT A.[C_PROVEEDOR_PRIMARIO] as Codigo_Proveedor\n",
    "    ,S.[C_ARTICULO] as Codigo_Articulo\n",
    "    ,S.[C_SUCU_EMPR] as Codigo_Sucursal\n",
    "    ,S.[I_PRECIO_VTA] as Precio_Venta\n",
    "    ,S.[I_COSTO_ESTADISTICO] as Precio_Costo\n",
    "    ,S.[Q_FACTOR_VTA_SUCU] as Factor_Venta\n",
    "    ,ST.Q_UNID_ARTICULO + ST.Q_PESO_ARTICULO AS Stock_Unidades-- Stock Cierre Dia Anterior\n",
    "    ,(R.[Q_VENTA_30_DIAS] + R.[Q_VENTA_15_DIAS]) * S.[Q_FACTOR_VTA_SUCU] AS Venta_Unidades_30_Dias -- OJO convertida desde BULTOS DIARCO\n",
    "            \n",
    "    ,(ST.Q_UNID_ARTICULO + ST.Q_PESO_ARTICULO)* S.[I_COSTO_ESTADISTICO] AS Stock_Valorizado-- Stock Cierre Dia Anterior\n",
    "    ,(R.[Q_VENTA_30_DIAS] + R.[Q_VENTA_15_DIAS]) * S.[Q_FACTOR_VTA_SUCU] * S.[I_COSTO_ESTADISTICO] AS Venta_Valorizada\n",
    "\n",
    "    ,S.[F_ULTIMA_VTA]\n",
    "    ,S.[Q_VTA_ULTIMOS_15DIAS] * S.[Q_FACTOR_VTA_SUCU] AS VENTA_UNIDADES_1Q -- OJO esto está en BULTOS DIARCO\n",
    "    ,S.[Q_VTA_ULTIMOS_30DIAS] * S.[Q_FACTOR_VTA_SUCU] AS VENTA_UNIDADES_2Q -- OJO esto está en BULTOS DIARCO\n",
    "        \n",
    "FROM [DIARCOP001].[DiarcoP].[dbo].[T051_ARTICULOS_SUCURSAL] S\n",
    "INNER JOIN [DIARCOP001].[DiarcoP].[dbo].[T050_ARTICULOS] A\n",
    "    ON A.[C_ARTICULO] = S.[C_ARTICULO]\n",
    "LEFT JOIN [DIARCOP001].[DiarcoP].[dbo].[T060_STOCK] ST\n",
    "    ON ST.C_ARTICULO = S.[C_ARTICULO] \n",
    "    AND ST.C_SUCU_EMPR = S.[C_SUCU_EMPR]\n",
    "LEFT JOIN [DIARCOP001].[DiarcoP].[dbo].[T710_ESTADIS_REPOSICION] R\n",
    "    ON R.[C_ARTICULO] = S.[C_ARTICULO]\n",
    "    AND R.[C_SUCU_EMPR] = S.[C_SUCU_EMPR]\n",
    "\n",
    "WHERE S.[M_HABILITADO_SUCU] = 'S' -- Permitido Reponer\n",
    "    AND A.M_BAJA = 'N'  -- Activo en Maestro Artículos\n",
    "    AND A.[C_PROVEEDOR_PRIMARIO] IN ( 596)  -- Solo LISTA DE PROVEEDORES\n",
    "                \n",
    "ORDER BY S.[C_ARTICULO],S.[C_SUCU_EMPR];\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Ejecutar la consulta SQL\n",
    "df_stock = pd.read_sql(query, conn)\n",
    "\n",
    "\n",
    "file_path = f'{folder}/TOTAL_Stock.csv'\n",
    "df_stock['Codigo_Proveedor']= df_stock['Codigo_Proveedor'].astype(int)\n",
    "df_stock['Codigo_Articulo']= df_stock['Codigo_Articulo'].astype(int)\n",
    "df_stock['Codigo_Sucursal']= df_stock['Codigo_Sucursal'].astype(int)\n",
    "df_stock.fillna(0, inplace= True)\n",
    "df_stock.to_csv(file_path, index=False, encoding='utf-8')        \n",
    "print(f\"---> Datos de STOCK guardados: {file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "tools.display_dataframe_to_user(name=\"DATOS de STOCK\", dataframe=df_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy import text\n",
    "\n",
    "# === CONFIGURACIÓN DE CONEXIÓN A POSTGRESQL ===\n",
    "secrets = dotenv_values(\".env\")   # Cargar credenciales desde .env    \n",
    "\n",
    "DB_TYPE = \"postgresql\"\n",
    "DB_USER = secrets['USUARIO4']\n",
    "DB_PASS = secrets['CONTRASENA4']  # ⚠️ Reemplazar por la contraseña real o usar variables de entorno\n",
    "DB_HOST = secrets['SERVIDOR4']\n",
    "DB_PORT = secrets['PUERTO4']\n",
    "DB_NAME = secrets['BASE4']\n",
    "\n",
    "# Crear engine de conexión\n",
    "engine = sqlalchemy.create_engine(\n",
    "    f\"{DB_TYPE}://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    ")\n",
    "\n",
    "# === FUNCION PARA ACTUALIZAR STOCK EN BATCHES DE UPDATE INDIVIDUAL (LENTO) ===\n",
    "def actualizar_stock(df, engine, batch_size=10000):\n",
    "    total_actualizados = 0\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        for i in range(0, len(df), batch_size):\n",
    "            batch = df.iloc[i:i+batch_size]\n",
    "\n",
    "            # Crear lista de valores para cada fila del batch\n",
    "            values = [\n",
    "                {\n",
    "                    \"ext_product_code\": str(row[\"Codigo_Articulo\"]),\n",
    "                    \"ext_site_code\": str(row[\"Codigo_Sucursal\"]),\n",
    "                    \"ext_supplier_code\": str(row[\"Codigo_Proveedor\"]),\n",
    "                    \"quantity_stock\": float(row[\"Stock_Unidades\"])\n",
    "                }\n",
    "                for _, row in batch.iterrows()\n",
    "            ]\n",
    "\n",
    "            # Consulta SQL con parámetros bindeados\n",
    "            update_sql = text(\"\"\"\n",
    "                UPDATE spl_supply_forecast_execution_execute_result\n",
    "                SET quantity_stock = :quantity_stock\n",
    "                WHERE ext_product_code = :ext_product_code\n",
    "                    AND ext_site_code = :ext_site_code\n",
    "                    AND ext_supplier_code = :ext_supplier_code\n",
    "            \"\"\")\n",
    "\n",
    "            # Ejecutar el batch de updates\n",
    "            conn.execute(update_sql, values)\n",
    "            total_actualizados += len(values)\n",
    "            print(f\"Batch {i // batch_size + 1}: {len(values)} registros actualizados.\")\n",
    "\n",
    "    print(f\"✅ Total registros actualizados: {total_actualizados}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def actualizar_stock_masivo(df, engine):\n",
    "    with engine.begin() as conn:\n",
    "        print(\"1. Creando tabla temporal...\")\n",
    "\n",
    "        conn.execute(text(\"\"\"\n",
    "            DROP TABLE IF EXISTS tmp_stock_update;\n",
    "            CREATE TEMP TABLE tmp_stock_update (\n",
    "                ext_product_code VARCHAR,\n",
    "                ext_site_code VARCHAR,\n",
    "                ext_supplier_code VARCHAR,\n",
    "                quantity_stock NUMERIC\n",
    "            ) ON COMMIT DROP;\n",
    "        \"\"\"))\n",
    "\n",
    "        print(\"2. Cargando datos en tabla temporal...\")\n",
    "\n",
    "        # Convertir tipos para coincidir con el esquema\n",
    "        df_tmp = df[[\"Codigo_Articulo\", \"Codigo_Sucursal\", \"Codigo_Proveedor\", \"Stock_Unidades\"]].copy()\n",
    "        df_tmp.columns = [\"ext_product_code\", \"ext_site_code\", \"ext_supplier_code\", \"quantity_stock\"]\n",
    "        \n",
    "        # === CORRECCIÓN: Valores negativos a 0 ===\n",
    "        df_tmp[\"quantity_stock\"] = df_tmp[\"quantity_stock\"].clip(lower=0)\n",
    "        df_tmp[\"ext_product_code\"] = df_tmp[\"ext_product_code\"].astype(str)\n",
    "        df_tmp[\"ext_site_code\"] = df_tmp[\"ext_site_code\"].astype(str)\n",
    "        df_tmp[\"ext_supplier_code\"] = df_tmp[\"ext_supplier_code\"].astype(str)\n",
    "\n",
    "        # Cargar en bloque usando COPY (eficiente)\n",
    "        df_tmp.to_sql(\"tmp_stock_update\", con=engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "\n",
    "        print(\"3. Ejecutando UPDATE masivo...\")\n",
    "\n",
    "        conn.execute(text(\"\"\"\n",
    "            UPDATE spl_supply_forecast_execution_execute_result AS t\n",
    "            SET quantity_stock = u.quantity_stock\n",
    "            FROM tmp_stock_update AS u\n",
    "            WHERE t.ext_product_code = u.ext_product_code\n",
    "                AND t.ext_site_code = u.ext_site_code\n",
    "                AND t.ext_supplier_code = u.ext_supplier_code;\n",
    "        \"\"\"))\n",
    "\n",
    "        print(\"✅ Actualización finalizada con éxito.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJECUTAR\n",
    "\n",
    "# === CARGA DEL DATAFRAME ===\n",
    "# df = pd.read_csv(\"ruta_al_archivo.csv\")  # O si ya está cargado, usar directamente\n",
    "actualizar_stock_masivo(df_stock, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ARREGLAR PROBLEMAS\n",
    "df_sin_duplicados = df_forecast_ext.drop_duplicates(subset=['Codigo_Articulo', 'Sucursal'], keep='first')\n",
    "file_path = f\"{folder}/{algoritmo}_Pronostico_Extendido_Con_Graficos.csv\"\n",
    "df_sin_duplicados.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Función para decodificar y mostrar una imagen en Jupyter Notebook\n",
    "    \n",
    "img_data = base64.b64decode(mini_grafico)\n",
    "buffer = BytesIO(img_data)\n",
    "\n",
    "# Mostrar la imagen en Jupyter Notebook\n",
    "display(Image(buffer.getvalue()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualizar en base de datos            \n",
    "update_execution_execute(\n",
    "    forecast_execution_execute_id,\n",
    "    supply_forecast_execution_status_id=50,\n",
    "    monthly_sales_in_millions=total_venta,\n",
    "    monthly_purchases_in_millions=total_costo,\n",
    "    monthly_net_margin_in_millions=total_margen,\n",
    "    graphic=mini_grafico,\n",
    "    total_products=total_productos,\n",
    "    total_units=total_unidades,\n",
    "    otif = randint(70, 100),  # Simulación de OTIF entre 70 y 100\n",
    "    sotck_days = randint(10,76), # Simulación de stock_days entre 10 y 76\n",
    "    sotck_days_colors ='green', # Simulación de semaforo\n",
    "    maximum_backorder_days = randint(0,45) # Simulación de oc_delay entre 0 y 45\n",
    "    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
