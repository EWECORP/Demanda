{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALGORITMOS BASADOS EN SERIES TEMPORALES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Recopilación de Funciones\n",
    "\n",
    "Se compilan los Algoritmos Probados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRERIAS NECESARIAS \n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "from dotenv import dotenv_values\n",
    "import psycopg2 as pg2    # Conectores para Postgres\n",
    "import getpass  # Para obtener el usuario del sistema operativo\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "import ace_tools_open as tools\n",
    "\n",
    "# Evitar Mensajes Molestos\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category= FutureWarning)\n",
    "\n",
    "# Liberias para Algoritmos\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.holtwinters import Holt\n",
    "\n",
    "secrets = dotenv_values(\".env\")   # Connection String from .env\n",
    "folder = secrets[\"FOLDER_DATOS\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIONES\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "#     DATOS\n",
    "###----------------------------------------------------------------\n",
    "def Open_Connection():\n",
    "    secrets = dotenv_values(\".env\")   # Connection String from .env\n",
    "    conn_str = f'DRIVER={secrets[\"DRIVER2\"]};SERVER={secrets[\"SERVIDOR2\"]};PORT={secrets[\"PUERTO2\"]};DATABASE={secrets[\"BASE2\"]};UID={secrets[\"USUARIO2\"]};PWD={secrets[\"CONTRASENA2\"]}'\n",
    "    # print (conn_str) \n",
    "    try:    \n",
    "        conn = pyodbc.connect(conn_str)\n",
    "        return conn\n",
    "    except:\n",
    "        print('Error en la Conexión')\n",
    "        return None\n",
    "\n",
    "def Open_Conn_Postgres():\n",
    "    secrets = dotenv_values(\".env\")   # Cargar credenciales desde .env    \n",
    "    conn_str = f\"dbname={secrets['BASE3']} user={secrets['USUARIO3']} password={secrets['CONTRASENA3']} host={secrets['SERVIDOR3']} port={secrets['PUERTO3']}\"\n",
    "    #print (conn_str)\n",
    "    try:    \n",
    "        conn = pg2.connect(conn_str)\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f'Error en la conexión: {e}')\n",
    "        return None\n",
    "    \n",
    "def Close_Connection(conn): \n",
    "    conn.close()\n",
    "    return True\n",
    "\n",
    "def generar_datos(id_proveedor, etiqueta):\n",
    "    secrets = dotenv_values(\".env\")   # Connection String from .env\n",
    "    folder = secrets[\"FOLDER_DATOS\"]\n",
    "    \n",
    "    #  Intento recuperar datos cacheados\n",
    "    try:\n",
    "        data = pd.read_csv(f'{folder}/{etiqueta}.csv')\n",
    "        data['Codigo_Articulo']= data['Codigo_Articulo'].astype(int)\n",
    "        data['Sucursal']= data['Sucursal'].astype(int)\n",
    "        data['Fecha']= pd.to_datetime(data['Fecha'])\n",
    "\n",
    "        articulos = pd.read_csv(f'{folder}/{etiqueta}_articulos.csv')\n",
    "        #articulos.head()\n",
    "        print(f\"-> Datos Recuperados del CACHE: {id_proveedor}, Label: {etiqueta}\")\n",
    "        return data, articulos\n",
    "    except:     \n",
    "        print(f\"-> Generando datos para ID: {id_proveedor}, Label: {etiqueta}\")\n",
    "        # Configuración de conexión\n",
    "        conn = Open_Connection()\n",
    "        \n",
    "        # FILTRA solo PRODUCTOS HABILITADOS y Traer datos de STOCK y PENDIENTES desde PRODUCCIÓN\n",
    "        query = f\"\"\"\n",
    "        SELECT  A.[C_PROVEEDOR_PRIMARIO]\n",
    "            ,S.[C_ARTICULO]\n",
    "            ,S.[C_SUCU_EMPR]\n",
    "            ,S.[Q_FACTOR_VENTA_ESP]\n",
    "            ,S.[Q_FACTOR_VTA_SUCU]\n",
    "            ,S.[M_OFERTA_SUCU]\n",
    "            ,S.[M_HABILITADO_SUCU]\n",
    "            ,A.M_BAJA\n",
    "            ,S.[Q_VTA_DIA_ANT]\n",
    "            ,S.[Q_VTA_ACUM]\n",
    "            ,S.[Q_ULT_ING_STOCK]\n",
    "            ,S.[Q_STOCK_A_ULT_ING]\n",
    "            ,S.[Q_15DIASVTA_A_ULT_ING_STOCK]\n",
    "            ,S.[Q_30DIASVTA_A_ULT_ING_STOCK]\n",
    "            ,S.[Q_BULTOS_PENDIENTE_OC]\n",
    "            ,S.[Q_PESO_PENDIENTE_OC]\n",
    "            ,S.[Q_UNID_PESO_PEND_RECEP_TRANSF]\n",
    "            ,S.[Q_UNID_PESO_VTA_MES_ACTUAL]\n",
    "            ,S.[F_ULTIMA_VTA]\n",
    "            ,S.[Q_VTA_ULTIMOS_15DIAS]\n",
    "            ,S.[Q_VTA_ULTIMOS_30DIAS]\n",
    "            ,S.[Q_TRANSF_PEND]\n",
    "            ,S.[Q_TRANSF_EN_PREP]\n",
    "            ,S.[M_FOLDER]\n",
    "            ,S.[M_ALTA_RENTABILIDAD]\n",
    "            ,S.[Lugar_Abastecimiento]\n",
    "            ,S.[M_COSTO_LOGISTICO]\n",
    "        \n",
    "        FROM [DIARCOP001].[DiarcoP].[dbo].[T051_ARTICULOS_SUCURSAL] S\n",
    "        LEFT JOIN [DIARCOP001].[DiarcoP].[dbo].[T050_ARTICULOS] A\n",
    "            ON A.[C_ARTICULO] = S.[C_ARTICULO]\n",
    "\n",
    "        WHERE S.[M_HABILITADO_SUCU] = 'S' -- Permitido Reponer\n",
    "            AND A.M_BAJA = 'N'  -- Activo en Maestro Artículos\n",
    "            AND A.[C_PROVEEDOR_PRIMARIO] = {id_proveedor} -- Solo del Proveedor\n",
    "        ;\n",
    "        \"\"\"\n",
    "        # Ejecutar la consulta SQL\n",
    "        articulos = pd.read_sql(query, conn)\n",
    "        file_path = f'{folder}/{etiqueta}_articulos.csv'\n",
    "        articulos['C_PROVEEDOR_PRIMARIO']= articulos['C_PROVEEDOR_PRIMARIO'].astype(int)\n",
    "        articulos['C_ARTICULO']= articulos['C_ARTICULO'].astype(int)\n",
    "        articulos.to_csv(file_path, index=False, encoding='utf-8')        \n",
    "        print(f\"---> Datos de Artículos guardados: {file_path}\")\n",
    "        \n",
    "        # Consulta SQL para obtener las ventas de un proveedor específico   \n",
    "        # Reemplazar {proveedor} en la consulta con el ID de la tienda actual\n",
    "        query = f\"\"\"\n",
    "        SELECT V.[F_VENTA] as Fecha\n",
    "            ,V.[C_ARTICULO] as Codigo_Articulo\n",
    "            ,V.[C_SUCU_EMPR] as Sucursal\n",
    "            ,V.[I_PRECIO_VENTA] as Precio\n",
    "            ,V.[I_PRECIO_COSTO] as Costo\n",
    "            ,V.[Q_UNIDADES_VENDIDAS] as Unidades\n",
    "            ,V.[C_FAMILIA] as Familia\n",
    "            ,A.[C_RUBRO] as Rubro\n",
    "            ,A.[C_SUBRUBRO_1] as SubRubro\n",
    "            ,LTRIM(RTRIM(REPLACE(REPLACE(REPLACE(A.N_ARTICULO, CHAR(9), ''), CHAR(13), ''), CHAR(10), ''))) as Nombre_Articulo\n",
    "            ,A.[C_CLASIFICACION_COMPRA] as Clasificacion\n",
    "        FROM [DCO-DBCORE-P02].[DiarcoEst].[dbo].[T702_EST_VTAS_POR_ARTICULO] V\n",
    "        LEFT JOIN [DCO-DBCORE-P02].[DiarcoEst].[dbo].[T050_ARTICULOS] A \n",
    "            ON V.C_ARTICULO = A.C_ARTICULO\n",
    "        WHERE A.[C_PROVEEDOR_PRIMARIO] = {id_proveedor} AND V.F_VENTA >= '20210101' AND A.M_BAJA ='N'\n",
    "        ORDER BY V.F_VENTA ;\n",
    "        \"\"\"\n",
    "\n",
    "        # Ejecutar la consulta SQL\n",
    "        demanda = pd.read_sql(query, conn)\n",
    "        \n",
    "        # UNIR Y FILTRAR solo la demanda de los Hartículos VALIDOS.\n",
    "        # Realizar la unión (merge) de los DataFrames por las claves especificadas\n",
    "        data = pd.merge(\n",
    "            articulos,  # DataFrame de artículos\n",
    "            demanda,    # DataFrame de demanda\n",
    "            left_on=['C_ARTICULO', 'C_SUCU_EMPR'],  # Claves en 'articulos'\n",
    "            right_on=['Codigo_Articulo', 'Sucursal'],  # Claves en 'demanda'\n",
    "            how='inner'  # Solo traer los productos que están en 'articulos'\n",
    "        )\n",
    "            \n",
    "        # Guardar los resultados en un archivo CSV con el nombre del Proveedor\n",
    "        file_path = f'{folder}/{etiqueta}_FULL.csv'\n",
    "        data['C_ARTICULO']= data['C_ARTICULO'].astype(int)\n",
    "        data['C_SUCU_EMPR']= data['C_SUCU_EMPR'].astype(int)\n",
    "        data.to_csv(file_path, index=False, encoding='utf-8')\n",
    "        print(f\"---> Datos de FULL guardados: {file_path}\")        \n",
    "        # Eliminar Columnas Innecesarias\n",
    "        data = data[['Fecha', 'Codigo_Articulo', 'Sucursal', 'Unidades']]\n",
    "        \n",
    "        # Guardar los resultados en un archivo CSV con el nombre del Proveedor\n",
    "        file_path = f'{folder}/{etiqueta}.csv'\n",
    "        data.to_csv(file_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        # Cerrar la conexión después de la iteración\n",
    "        Close_Connection(conn)\n",
    "        return data, articulos\n",
    "###----------------------------------------------------------------\n",
    "#     ALGORITMOS\n",
    "###----------------------------------------------------------------\n",
    "# ALGO_01 Promedio de Ventas Ponderado \n",
    "###---------------------------------------------------------------- \n",
    "def Calcular_Demanda_ALGO_01(df, id_proveedor, etiqueta, period_length, current_date, factor_last, factor_previous, factor_year):\n",
    "    print('Dentro del Calcular_Demanda_ALGO_01')\n",
    "    print(f'FORECATS control: {id_proveedor} - {etiqueta} - ventana: {period_length} - factores: {factor_last} - {factor_previous} - {factor_year}')\n",
    "    # Definir rangos de fechas para cada período\n",
    "    last_period_start = current_date - pd.Timedelta(days=period_length - 1)\n",
    "    last_period_end = current_date\n",
    "\n",
    "    previous_period_start = current_date - pd.Timedelta(days=2 * period_length - 1)\n",
    "    previous_period_end = current_date - pd.Timedelta(days=period_length)\n",
    "\n",
    "    same_period_last_year_start = current_date - pd.DateOffset(years=1) - pd.Timedelta(days=period_length - 1)\n",
    "    same_period_last_year_end = current_date - pd.DateOffset(years=1)\n",
    "\n",
    "    # Filtrar los datos para cada uno de los períodos\n",
    "    df_last = df[(df['Fecha'] >= last_period_start) & (df['Fecha'] <= last_period_end)]\n",
    "    df_previous = df[(df['Fecha'] >= previous_period_start) & (df['Fecha'] <= previous_period_end)]\n",
    "    df_same_year = df[(df['Fecha'] >= same_period_last_year_start) & (df['Fecha'] <= same_period_last_year_end)]\n",
    "\n",
    "    # Agregar las ventas (unidades) por artículo y sucursal para cada período\n",
    "    sales_last = df_last.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                        .sum().reset_index().rename(columns={'Unidades': 'ventas_last'})\n",
    "    sales_previous = df_previous.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_previous'})\n",
    "    sales_same_year = df_same_year.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_same_year'})\n",
    "\n",
    "    # Unir la información de los tres períodos\n",
    "    forecast_df = pd.merge(sales_last, sales_previous, on=['Codigo_Articulo', 'Sucursal'], how='outer')\n",
    "    forecast_df = pd.merge(forecast_df, sales_same_year, on=['Codigo_Articulo', 'Sucursal'], how='outer')\n",
    "    forecast_df.fillna(0, inplace=True)\n",
    "\n",
    "    # Calcular la demanda estimada como el promedio de las ventas de los tres períodos\n",
    "    forecast_df['Forecast'] = (forecast_df['ventas_last'] * factor_last +\n",
    "                               forecast_df['ventas_previous'] * factor_previous +\n",
    "                               forecast_df['ventas_same_year'] * factor_year) / (factor_year + factor_last + factor_previous)\n",
    "\n",
    "    # Redondear la predicción al entero más cercano\n",
    "    forecast_df['Forecast'] = np.ceil(forecast_df['Forecast']).clip(lower=0)\n",
    "    forecast_df['Average'] = round(forecast_df['Forecast'] /period_length ,3)\n",
    "    # Borrar Columnas Innecesarias\n",
    "    forecast_df.drop(columns=['ventas_last', 'ventas_previous', 'ventas_same_year'], inplace=True)    \n",
    "\n",
    "    return forecast_df\n",
    "\n",
    "def Calcular_Demanda_Extendida_ALGO_01(df, id_proveedor, etiqueta, period_length, current_date, factor_last, factor_previous, factor_year):\n",
    "    # Definir rangos de fechas para cada período\n",
    "    last_period_start = current_date - pd.Timedelta(days=period_length - 1)\n",
    "    last_period_end = current_date\n",
    "\n",
    "    previous_period_start = current_date - pd.Timedelta(days=2 * period_length - 1)\n",
    "    previous_period_end = current_date - pd.Timedelta(days=period_length)\n",
    "\n",
    "    same_period_last_year_start = current_date - pd.DateOffset(years=1) - pd.Timedelta(days=period_length - 1)\n",
    "    same_period_last_year_end = current_date - pd.DateOffset(years=1)\n",
    "\n",
    "    # Filtrar los datos para cada uno de los períodos\n",
    "    df_last = df[(df['Fecha'] >= last_period_start) & (df['Fecha'] <= last_period_end)]\n",
    "    df_previous = df[(df['Fecha'] >= previous_period_start) & (df['Fecha'] <= previous_period_end)]\n",
    "    df_same_year = df[(df['Fecha'] >= same_period_last_year_start) & (df['Fecha'] <= same_period_last_year_end)]\n",
    "\n",
    "    # Agregar las ventas (unidades) por artículo y sucursal para cada período mas todos los datos anteriores.\n",
    "    sales_last = df_last.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                        .sum().reset_index().rename(columns={'Unidades': 'ventas_last'})\n",
    "    sales_previous = df_previous.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_previous'})\n",
    "    sales_same_year = df_same_year.groupby(['Codigo_Articulo', 'Sucursal'])['Unidades'] \\\n",
    "                                .sum().reset_index().rename(columns={'Unidades': 'ventas_same_year'})\n",
    "\n",
    "    # Unir la información de los tres períodos\n",
    "    validacion_df = pd.merge(sales_last, sales_previous, on=['Codigo_Articulo', 'Sucursal'], how='outer')\n",
    "    validacion_df = pd.merge(validacion_df, sales_same_year, on=['Codigo_Articulo', 'Sucursal'], how='outer')\n",
    "    validacion_df.fillna(0, inplace=True)\n",
    "\n",
    "    # Calcular la demanda estimada como el promedio de las ventas de los tres períodos\n",
    "    validacion_df['Forecast'] = (validacion_df['ventas_last'] * factor_last +\n",
    "                               validacion_df['ventas_previous'] * factor_previous +\n",
    "                               validacion_df['ventas_same_year'] * factor_year) / (factor_year + factor_last + factor_previous)\n",
    "    validacion_df['Average'] = round(validacion_df['Forecast'] /period_length ,3)\n",
    "    \n",
    "    # Redondear la predicción al entero más cercano\n",
    "    validacion_df['Forecast'] = np.ceil(validacion_df['Forecast']).clip(lower=0)\n",
    "    return validacion_df\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "# ALGO_02 Doble Exponencial -  Modelo Holt (TENDENCIA)\n",
    "###----------------------------------------------------------------\n",
    "def Calcular_Demanda_ALGO_02(df, id_proveedor, etiqueta, forecast_window, current_date):\n",
    "    print('Dentro del Calcular_Demanda_ALGO_02')\n",
    "    print(f'FORECATS Holt control: {id_proveedor} - {etiqueta} - ventana: {forecast_window} ')\n",
    "\n",
    "        # Ajustar el modelo Holt-Winters: \n",
    "        # - trend: 'add' para tendencia aditiva\n",
    "        # - seasonal: 'add' para estacionalidad aditiva\n",
    "        # - seasonal_periods: 7 (para estacionalidad semanal)\n",
    "    # Configurar la ventana de pronóstico (por ejemplo, 30 días o 45 días)\n",
    "    #forecast_window = 30  # Cambia a 45 si es necesario\n",
    "    # Lista para almacenar los resultados del forecast\n",
    "    resultados = []\n",
    "\n",
    "    # Agrupar los datos por 'Codigo_Articulo' y 'Sucursal'\n",
    "    for (codigo, sucursal), grupo in df.groupby(['Codigo_Articulo', 'Sucursal']):\n",
    "        # Ordenar cronológicamente y fijar 'Fecha' como índice\n",
    "        grupo = grupo.set_index('Fecha').sort_index()\n",
    "        \n",
    "        # Resamplear a frecuencia diaria sumando las ventas y rellenando días sin datos\n",
    "        ventas_diarias = grupo['Unidades'].resample('D').sum().fillna(0)\n",
    "        \n",
    "        # Verificar que la serie tenga suficientes datos para ajustar el modelo\n",
    "        if len(ventas_diarias) < 2 * 7:  # por ejemplo, al menos dos ciclos de la estacionalidad semanal\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Ajustar el modelo Holt\n",
    "            # - trend: 'add' para tendencia aditiva\n",
    "            # - seasonal: 'add' para estacionalidad aditiva\n",
    "            # - seasonal_periods: 7 (para estacionalidad semanal)\n",
    "            modelo = Holt(ventas_diarias)\n",
    "            modelo_ajustado = modelo.fit(optimized=True)\n",
    "            \n",
    "            # Realizar el forecast para la ventana definida\n",
    "            pronostico = modelo_ajustado.forecast(forecast_window)\n",
    "            \n",
    "            # La demanda esperada es la suma de las predicciones diarias en el periodo\n",
    "            forecast_total = pronostico.sum()\n",
    "        except Exception as e:\n",
    "            # Si ocurre algún error en el ajuste, puedes asignar un valor nulo o manejarlo de otra forma\n",
    "            forecast_total = None\n",
    "        \n",
    "        resultados.append({\n",
    "            'Codigo_Articulo': codigo,\n",
    "            'Sucursal': sucursal,\n",
    "            'Forecast': round(forecast_total, 2) if forecast_total is not None else None\n",
    "        })\n",
    "\n",
    "    # Crear el DataFrame final con los resultados del forecast\n",
    "    df_forecast = pd.DataFrame(resultados)\n",
    "    # Redondear la predicción al entero más cercano\n",
    "    df_forecast['Forecast'] = np.ceil(df_forecast['Forecast']).clip(lower=0)\n",
    "\n",
    "    return df_forecast\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "# ALGO_03 Suavizado Exponencial -  Modelo Holt-Winters (TENDENCIA + ESTACIONALIDAD)\n",
    "###----------------------------------------------------------------\n",
    "def Calcular_Demanda_ALGO_03(df, id_proveedor, etiqueta, forecast_window, current_date, periodos, f2, f3):\n",
    "    print('Dentro del Calcular_Demanda_ALGO_03')\n",
    "    print(f'FORECATS control: {id_proveedor} - {etiqueta} - ventana: {forecast_window} - factores: Períodos Estacionalidad  {periodos} - Tendencia: {f2} - Estacionalidad: {f3}')\n",
    "\n",
    "        # Ajustar el modelo Holt-Winters: \n",
    "        # - trend: 'add' para tendencia aditiva\n",
    "        # - seasonal: 'add' para estacionalidad aditiva\n",
    "        # - seasonal_periods: 7 (para estacionalidad semanal)\n",
    "    # Configurar la ventana de pronóstico (por ejemplo, 30 días o 45 días)\n",
    "    #forecast_window = 30  # Cambia a 45 si es necesario\n",
    "    # Lista para almacenar los resultados del forecast\n",
    "    resultados = []\n",
    "\n",
    "    # Agrupar los datos por 'Codigo_Articulo' y 'Sucursal'\n",
    "    for (codigo, sucursal), grupo in df.groupby(['Codigo_Articulo', 'Sucursal']):\n",
    "        # Ordenar cronológicamente y fijar 'Fecha' como índice\n",
    "        grupo = grupo.set_index('Fecha').sort_index()\n",
    "        \n",
    "        # Resamplear a frecuencia diaria sumando las ventas y rellenando días sin datos\n",
    "        ventas_diarias = grupo['Unidades'].resample('D').sum().fillna(0)\n",
    "        \n",
    "        # Verificar que la serie tenga suficientes datos para ajustar el modelo\n",
    "        if len(ventas_diarias) < 2 * 7:  # por ejemplo, al menos dos ciclos de la estacionalidad semanal\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Ajustar el modelo Holt-Winters: \n",
    "            # - trend: 'add' para tendencia aditiva\n",
    "            # - seasonal: 'add' para estacionalidad aditiva\n",
    "            # - seasonal_periods: 7 (para estacionalidad semanal)\n",
    "            modelo = ExponentialSmoothing(ventas_diarias, trend=f2, seasonal=f3, seasonal_periods=periodos)\n",
    "            modelo_ajustado = modelo.fit(optimized=True)\n",
    "            \n",
    "            # Realizar el forecast para la ventana definida\n",
    "            pronostico = modelo_ajustado.forecast(forecast_window)\n",
    "            \n",
    "            # La demanda esperada es la suma de las predicciones diarias en el periodo\n",
    "            forecast_total = pronostico.sum()\n",
    "        except Exception as e:\n",
    "            # Si ocurre algún error en el ajuste, puedes asignar un valor nulo o manejarlo de otra forma\n",
    "            forecast_total = None\n",
    "        \n",
    "        resultados.append({\n",
    "            'Codigo_Articulo': codigo,\n",
    "            'Sucursal': sucursal,\n",
    "            'Forecast': round(forecast_total, 2) if forecast_total is not None else None\n",
    "        })\n",
    "\n",
    "    # Crear el DataFrame final con los resultados del forecast\n",
    "    df_forecast = pd.DataFrame(resultados)\n",
    "    # Redondear la predicción al entero más cercano\n",
    "    df_forecast['Forecast'] = np.ceil(df_forecast['Forecast']).clip(lower=0)\n",
    "\n",
    "    return df_forecast\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "# ALGO_04 Suavizado Exponencial Simple -  Modelo de Media Movil Exponencial Ponderada (EWMA) x Factor alpha\n",
    "###----------------------------------------------------------------\n",
    "def Calcular_Demanda_ALGO_04(df, id_proveedor, etiqueta, forecast_window, current_date, alpha):\n",
    "    print('Dentro del Calcular_Demanda_ALGO_04')\n",
    "    print(f'FORECATS control: {id_proveedor} - {etiqueta} - ventana: {forecast_window} - Fator Alpha: {alpha} ')\n",
    "\n",
    "    # Configurar la ventana de pronóstico (por ejemplo, 30 o 45 días)\n",
    "    #forecast_window = 45  # Puedes cambiarlo a 45 según tus necesidades\n",
    "    # Parámetro de suavizado (alpha); valores cercanos a 1 dan más peso a los datos recientes\n",
    "    #alpha = 0.3\n",
    "\n",
    "    # Lista para almacenar los resultados del forecast\n",
    "    resultados = []\n",
    "\n",
    "    # Agrupar los datos por 'Codigo_Articulo' y 'Sucursal'\n",
    "    for (codigo, sucursal), grupo in df.groupby(['Codigo_Articulo', 'Sucursal']):\n",
    "        # Ordenar cronológicamente y fijar 'Fecha' como índice\n",
    "        grupo = grupo.set_index('Fecha').sort_index()\n",
    "        \n",
    "        # Resamplear a frecuencia diaria sumando las ventas y rellenando días sin datos\n",
    "        ventas_diarias = grupo['Unidades'].resample('D').sum().fillna(0)\n",
    "        \n",
    "        # Calcular el suavizado exponencial (EWMA) sobre la serie de ventas diarias\n",
    "        ewma_series = ventas_diarias.ewm(alpha=alpha, adjust=False).mean()\n",
    "        \n",
    "        # Tomamos el último valor suavizado como forecast diario\n",
    "        ultimo_ewma = ewma_series.iloc[-1]\n",
    "        \n",
    "        # El pronóstico total para la ventana definida es el pronóstico diario multiplicado por la cantidad de días\n",
    "        forecast_total = ultimo_ewma * forecast_window\n",
    "        \n",
    "        resultados.append({\n",
    "            'Codigo_Articulo': codigo,\n",
    "            'Sucursal': sucursal,\n",
    "            'Forecast': round(forecast_total, 2),\n",
    "            'EWMA': round(ultimo_ewma, 3)\n",
    "        })\n",
    "\n",
    "    # Crear el DataFrame final con los resultados\n",
    "    df_forecast = pd.DataFrame(resultados)\n",
    "    # Redondear la predicción al entero más cercano\n",
    "    df_forecast['Forecast'] = np.ceil(df_forecast['Forecast']).clip(lower=0)\n",
    "\n",
    "    #df_forecast.drop(columns=['EWMA'], inplace=True)    # Borrar Columnas Innecesarias\n",
    "    return df_forecast\n",
    "\n",
    "def Calcular_Demanda_Extendida_ALGO_04(df, id_proveedor, etiqueta, forecast_window, current_date, alpha):\n",
    "    print('Dentro del Calcular_Demanda_Extendida_ALGO_04')\n",
    "    print(f'FORECATS EXTENDIDO control: {id_proveedor} - {etiqueta} - ventana: {forecast_window} - Factor Alpha: {alpha}')\n",
    "\n",
    "    # Configurar la ventana de pronóstico (por ejemplo, 30 o 45 días)\n",
    "    #forecast_window = 45  # Puedes cambiarlo a 45 según tus necesidades\n",
    "    # Parámetro de suavizado (alpha); valores cercanos a 1 dan más peso a los datos recientes\n",
    "    #alpha = 0.3\n",
    "\n",
    "    # Lista para almacenar los resultados del forecast\n",
    "    resultados_validacion = []\n",
    "\n",
    "    # Agrupar los datos por 'Codigo_Articulo' y 'Sucursal'\n",
    "    for (codigo, sucursal), grupo in df.groupby(['Codigo_Articulo', 'Sucursal']):\n",
    "        # Ordenar cronológicamente y fijar 'Fecha' como índice\n",
    "        grupo = grupo.set_index('Fecha').sort_index()\n",
    "        \n",
    "        # Resamplear a frecuencia diaria sumando las ventas y rellenando días sin datos\n",
    "        ventas_diarias = grupo['Unidades'].resample('D').sum().fillna(0)\n",
    "        \n",
    "        # Calcular el suavizado exponencial (EWMA) sobre la serie de ventas diarias\n",
    "        ewma_series = ventas_diarias.ewm(alpha=alpha, adjust=False).mean()\n",
    "        \n",
    "        # Tomamos el último valor suavizado como forecast diario\n",
    "        ultimo_ewma = ewma_series.iloc[-1]\n",
    "        \n",
    "        # El pronóstico total para la ventana definida es el pronóstico diario multiplicado por la cantidad de días\n",
    "        forecast_total = ultimo_ewma * forecast_window\n",
    "        \n",
    "        resultados_validacion.append({\n",
    "            'Codigo_Articulo': codigo,\n",
    "            'Sucursal': sucursal,\n",
    "            'Forecast': round(forecast_total, 2),\n",
    "            'EWMA': round(ultimo_ewma, 3)\n",
    "        })\n",
    "\n",
    "    # Crear el DataFrame final con los resultados\n",
    "    df_validacion = pd.DataFrame(resultados_validacion)\n",
    "    # Redondear la predicción al entero más cercano\n",
    "    df_validacion['Forecast'] = np.ceil(df_validacion['Forecast']).clip(lower=0)\n",
    "    return df_validacion\n",
    "\n",
    "###----------------------------------------------------------------\n",
    "# ALGO_05 Promedio de Venta SIMPLE (PVS) (Metodo Actual que usan los Compradores)\n",
    "###----------------------------------------------------------------\n",
    "def Calcular_Demanda_ALGO_05(df_prv,forecast_window,id_proveedor, etiqueta):\n",
    "    # Lista para almacenar los resultados del pronóstico\n",
    "    resultados = []\n",
    "\n",
    "    # Agrupar los datos por 'Codigo_Articulo' y 'Sucursal'\n",
    "    for (codigo, sucursal), grupo in df_prv.groupby(['Codigo_Articulo', 'Sucursal']):\n",
    "        # Establecer 'Fecha' como índice y ordenar los datos\n",
    "        grupo = grupo.set_index('Fecha').sort_index()\n",
    "        \n",
    "        # Resamplear a diario sumando las ventas\n",
    "        ventas_diarias = grupo['Unidades'].resample('D').sum().fillna(0)\n",
    "        \n",
    "        # Seleccionar un periodo reciente para calcular la media; por ejemplo, los últimos 30 días\n",
    "        # Si hay menos de 30 días de datos, se utiliza el periodo disponible\n",
    "        ventas_recientes = ventas_diarias[-30:]\n",
    "        media_diaria = ventas_recientes.mean()\n",
    "        \n",
    "        # Pronosticar la demanda para el periodo de reposición\n",
    "        pronostico = media_diaria * forecast_window\n",
    "        \n",
    "        resultados.append({\n",
    "            'Codigo_Articulo': codigo,\n",
    "            'Sucursal': sucursal,\n",
    "            'Forecast': round(pronostico, 2),\n",
    "            'Average': round(media_diaria, 3)\n",
    "        })\n",
    "\n",
    "    # Crear el DataFrame de pronósticos\n",
    "    df_pronostico = pd.DataFrame(resultados)\n",
    "        # Redondear la predicción al entero más cercano\n",
    "    df_pronostico['Forecast'] = np.ceil(df_pronostico['Forecast']).clip(lower=0)\n",
    "    return df_pronostico\n",
    "\n",
    "def Calcular_Demanda_Extendida_ALGO_05(df_prv,forecast_window,id_proveedor, etiqueta):\n",
    "    max_date = df_prv['Fecha'].max()\n",
    "    cutoff_date = max_date - timedelta(days=forecast_window)\n",
    "    resultados_validacion = []\n",
    "\n",
    "    # Agrupar los datos por 'Codigo_Articulo' y 'Sucursal'\n",
    "    for (codigo, sucursal), grupo in df_prv.groupby(['Codigo_Articulo', 'Sucursal']):\n",
    "        # Establecer 'Fecha' como índice y ordenar cronológicamente\n",
    "        grupo = grupo.set_index('Fecha').sort_index()\n",
    "        \n",
    "        # Datos de entrenamiento: hasta la fecha de corte\n",
    "        datos_entrenamiento = grupo.loc[:cutoff_date]\n",
    "        \n",
    "        # Verificar que existan suficientes datos para calcular el promedio (por ejemplo, al menos 30 días)\n",
    "        if len(datos_entrenamiento) < 30:\n",
    "            continue  # O vemos como manejarlo de otra forma\n",
    "        \n",
    "        # Resamplear a ventas diarias en el conjunto de entrenamiento\n",
    "        ventas_diarias_entrenamiento = datos_entrenamiento['Unidades'].resample('D').sum().fillna(0)\n",
    "        \n",
    "        # Calcular la media diaria de los últimos 30 días del periodo de entrenamiento\n",
    "        ventas_recientes = ventas_diarias_entrenamiento[-30:]\n",
    "        media_diaria = ventas_recientes.mean()\n",
    "        \n",
    "        # Calcular el pronóstico para la ventana definida\n",
    "        forecast = media_diaria * forecast_window\n",
    "        \n",
    "        # Definir el periodo de validación: desde el día siguiente a la fecha de corte hasta completar la ventana\n",
    "        inicio_validacion = cutoff_date + timedelta(days=1)\n",
    "        fin_validacion = cutoff_date + timedelta(days=forecast_window)\n",
    "        \n",
    "        # Extraer y resumir las ventas reales en el periodo de validación\n",
    "        ventas_validacion = grupo.loc[inicio_validacion:fin_validacion]['Unidades'].resample('D').sum().fillna(0)\n",
    "        ventas_reales = ventas_validacion.sum()\n",
    "        \n",
    "        # Calcular medidas de error\n",
    "        error_absoluto = abs(forecast - ventas_reales)\n",
    "        error_porcentual = (error_absoluto / ventas_reales * 100) if ventas_reales != 0 else None\n",
    "        \n",
    "        resultados_validacion.append({\n",
    "            'Codigo_Articulo': codigo,\n",
    "            'Sucursal': sucursal,\n",
    "            'Forecast': round(forecast, 2),\n",
    "            'Ventas_Reales': round(ventas_reales, 2),\n",
    "            'Error_Absoluto': round(error_absoluto, 2),\n",
    "            'Error_Porcentual': round(error_porcentual, 2) if error_porcentual is not None else None\n",
    "        })\n",
    "\n",
    "    # Crear un DataFrame con los resultados de validación\n",
    "    df_validacion = pd.DataFrame(resultados_validacion)\n",
    "    # Redondear la predicción al entero más cercano\n",
    "    df_validacion['Forecast'] = np.ceil(df_validacion['Forecast']).clip(lower=0)\n",
    "    return df_validacion\n",
    "\n",
    "\n",
    "def Exportar_Pronostico(df_forecast, proveedor, etiqueta, algoritmo):\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    \n",
    "    # tools.display_dataframe_to_user(name=\"SET de Datos del Proveedor\", dataframe=df_forecast)\n",
    "    # df_forecast.info()\n",
    "    print(f'-> ** Pronostico Guardado en: {folder}/{etiqueta}_Pronostico_{algoritmo}.csv **')\n",
    "    df_forecast.to_csv(f'{folder}/{etiqueta}_Pronostico_{algoritmo}.csv', index=False)\n",
    "    \n",
    "    ## GUARDAR TABLA EN POSTGRES\n",
    "    usuario = getpass.getuser()  # Obtiene el usuario del sistema operativo\n",
    "    fecha_actual = datetime.today().strftime('%Y-%m-%d')  # Obtiene la fecha de hoy en formato 'YYYY-MM-DD'\n",
    "\n",
    "    conn = Open_Conn_Postgres()\n",
    "    \n",
    "    # Query de inserción\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO public.f_oc_precarga_connexa (\n",
    "        c_proveedor, c_articulo, c_sucu_empr, q_forecast_unidades, f_alta_forecast, c_usuario_forecast, create_date\n",
    "    ) VALUES (%s, %s, %s, %s, %s, %s, %s);\n",
    "    \"\"\"\n",
    "\n",
    "    # Convertir el DataFrame a una lista de tuplas para la inserción en bloque\n",
    "    data_to_insert = [\n",
    "        (proveedor, row['Codigo_Articulo'], row['Sucursal'], row['Forecast'], fecha_actual, usuario, fecha_actual)\n",
    "        for _, row in df_forecast.iterrows()\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.executemany(insert_query, data_to_insert)\n",
    "        conn.commit()\n",
    "        print(f\"✅ Inserción completada: {len(data_to_insert)} registros insertados.\")\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"❌ Error en la inserción: {e}\")\n",
    "    finally:\n",
    "        Close_Connection(conn)\n",
    "        print(\"✅ Conexión cerrada.\")\n",
    "    \n",
    "    \n",
    "def Procesar_ALGO_05(data, proveedor, etiqueta, ventana, fecha):\n",
    "    df_forecast = Calcular_Demanda_ALGO_05(data, ventana, proveedor, etiqueta)    # Exportar el resultado a un CSV para su posterior procesamiento\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    df_forecast.to_csv(f'{folder}/{etiqueta}_ALGO_05_Solicitudes_Compra.csv', index=False)\n",
    "\n",
    "    df_validacion = Calcular_Demanda_Extendida_ALGO_05(data, ventana, proveedor, etiqueta)\n",
    "    df_validacion['Codigo_Articulo']= df_validacion['Codigo_Articulo'].astype(int)\n",
    "    df_validacion['Sucursal']= df_validacion['Sucursal'].astype(int)\n",
    "    df_validacion.to_csv(f'{folder}/{etiqueta}_ALGO_05_Datos_Validacion.csv', index=False)\n",
    "    print(f'-> ** Validación Exportada: {etiqueta}_ALGO_05_Datos_Validacion.csv *** : ventana: {ventana}  - {fecha}')\n",
    "    \n",
    "    Exportar_Pronostico(df_forecast, proveedor, etiqueta, 'ALGO_05')  # Impactar Datos en la Interface   \n",
    "    return\n",
    "\n",
    "def Procesar_ALGO_04(data, proveedor, etiqueta, ventana, current_date=None,  alfa=None):    \n",
    "    # Asignar valores por defecto si los factores no están definidos\n",
    "    alfa = 0.5 if alfa is None else float(alfa)\n",
    "    \n",
    "    # Determinar la fecha base\n",
    "    if current_date is None:\n",
    "        current_date = data['Fecha'].max()  # Se toma la última fecha en los datos\n",
    "    else:\n",
    "        current_date = pd.to_datetime(current_date)  # Se asegura que sea un objeto datetime\n",
    "    \n",
    "    # Parámetro de suavizado (alpha); valores cercanos a 1 dan más peso a los datos recientes\n",
    "    \n",
    "    print(f'--> ALGO_04 ventana {ventana} - fecha {current_date} Peso de los Factores Utilizados: Factor Alpha: {alfa} ')\n",
    "        \n",
    "    df_forecast = Calcular_Demanda_ALGO_04(data, proveedor, etiqueta, ventana, current_date, alfa)\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    df_forecast.to_csv(f'{folder}/{etiqueta}_ALGO_04_Solicitudes_Compra.csv', index=False)   # Exportar el resultado a un CSV para su posterior procesamiento\n",
    "    \n",
    "    df_validacion = Calcular_Demanda_Extendida_ALGO_04(data, proveedor, etiqueta, ventana, current_date, alfa)\n",
    "    df_validacion['Codigo_Articulo']= df_validacion['Codigo_Articulo'].astype(int)\n",
    "    df_validacion['Sucursal']= df_validacion['Sucursal'].astype(int)\n",
    "    df_validacion.to_csv(f'{folder}/{etiqueta}_ALGO_04_Datos_Validacion.csv', index=False)\n",
    "    print(f'-> ** Validación Exportada: {etiqueta}_ALGO_04_Datos_Validacion.csv *** : ventana: {ventana}  - {current_date}')\n",
    "    \n",
    "    Exportar_Pronostico(df_forecast, proveedor, etiqueta, 'ALGO_04')  # Impactar Datos en la Interface        \n",
    "    return\n",
    "\n",
    "def Procesar_ALGO_03(data, proveedor, etiqueta, ventana, fecha, periodos=None, f2=None, f3=None):    \n",
    "    # Asignar valores por defecto si los factores no están definidos\n",
    "    periodos = 7 if periodos is None else int(periodos)\n",
    "    f2 = 'add' if f2 is None else str(f2)  # Incorporar Efecto Estacionalidad\n",
    "    f3 = 'add' if f3 is None else str(f3) # Informprar Efecto Tendencia Anual\n",
    "    \n",
    "    print(f'--> ALGO_03 ventana {ventana} - Factores Utilizados: Períodos: {periodos} estacionalidad: {f2} tendencia: {f3}')\n",
    "        \n",
    "    df_forecast = Calcular_Demanda_ALGO_03(data, proveedor, etiqueta, ventana, fecha, periodos, f2, f3)\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    df_forecast.to_csv(f'{folder}/{etiqueta}_ALGO_02_Solicitudes_Compra.csv', index=False)   # Exportar el resultado a un CSV para su posterior procesamiento\n",
    "    print(f'-> ** Datos Exportados: {etiqueta}_ALGO_02_Solicitudes_Compra.csv *** : ventana: {ventana}  - {fecha}')\n",
    "    Exportar_Pronostico(df_forecast, proveedor, etiqueta, 'ALGO_03')  # Impactar Datos en la Interface        \n",
    "    return\n",
    "\n",
    "def Procesar_ALGO_02(data, proveedor, etiqueta, ventana, fecha):    \n",
    "    print(f'--> ALGO_02 ventana {ventana} - Holt - No usa Factores')\n",
    "        \n",
    "    df_forecast = Calcular_Demanda_ALGO_02(data, proveedor, etiqueta, ventana, fecha)\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    df_forecast.to_csv(f'{folder}/{etiqueta}_ALGO_02_Solicitudes_Compra.csv', index=False)   # Exportar el resultado a un CSV para su posterior procesamiento\n",
    "    print(f'-> ** Datos Exportados: {etiqueta}_ALGO_02_Solicitudes_Compra.csv *** : ventana: {ventana}  - {fecha}')\n",
    "    Exportar_Pronostico(df_forecast, proveedor, etiqueta, 'ALGO_02')  # Impactar Datos en la Interface        \n",
    "    return\n",
    "\n",
    "def Procesar_ALGO_01(data, proveedor, etiqueta, ventana, fecha, factor_last=None, factor_previous=None, factor_year=None):    \n",
    "    # Asignar valores por defecto si los factores no están definidos\n",
    "    factor_last = 77 if factor_last is None else int(factor_last)\n",
    "    factor_previous = 22 if factor_previous is None else int(factor_previous)\n",
    "    factor_year = 11 if factor_year is None else int(factor_year)\n",
    "\n",
    "    print(f'--> ALGO_01 ventana {ventana} - Peso de los Factores Utilizados: último: {factor_last} previo: {factor_previous} año anterior: {factor_year}')\n",
    "        \n",
    "    df_forecast = Calcular_Demanda_ALGO_01(data, proveedor, etiqueta, ventana, fecha, factor_last, factor_previous, factor_year)\n",
    "    df_forecast['Codigo_Articulo']= df_forecast['Codigo_Articulo'].astype(int)\n",
    "    df_forecast['Sucursal']= df_forecast['Sucursal'].astype(int)\n",
    "    df_forecast.to_csv(f'{folder}/{etiqueta}_ALGO_01_Solicitudes_Compra.csv', index=False)   # Exportar el resultado a un CSV para su posterior procesamiento\n",
    "    \n",
    "    df_validacion = Calcular_Demanda_Extendida_ALGO_01(data, proveedor, etiqueta, ventana, fecha, factor_last, factor_previous, factor_year)\n",
    "    df_validacion['Codigo_Articulo']= df_validacion['Codigo_Articulo'].astype(int)\n",
    "    df_validacion['Sucursal']= df_validacion['Sucursal'].astype(int)\n",
    "    df_validacion.to_csv(f'{folder}/{etiqueta}_ALGO_01_Datos_Validacion.csv', index=False)\n",
    "    print(f'-> ** Validación Exportada: {etiqueta}_ALGO_01_Datos_Validacion.csv *** : ventana: {ventana}  - {fecha}')\n",
    "    \n",
    "    Exportar_Pronostico(df_forecast, proveedor, etiqueta, 'ALGO_01')  # Impactar Datos en la Interface        \n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUTINA PRINCIPAL para obtener el pronóstico\n",
    "def get_forecast( id_proveedor, lbl_proveedor, period_lengh=30, algorithm='basic', f1=None, f2=None, f3=None, current_date=None ):\n",
    "    \"\"\"\n",
    "    Genera la predicción de demanda según el algoritmo seleccionado.\n",
    "\n",
    "    Parámetros:\n",
    "    - id_proveedor: ID del proveedor.\n",
    "    - lbl_proveedor: Etiqueta del proveedor.\n",
    "    - period_lengh: Número de días del período a analizar (por defecto 30).\n",
    "    - algorithm: Algoritmo a utilizar.\n",
    "    - current_date: Fecha de referencia; si es None, se toma la fecha máxima de los datos.\n",
    "    - factores de ponderación: F1, F2, F3  (No importa en que unidades estén, luego los hace relativos al total del peso)\n",
    "\n",
    "    Retorna:\n",
    "    - Un DataFrame con las predicciones.\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Dentro del get_forecast')\n",
    "    print(f'FORECAST control: {id_proveedor} - {lbl_proveedor} - ventana: {period_lengh} - {algorithm} factores: {f1} - {f2} - {f3}')\n",
    "    # Generar los datos de entrada\n",
    "    data, articulos = generar_datos(id_proveedor, lbl_proveedor)\n",
    "\n",
    "        # Determinar la fecha base\n",
    "    if current_date is None:\n",
    "        current_date = data['Fecha'].max()  # Se toma la última fecha en los datos\n",
    "    else:\n",
    "        current_date = pd.to_datetime(current_date)  # Se asegura que sea un objeto datetime\n",
    "    print(f'Fecha actual {current_date}')\n",
    "    \n",
    "\n",
    "    # Selección del algoritmo de predicción\n",
    "    match algorithm:\n",
    "        case 'ALGO_01':\n",
    "            return Procesar_ALGO_01(data, id_proveedor, lbl_proveedor, period_lengh, current_date, f1, f2, f3)  # Promedio Ponderado x 3 Factores\n",
    "        case 'ALGO_02':\n",
    "            return Procesar_ALGO_02(data, id_proveedor, lbl_proveedor, period_lengh, current_date) # Doble Exponencial - Modelo Holt (Tendencia)\n",
    "        case 'ALGO_03':\n",
    "            return Procesar_ALGO_03(data, id_proveedor, lbl_proveedor, period_lengh, current_date, f1, f2, f3) # Triple Exponencial Holt-WInter (Tendencia + Estacionalidad) (periodos, add, add)\n",
    "        case 'ALGO_04':\n",
    "            return Procesar_ALGO_04(data, id_proveedor, lbl_proveedor, period_lengh, current_date, f1) # EWMA con Factor alpha\n",
    "        case 'ALGO_05':\n",
    "            return Procesar_ALGO_05(data, id_proveedor, lbl_proveedor, period_lengh, current_date) # Promedio Venta Simple en Ventana\n",
    "        case _:\n",
    "            raise ValueError(f\"Error: El algoritmo '{algorithm}' no está implementado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJECUCIÓN MASIVA x LISTA\n",
    "\n",
    "proveedores = [\n",
    "    {\"id\": 20, \"nombre\": \"MOLINOS RIO DE LA PLATA\", \"label\": \"20_MOLINOS\", \"ventana\": 30, \"algoritmo\" : \"ALGO_05\"},\n",
    "    {\"id\": 20, \"nombre\": \"MOLINOS RIO DE LA PLATA\", \"label\": \"20_MOLINOS\", \"ventana\": 30, \"algoritmo\" : \"ALGO_01\", \"f1\": 90, \"f2\": 10, \"f3\": 20},\n",
    "    {\"id\": 20, \"nombre\": \"MOLINOS RIO DE LA PLATA\", \"label\": \"20_MOLINOS\", \"ventana\": 30, \"algoritmo\" : \"ALGO_04\", \"f1\": 0.6},\n",
    "    \n",
    "    {\"id\": 25, \"nombre\": \"CAFES LA VIRGINIA S.A.\", \"label\": \"25_LA_VIRGINIA\", \"ventana\": 30, \"algoritmo\"  :  \"ALGO_05\"},\n",
    "    {\"id\": 25, \"nombre\": \"CAFES LA VIRGINIA S.A.\", \"label\": \"25_LA_VIRGINIA\", \"ventana\": 30, \"algoritmo\"  :  \"ALGO_02\"},\n",
    "    {\"id\": 25, \"nombre\": \"CAFES LA VIRGINIA S.A.\", \"label\": \"25_LA_VIRGINIA\", \"ventana\": 30, \"algoritmo\"  :   \"ALGO_01\", \"f1\": 80, \"f2\": 10, \"f3\": 20},\n",
    "    \n",
    "    {\"id\": 62, \"nombre\": \"ARCOR\",\"label\":\"62_ARCOR\", \"label\": \"62_ARCOR\", \"ventana\": 30, \"algoritmo\" : \"ALGO_05\"},\n",
    "    \n",
    "    {\"id\": 98, \"nombre\": \"FRATELLI BRANCA DESTILERIAS S.A.\", \"label\": \"98_FRATELLI_BRANCA\", \"ventana\": 30, \"algoritmo\" : \"ALGO_01\", \"f1\": 70, \"f2\": 10, \"f3\": 20},\n",
    "    {\"id\": 98, \"nombre\": \"FRATELLI BRANCA DESTILERIAS S.A.\", \"label\": \"98_FRATELLI_BRANCA\", \"ventana\": 30, \"algoritmo\" : \"ALGO_05\"},\n",
    "    {\"id\": 98, \"nombre\": \"FRATELLI BRANCA DESTILERIAS S.A.\", \"label\": \"98_FRATELLI_BRANCA\", \"ventana\": 30, \"algoritmo\" : \"ALGO_04\", \"f1\": 0.6},\n",
    "    {\"id\": 98, \"nombre\": \"FRATELLI BRANCA DESTILERIAS S.A.\", \"label\": \"98_FRATELLI_BRANCA\", \"ventana\": 30, \"algoritmo\" : \"ALGO_03\", \"f1\": 12, \"f2\": \"add\", \"f3\": \"add\"},\n",
    "    \n",
    "    {\"id\": 140, \"nombre\": \"UNILEVER DE ARGENTINA S.A.\", \"label\": \"140_UNILEVER\", \"ventana\": 30, \"algoritmo\" : \"ALGO_05\"},\n",
    "    \n",
    "    {\"id\": 189, \"nombre\": \"BODEGAS Y VIÑEDOS LOPEZ S.A.I.C.\", \"label\": \"189_BODEGAS_LOPEZ\", \"ventana\": 30, \"algoritmo\" : \"ALGO_05\"},\n",
    "    {\"id\": 189, \"nombre\": \"BODEGAS Y VIÑEDOS LOPEZ S.A.I.C.\", \"label\": \"189_BODEGAS_LOPEZ\", \"ventana\": 30, \"algoritmo\" : \"ALGO_01\", \"f1\": 100, \"f2\": 10, \"f3\": 10},\n",
    "    {\"id\": 189, \"nombre\": \"BODEGAS Y VIÑEDOS LOPEZ S.A.I.C.\", \"label\": \"189_BODEGAS_LOPEZ\", \"ventana\": 30, \"algoritmo\" : \"ALGO_04\", \"f1\": 0.3},\n",
    "    {\"id\": 189, \"nombre\": \"BODEGAS Y VIÑEDOS LOPEZ S.A.I.C.\", \"label\": \"189_BODEGAS_LOPEZ\", \"ventana\": 30, \"algoritmo\" : \"ALGO_03\", \"f1\": 7, \"f2\": \"add\", \"f3\": \"add\"},\n",
    "\n",
    "    {\"id\": 3075, \"nombre\": \"<NAME>\", \"label\":\"3075_MARTIN_GARCIA\", \"ventana\": 30, \"algoritmo\" : \"ALGO_01\"},\n",
    "\n",
    "    {\"id\": 1465, \"nombre\": \"QUICKFOOD S.A.\", \"label\":\"1465_QUICKFOOD\", \"ventana\": 30, \"algoritmo\" : \"ALGO_05\"},\n",
    "    \n",
    "    {\"id\": 327, \"nombre\": \"PALADINI S.A.\", \"label\":\"327_PALADINI\", \"ventana\": 30, \"algoritmo\" : \"ALGO_05\"}\n",
    "]\n",
    "\n",
    "for proveedor in proveedores:\n",
    "    f1 = proveedor.get(\"f1\", None)  # Si no está en el diccionario, devuelve None\n",
    "    f2 = proveedor.get(\"f2\", None)\n",
    "    f3 = proveedor.get(\"f3\", None)\n",
    "    \n",
    "    print(f'Procesando: {proveedor[\"id\"]} - {proveedor[\"label\"]} - ventana: {proveedor[\"ventana\"]} - {proveedor[\"algoritmo\"]} factores: {f1} - {f2} - {f3}')\n",
    "    \n",
    "    # Llamando a la Rutina Principal\n",
    "    get_forecast(proveedor[\"id\"], proveedor[\"label\"], proveedor[\"ventana\"], proveedor[\"algoritmo\"], f1, f2, f3)    \n",
    "    print('------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de Ejecución Individual\n",
    "\n",
    "etiqueta ='189_BODEGAS_LOPEZ'\n",
    "data = pd.read_csv(f'{folder}/{etiqueta}.csv')\n",
    "data['Codigo_Articulo']= data['Codigo_Articulo'].astype(int)\n",
    "data['Sucursal']= data['Sucursal'].astype(int)\n",
    "data['Fecha']= pd.to_datetime(data['Fecha'])\n",
    "\n",
    "# import ace_tools_open as tools\n",
    "tools.display_dataframe_to_user(name=\"SET de Datos del Proveedor\", dataframe=data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
